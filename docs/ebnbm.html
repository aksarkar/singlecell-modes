<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-09-05 Sat 13:56 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Negative binomial measurement model</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="css/bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="css/supp.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Negative binomial measurement model</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org040c2a7">Introduction</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#orgf3cc87c">Results</a>
<ul>
<li><a href="#org1469cfa">Simulate from the NB measurement model</a></li>
<li><a href="#total-var">Total variance under NB measurement</a></li>
<li><a href="#org72a0851">VBEM algorithm for Gamma expression model</a></li>
<li><a href="#org0473663">Simulated example</a></li>
<li><a href="#org9a061c5">Application to control data</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org040c2a7" class="outline-2">
<h2 id="org040c2a7">Introduction</h2>
<div class="outline-text-2" id="text-org040c2a7">
<p>
We, and Svensson 2020, found some evidence for overdispersion in control
scRNA-seq data. Here, we estimate to what extent that overdispersion could be
explained by an overdispersed measurement model, using the key fact that the
measurement overdispersion is described by a single parameter common across
all genes. We specifically consider combining an NB measurement model with a
Gamma expression model \(
  \DeclareMathOperator\Pois{Poisson}
  \DeclareMathOperator\Gam{Gamma}
  \DeclareMathOperator\NB{NB}
  \DeclareMathOperator\V{V}
  \newcommand\const{\mathrm{const}}
  \newcommand\lnb{l_{\mathrm{NB}}}
  \newcommand\E[1]{\left\langle #1 \right\rangle}
  \)
</p>

\begin{align}
  x_{ij} \mid s_i, \lambda_{ij}, u_{ij} &\sim \NB(s_i \lambda_{ij}, \theta)\\
  \lambda_{ij} \mid a_j, b_j &\sim \Gam(a_j, b_j),
\end{align}

<p>
where the NB distribution is parameterized by mean and dispersion, and the
Gamma distribution is parameterized by shape and rate.
</p>
</div>
</div>

<div id="outline-container-orgf1021bd" class="outline-2">
<h2 id="setup"><a id="orgf1021bd"></a>Setup</h2>
<div class="outline-text-2" id="text-setup">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> pandas <span class="org-keyword">as</span> pd
<span class="org-keyword">import</span> pickle
<span class="org-keyword">import</span> scanpy <span class="org-keyword">as</span> sc
<span class="org-keyword">import</span> scipy.special <span class="org-keyword">as</span> sp
<span class="org-keyword">import</span> scipy.stats <span class="org-keyword">as</span> st
<span class="org-keyword">import</span> scmodes
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> colorcet
<span class="org-keyword">import</span> matplotlib
<span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'figure.facecolor'</span>] = <span class="org-string">'w'</span>
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'font.family'</span>] = <span class="org-string">'Nimbus Sans'</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf3cc87c" class="outline-2">
<h2 id="orgf3cc87c">Results</h2>
<div class="outline-text-2" id="text-orgf3cc87c">
</div>
<div id="outline-container-org1469cfa" class="outline-3">
<h3 id="org1469cfa">Simulate from the NB measurement model</h3>
<div class="outline-text-3" id="text-org1469cfa">
<p>
Simulate data from the model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">simulate_nb_gamma</span>(n, p, theta, seed=0):
  np.random.seed(seed)
  <span class="org-variable-name">log_mean</span> = np.random.uniform(low=-12, high=-8, size=(1, p))
  <span class="org-variable-name">log_disp</span> = np.random.uniform(low=-6, high=0, size=(1, p))
  <span class="org-variable-name">s</span> = 1e5 * np.ones((n, 1))
  <span class="org-variable-name">lam</span> = st.gamma(a=np.exp(-log_disp), scale=np.exp(log_mean + log_disp)).rvs(size=(n, p))
  <span class="org-variable-name">u</span> = st.gamma(a=1 / theta, scale=theta).rvs(size=(n, p))
  <span class="org-variable-name">x</span> = st.poisson(s * lam * u).rvs()
  <span class="org-keyword">return</span> x, s, lam, u, log_mean, -log_disp, theta
</pre>
</div>
</div>
</div>

<div id="outline-container-org1de4fd0" class="outline-3">
<h3 id="total-var"><a id="org1de4fd0"></a>Total variance under NB measurement</h3>
<div class="outline-text-3" id="text-total-var">
<p>
Consider gene \(j\), and assume \(a = \phi^{-1}\), \(b =
   \mu^{-1}\phi^{-1}\). Then,
</p>

\begin{align}
  \E{\lambda_i} &= \mu\\
  \V[\lambda_i] &= \mu^2\phi\\
  \V[x_i] &= \E{\V[x_i \mid \lambda_i]} + \V[\E{x_i \mid \lambda_i}]\\
  &= \E{s_i \lambda_i + (s_i \lambda_i)^2 \theta} + \V[s_i \lambda_i]\\
  &= s_i \mu + s_i^2 \mu^2 (\phi + \theta + \phi\theta)
\end{align}

<p>
This result suggests a heuristic approach to characterize the profile
likelihood of the data with respect to \(\theta\). The key question is: what
does the profile likelihood look like for data consistent with \(\theta=0\)?
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> scipy.optimize <span class="org-keyword">as</span> so

<span class="org-keyword">def</span> <span class="org-function-name">_loss</span>(par, x, s, theta0):
  <span class="org-variable-name">mu</span>, <span class="org-variable-name">phi</span> = np.exp(par)
  <span class="org-variable-name">theta</span> = phi + theta0 + phi * theta0
  <span class="org-keyword">return</span> -st.nbinom(n=1 / theta, p=1 / (1 + s * np.exp(log_mu) / theta)).logpmf(x).mean()

np.random.seed(1)
<span class="org-variable-name">log_mu</span> = -10
<span class="org-variable-name">s</span> = 1e5
<span class="org-variable-name">n</span> = 100
<span class="org-variable-name">theta0</span> = 0.2

<span class="org-variable-name">fits</span> = <span class="org-builtin">dict</span>()
<span class="org-variable-name">grid</span> = np.logspace(-3, 1, 100)
<span class="org-keyword">for</span> log_phi <span class="org-keyword">in</span> (-4, -2, 0):
  <span class="org-variable-name">lam</span> = st.gamma(a=np.exp(-log_phi), scale=np.exp(log_mu + log_phi)).rvs(n)
  <span class="org-variable-name">u</span> = st.gamma(a=1 / theta0, scale=theta0).rvs(n)
  <span class="org-variable-name">x</span> = st.poisson(s * lam * u).rvs(n)
  <span class="org-variable-name">fits</span>[log_phi] = [so.minimize(_loss, x0=[log_mu, log_phi], args=(x, s, theta), method=<span class="org-string">'Nelder-Mead'</span>)
                   <span class="org-keyword">for</span> theta <span class="org-keyword">in</span> grid]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
<span class="org-keyword">for</span> i, k <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(fits):
  <span class="org-variable-name">temp</span> = n * np.array([-f.fun <span class="org-keyword">for</span> f <span class="org-keyword">in</span> fits[k]])
  plt.plot(grid, temp - temp.<span class="org-builtin">max</span>(), lw=1, c=cm(i), label=rf<span class="org-string">'$\phi$ = {np.exp(k):.2g}'</span>)
plt.axvline(x=theta0, c=<span class="org-string">'k'</span>, lw=1, ls=<span class="org-string">':'</span>)
plt.legend()
plt.xlabel(r<span class="org-string">'Measurement dispersion $\theta$'</span>)
plt.ylabel(<span class="org-string">'Diff log lik from best'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/var-heuristic.png" alt="var-heuristic.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org72a0851" class="outline-3">
<h3 id="org72a0851">VBEM algorithm for Gamma expression model</h3>
<div class="outline-text-3" id="text-org72a0851">
<p>
To estimate \(a_1, \ldots, a_p, b_1, \ldots, b_p, \theta\) from observed
data, we use a VBEM algorithm. First, introduce latent variables \(u_{ij}\)
</p>

\begin{align}
  x_{ij} \mid s_i, \lambda_{ij}, u_{ij} &\sim \Pois(s_i \lambda_{ij} u_{ij})\\
  u_{ij} \mid \theta &\sim \Gam(\theta^{-1}, \theta^{-1})\\
  \lambda_{ij} \mid a_j, b_j &\sim \Gam(a_j, b_j),
\end{align}

<p>
where the Gamma distribution is parameterized by shape and rate. It is
straightforward to show that marginalizing over \(u_{ij}\) yields the
original NB-Gamma compound model of interest. The log joint
</p>

\begin{multline}
  \ln p(x_{ij} \mid \lambda_{ij}, u_{ij}, a_j, b_j, \theta) = x_{ij} \ln (s_i \lambda_{ij} u_{ij}) - s_i \lambda_{ij} u_{ij} - \ln\Gamma(x_{ij} + 1)\\
  + (a_j - 1) \ln \lambda_{ij} - b_j \lambda_{ij} + a_j \ln b_j - \ln\Gamma(a_j) + (\theta^{-1} - 1) \ln u_{ij} - \theta^{-1} u_{ij} + \theta^{-1}\ln(\theta^{-1}) - \ln\Gamma(\theta^{-1}),
\end{multline}

<p>
and the posteriors
</p>

\begin{align}
  \ln p(\lambda_{ij} \mid x_{ij}, u_{ij}, a_j, b_j) &= (x_{ij} + a_j - 1) \ln \lambda_{ij} - (s_i u_{ij} + b_j) \lambda_{ij} + \const\\
  &= \Gam(x_{ij} + a_j, s_i u_{ij} + b_j)\\
  \ln p(u_{ij} \mid x_{ij}, \lambda_{ij}, a_j, b_j) &= (x_{ij} + \theta^{-1} - 1) \ln \lambda_{ij} - (s_i \lambda_{ij} + b_j) u_{ij} + \const\\
  &= \Gam(x_{ij} + \theta^{-1}, s_i \lambda_{ij} + b_j).
\end{align}

<p>
However, the required expectations for an EM algorithm that directly
maximizes the likelihood are non-analytic. To side-step this problem,
introduce a variational approximation
</p>

\begin{align}
  q &= \prod_{i,j} q(\lambda_{ij}) q(u_{ij})\\
  q^*(\lambda_{ij}) &\propto \exp((x_{ij} + a_j - 1) \ln \lambda_{ij} - (s_i \E{u_{ij}} + b_j) \lambda_{ij})\\
  &= \Gam(x_{ij} + a_j, s_i \E{u_{ij}} + b_j)\\
  &\triangleq \Gam(\alpha_{ij}, \beta_{ij})\\
  q^*(u_{ij}) &\propto \exp((x_{ij} + \theta^{-1} - 1) \ln u_{ij} - (s_i \E{\lambda_{ij}} + b_j) u_{ij})\\
  &= \Gam(x_{ij} + \theta^{-1}, s_i \E{\lambda_{ij}} + \theta^{-1})\\
  &\triangleq \Gam(\gamma_{ij}, \delta_{ij}).
\end{align}

<p>
The evidence lower bound
</p>

\begin{multline}
  \ell = \sum_{i, j} \left[ (x_{ij} + a_j - \alpha_{ij}) \E{\ln \lambda_{ij}} - (b_j - \beta_{ij}) \E{\lambda_{ij}} + (x_{ij} + \theta^{-1} - \gamma_{ij}) \E{\ln u_{ij}} - (\theta^{-1} - \delta_{ij}) \E{u_{ij}} - s_i \E{\lambda_{ij}} \E{u_{ij}}\right.\\
    + \left. a_j \ln b_j + \theta^{-1}\ln(\theta^{-1}) - \alpha_{ij} \ln \beta_{ij} - \gamma_{ij} \ln \delta_{ij} - \ln\Gamma(a_j) - \ln\Gamma(\theta^{-1}) + \ln\Gamma(\alpha_{ij}) + \ln\Gamma(\gamma_{ij})\right] + \const,
\end{multline}

<p>
where
</p>

\begin{align}
  \E{\lambda_{ij}} &= \alpha_{ij} / \beta_{ij}\\
  \E{\ln\lambda_{ij}} &= \psi(\alpha_{ij}) - \ln(\beta_{ij})\\
  \E{u_{ij}} &= \gamma_{ij} / \delta_{ij}\\
  \E{\ln u_{ij}} &= \psi(\gamma_{ij}) - \ln(\delta_{ij}),
\end{align}

<p>
and \(\psi\) denotes the digamma function. Then, we have analytic M step update
</p>

\begin{align}
  \frac{\partial \ell}{\partial b_j} &= \sum_{i} \frac{a_j}{b_j} - \E{\lambda_{ij}} = 0\\
  b_j &:= \frac{n a_j}{\sum_i \E{\lambda_{ij}}}
\end{align}

<p>
and Newton-Raphson partial M step updates
</p>

\begin{align}
  \eta &\triangleq \theta^{-1}\\
  \frac{\partial \ell}{\partial \eta} &= \sum_{i, j} 1 + \E{\ln u_{ij}} - \E{u_{ij}} - \psi(\eta)\\
  \frac{\partial^2 \ell}{\partial \eta^2} &= -n p \psi^{(1)}(\eta)\\
  \frac{\partial \ell}{\partial a_j} &= \sum_i \E{\ln\lambda_{ij}} + \ln b_j - \psi(a_j)\\
  \frac{\partial^2 \ell}{\partial a_j^2} &=  -n \psi^{(1)}(a_j),
\end{align}

<p>
where \(\psi^{(1)}\) denotes the trigamma function.
</p>
</div>
</div>

<div id="outline-container-org0473663" class="outline-3">
<h3 id="org0473663">Simulated example</h3>
<div class="outline-text-3" id="text-org0473663">
<p>
Fit the model to a simulated example, fixing the hyperparameters to the
ground truth values. (This only updates the variational approximation.) As a
baseline, fit a Gamma expression model to each gene assuming a Poisson
measurement model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span>, <span class="org-variable-name">s</span>, <span class="org-variable-name">lam</span>, <span class="org-variable-name">u</span>, <span class="org-variable-name">log_mean</span>, <span class="org-variable-name">log_inv_disp</span>, <span class="org-variable-name">theta</span> = simulate_nb_gamma(n=1000, p=5, theta=0.2, seed=1)
<span class="org-variable-name">par</span> = np.array([scmodes.ebpm.ebpm_gamma(x[:,j].ravel(), s.ravel()) <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(x.shape[1])])
<span class="org-variable-name">log_mean_hat</span>, <span class="org-variable-name">log_inv_disp_hat</span>, <span class="org-variable-name">log_meas_disp_hat</span>, <span class="org-variable-name">alpha</span>, <span class="org-variable-name">beta</span>, <span class="org-variable-name">gamma</span>, <span class="org-variable-name">delta</span>, <span class="org-variable-name">elbo</span> = scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=np.hstack([np.exp(log_inv_disp).ravel(), np.exp(-log_mean + log_inv_disp).ravel(), theta]),
  tol=1e-5,
  extrapolate=<span class="org-constant">False</span>,
  fix_g=<span class="org-constant">True</span>,
  fix_theta=<span class="org-constant">True</span>)
</pre>
</div>

<p>
Make sure we didn&rsquo;t mess up the parameterization.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 5, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(8, 2)

<span class="org-keyword">for</span> i, a <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(ax):
  <span class="org-variable-name">y</span> = np.arange(x[:,i].<span class="org-builtin">max</span>() + 1)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Poisson measurement =&gt; NB observation</span>
  <span class="org-variable-name">pmf</span> = <span class="org-builtin">dict</span>()
  <span class="org-variable-name">pmf</span>[<span class="org-string">'Poisson'</span>] = st.nbinom(n=np.exp(par[i,1]), p=1 / (1 + (s * np.exp(par[i,0] - par[i,1])))).pmf(y).mean(axis=0)
  <span class="org-comment-delimiter"># </span><span class="org-comment">NB measurement =&gt; Monte Carlo integral</span>
  <span class="org-variable-name">n_samples</span> = 1000
  <span class="org-variable-name">Ghat</span> = st.gamma(a=np.exp(log_inv_disp_hat[:,i]), scale=np.exp(log_mean_hat[:,i] - log_inv_disp_hat[:,i]))
  <span class="org-variable-name">temp</span> = Ghat.rvs(size=(n_samples, y.shape[0], 1))
  <span class="org-variable-name">pmf</span>[rf<span class="org-string">'NB ($\hat\theta$ = {np.exp(log_meas_disp_hat):.2g})'</span>] = st.nbinom(n=np.exp(-log_meas_disp_hat), p=1 / (1 + s[0] * temp * np.exp(log_meas_disp_hat))).pmf(y.reshape(-1, 1)).mean(axis=0)

  ax[i].hist(x[:,i], bins=y, color=<span class="org-string">'0.7'</span>, density=<span class="org-constant">True</span>)
  <span class="org-keyword">for</span> j, k <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(pmf):
    ax[i].plot(y + .5, pmf[k], c=cm(j), lw=1, label=k)
  ax[i].set_title(f<span class="org-string">'Gene {i+1}'</span>)
  ax[i].set_xlim(0, x[:,i].<span class="org-builtin">max</span>())

ax[0].set_ylabel(<span class="org-string">'Density'</span>)
ax[-1].legend(title=<span class="org-string">'Measurement model'</span>, frameon=<span class="org-constant">False</span>, bbox_to_anchor=(1, .5), loc=<span class="org-string">'center left'</span>)
<span class="org-variable-name">a</span> = fig.add_subplot(111, frameon=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_xlabel(<span class="org-string">'Number of molecules'</span>, labelpad=16)
fig.tight_layout(pad=0.5)
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex.png" alt="sim-ex.png">
</p>
</div>

<p>
Compare the true posterior against the variational approximation.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(5, 2.5)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.set_aspect(<span class="org-string">'equal'</span>, adjustable=<span class="org-string">'datalim'</span>)

ax[0].set_xscale(<span class="org-string">'log'</span>)
ax[0].set_yscale(<span class="org-string">'log'</span>)
ax[0].scatter(((x + np.exp(log_inv_disp)) / (s * u + np.exp(log_inv_disp - log_mean))).ravel(), (alpha / beta).ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
<span class="org-variable-name">lim</span> = ax[0].get_xlim()
ax[0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(r<span class="org-string">'$\mathrm{E}[\lambda \mid x, u]$'</span>)
ax[0].set_ylabel(r<span class="org-string">'$\mathrm{E}_q[\lambda]$'</span>)

ax[1].scatter(((x + theta) / (s * lam + theta)), (gamma / delta).ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
<span class="org-variable-name">lim</span> = ax[1].get_xlim()
ax[1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(r<span class="org-string">'$\mathrm{E}[u \mid x, \lambda]$'</span>)
ax[1].set_ylabel(r<span class="org-string">'$\mathrm{E}_q[u]$'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex2.png" alt="sim-ex2.png">
</p>
</div>

<p>
Now, fit the model initialized at the ground truth hyperparameters, fixing
\(\theta\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit0</span> = scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=np.hstack([np.exp(log_inv_disp).ravel(), np.exp(-log_mean + log_inv_disp).ravel(), theta]),
  tol=1e-4,
  max_iters=300_000,
  extrapolate=<span class="org-constant">True</span>,
  fix_g=<span class="org-constant">False</span>,
  fix_theta=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit1</span> = scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=np.hstack([np.exp(log_inv_disp).ravel(), np.exp(-log_mean + log_inv_disp).ravel(), theta]),
  tol=1e-5,
  max_iters=300_000,
  extrapolate=<span class="org-constant">True</span>,
  fix_g=<span class="org-constant">False</span>,
  fix_theta=<span class="org-constant">True</span>)
<span class="org-keyword">with</span> <span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/modes/ebnbm-sim-ex-1e-5.pkl'</span>, <span class="org-string">'wb'</span>) <span class="org-keyword">as</span> f:
  pickle.dump(fit1, f)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">with</span> <span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/modes/ebnbm-sim-ex-1e-5.pkl'</span>, <span class="org-string">'rb'</span>) <span class="org-keyword">as</span> f:
  <span class="org-variable-name">log_mean_hat</span>, <span class="org-variable-name">log_inv_disp_hat</span>, <span class="org-variable-name">log_meas_disp_hat</span>, <span class="org-variable-name">alpha</span>, <span class="org-variable-name">beta</span>, <span class="org-variable-name">gamma</span>, <span class="org-variable-name">delta</span>, <span class="org-variable-name">elbo</span> = pickle.load(f)
</pre>
</div>

<p>
Plot the fitted observation models against the observed data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 5, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(8, 2)

<span class="org-keyword">for</span> i, a <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(ax):
  <span class="org-variable-name">y</span> = np.arange(x[:,i].<span class="org-builtin">max</span>() + 1)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Poisson measurement =&gt; NB observation</span>
  <span class="org-variable-name">pmf</span> = <span class="org-builtin">dict</span>()
  <span class="org-variable-name">pmf</span>[<span class="org-string">'Poisson'</span>] = st.nbinom(n=np.exp(par[i,1]), p=1 / (1 + (s * np.exp(par[i,0] - par[i,1])))).pmf(y).mean(axis=0)
  <span class="org-comment-delimiter"># </span><span class="org-comment">NB measurement =&gt; Monte Carlo integral</span>
  <span class="org-variable-name">n_samples</span> = 1000
  <span class="org-variable-name">Ghat</span> = st.gamma(a=np.exp(log_inv_disp_hat[:,i]), scale=np.exp(log_mean_hat[:,i] - log_inv_disp_hat[:,i]))
  <span class="org-variable-name">temp</span> = Ghat.rvs(size=(n_samples, y.shape[0], 1))
  <span class="org-variable-name">pmf</span>[rf<span class="org-string">'NB ($\hat\theta$ = {np.exp(log_meas_disp_hat):.2g})'</span>] = st.nbinom(n=np.exp(-log_meas_disp_hat), p=1 / (1 + s[0] * temp * np.exp(log_meas_disp_hat))).pmf(y.reshape(-1, 1)).mean(axis=0)

  ax[i].hist(x[:,i], bins=y, color=<span class="org-string">'0.7'</span>, density=<span class="org-constant">True</span>)
  <span class="org-keyword">for</span> j, k <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(pmf):
    ax[i].plot(y + .5, pmf[k], c=cm(j), lw=1, label=k)
  ax[i].set_title(f<span class="org-string">'Gene {i+1}'</span>)
  ax[i].set_xlim(0, x[:,i].<span class="org-builtin">max</span>())

ax[0].set_ylabel(<span class="org-string">'Density'</span>)
ax[-1].legend(title=<span class="org-string">'Measurement model'</span>, frameon=<span class="org-constant">False</span>, bbox_to_anchor=(1, .5), loc=<span class="org-string">'center left'</span>)
<span class="org-variable-name">a</span> = fig.add_subplot(111, frameon=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_xlabel(<span class="org-string">'Number of molecules'</span>, labelpad=16)
fig.tight_layout(pad=0.5)
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex3.png" alt="sim-ex3.png">
</p>
</div>

<p>
Compare the estimated expression models against the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(5, 2.5)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.set_aspect(<span class="org-string">'equal'</span>, <span class="org-string">'datalim'</span>)
ax[0].scatter(log_mean, log_mean_hat, s=4, c=<span class="org-string">'k'</span>)
<span class="org-variable-name">lim</span> = ax[0].get_xlim()
ax[0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(<span class="org-string">'$\ln(\mu)$'</span>)
ax[0].set_ylabel(<span class="org-string">'$\ln(\hat\mu)$'</span>)
ax[1].scatter(log_inv_disp, log_inv_disp_hat, s=4, c=<span class="org-string">'k'</span>)
<span class="org-variable-name">lim</span> = ax[1].get_xlim()
ax[1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(<span class="org-string">'$\ln(\phi)$'</span>)
ax[1].set_ylabel(<span class="org-string">'$\ln(\hat\phi)$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex4.png" alt="sim-ex4.png">
</p>
</div>

<p>
Now fit the model, fixing \(\theta\) to the ground truth, and initializing
the expression models at the MLE of a Gamma expression model assuming a
Poisson measurement model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">par</span> = np.array([scmodes.ebpm.ebpm_gamma(x[:,j], s.ravel()) <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(x.shape[1])])
<span class="org-variable-name">init</span> = np.hstack([np.exp(par[:,1]), np.exp(par[:,1] - par[:,0]), theta])
<span class="org-variable-name">fit2</span> = scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=init,
  tol=1e-5,
  max_iters=300_000,
  extrapolate=<span class="org-constant">True</span>,
  fix_g=<span class="org-constant">False</span>,
  fix_theta=<span class="org-constant">True</span>)
<span class="org-keyword">with</span> <span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/modes/ebnbm-sim-ex-1e-5-pois-init.pkl'</span>, <span class="org-string">'wb'</span>) <span class="org-keyword">as</span> f:
  pickle.dump(fit2, f)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">with</span> <span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/modes/ebnbm-sim-ex-1e-5-pois-init.pkl'</span>, <span class="org-string">'rb'</span>) <span class="org-keyword">as</span> f:
  <span class="org-variable-name">log_mean_hat</span>, <span class="org-variable-name">log_inv_disp_hat</span>, <span class="org-variable-name">log_meas_disp_hat</span>, <span class="org-variable-name">alpha</span>, <span class="org-variable-name">beta</span>, <span class="org-variable-name">gamma</span>, <span class="org-variable-name">delta</span>, <span class="org-variable-name">elbo</span> = pickle.load(f)
</pre>
</div>

<p>
Compare the fitted expression models against the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(5, 2.5)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.set_aspect(<span class="org-string">'equal'</span>, <span class="org-string">'datalim'</span>)
ax[0].scatter(log_mean, par[:,0], s=16, c=<span class="org-string">'r'</span>, marker=<span class="org-string">'x'</span>, label=<span class="org-string">'Initialization'</span>)
ax[0].scatter(log_mean, log_mean_hat, s=16, c=<span class="org-string">'k'</span>, marker=<span class="org-string">'+'</span>, label=<span class="org-string">'Estimate'</span>)
<span class="org-variable-name">lim</span> = ax[0].get_xlim()
ax[0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].legend(handletextpad=0, frameon=<span class="org-constant">False</span>)
ax[0].set_xlabel(<span class="org-string">'$\ln(\mu)$'</span>)
ax[0].set_ylabel(<span class="org-string">'$\ln(\hat\mu)$'</span>)

ax[1].scatter(log_inv_disp, par[:,1], s=16, c=<span class="org-string">'r'</span>, marker=<span class="org-string">'x'</span>, label=<span class="org-string">'Initialization'</span>)
ax[1].scatter(log_inv_disp, log_inv_disp_hat, s=16, c=<span class="org-string">'k'</span>, marker=<span class="org-string">'+'</span>, label=<span class="org-string">'Estimate'</span>)
<span class="org-variable-name">lim</span> = ax[1].get_ylim()
ax[1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(<span class="org-string">'$\ln(\phi)$'</span>)
ax[1].set_ylabel(<span class="org-string">'$\ln(\hat\phi)$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex5.png" alt="sim-ex5.png">
</p>
</div>

<p>
Compute the ELBO as a function of \(\theta\).
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org558c104"><span class="org-keyword">def</span> <span class="org-function-name">map_ebnbm_gamma</span>(x, s, grid):
  <span class="org-keyword">print</span>(<span class="org-string">'initializing'</span>)
  <span class="org-variable-name">par</span> = np.array([scmodes.ebpm.ebpm_gamma(x[:,j], s.ravel()) <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(x.shape[1])])
  <span class="org-comment-delimiter"># </span><span class="org-comment">exp(20) is finite and large enough</span>
  <span class="org-variable-name">par</span> = np.ma.masked_invalid(par).filled(20)
  <span class="org-variable-name">fits</span> = []
  <span class="org-keyword">for</span> theta <span class="org-keyword">in</span> grid:
    <span class="org-keyword">print</span>(f<span class="org-string">'fitting theta={theta:.3g}'</span>)
    <span class="org-variable-name">fit</span> = scmodes.ebnbm.ebnbm_gamma(
      x,
      s,
      init=np.hstack([np.exp(par[:,1]), np.exp(par[:,1] - par[:,0]), theta]),
      tol=1e-4,
      max_iters=100_000,
      extrapolate=<span class="org-constant">True</span>,
      fix_g=<span class="org-constant">False</span>,
      fix_theta=<span class="org-constant">True</span>)
    <span class="org-comment-delimiter"># </span><span class="org-comment">Warm start</span>
    <span class="org-variable-name">par</span> = np.vstack(fit[:2]).T
    fits.append(fit)
  <span class="org-keyword">return</span> fits
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">grid</span> = np.logspace(-3, 0, 40)
<span class="org-variable-name">fits</span> = map_ebnbm_gamma(x, s, grid)
<span class="org-variable-name">elbo</span> = np.array([f[-1] <span class="org-keyword">for</span> f <span class="org-keyword">in</span> fits])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
plt.plot(grid, elbo, lw=1, c=<span class="org-string">'k'</span>)
plt.axvline(x=0.2, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
plt.xticks(np.logspace(-3, 0, 4))
plt.xlabel(r<span class="org-string">'Measurement dispersion $\theta$'</span>)
plt.ylabel(<span class="org-string">'ELBO'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-elbo.png" alt="sim-elbo.png">
</p>
</div>

<p>
Find the local minimum in the ELBO.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">idx</span> = np.where((np.sign(np.diff(elbo)) + 1) / 2)
grid[idx][0], elbo[idx][0]
</pre>
</div>

<pre class="example">
(0.05878016072274915, -9681.893026800943)

</pre>

<p>
Try running VBEM to stricter tolerance for this choice of \(\theta\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">par</span> = np.array([scmodes.ebpm.ebpm_gamma(x[:,j], s.ravel()) <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(x.shape[1])])
<span class="org-variable-name">init</span> = np.hstack([np.exp(par[:,1]), np.exp(par[:,1] - par[:,0]), grid[idx][0]])
<span class="org-variable-name">fit3</span> = scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=init,
  tol=1e-6,
  max_iters=300_000,
  extrapolate=<span class="org-constant">True</span>,
  fix_g=<span class="org-constant">False</span>,
  fix_theta=<span class="org-constant">True</span>)
fit3[-1]
</pre>
</div>

<pre class="example">
-9681.60485796223

</pre>

<p>
Try initializing VBEM at the ground truth for this choice of \(\theta\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">init</span> = np.hstack([np.exp(log_inv_disp).ravel(), np.exp(-log_mean + log_inv_disp).ravel(), grid[idx][0]])
<span class="org-variable-name">fit4</span> = scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=init,
  tol=1e-6,
  max_iters=300_000,
  extrapolate=<span class="org-constant">True</span>,
  fix_g=<span class="org-constant">False</span>,
  fix_theta=<span class="org-constant">True</span>)
fit4[-1]
</pre>
</div>

<pre class="example">
-9718.192640132213

</pre>

<p>
Look at what&rsquo;s happening for small \(\theta\), by comparing the estimated
expression models.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = colorcet.cm[<span class="org-string">'bmy'</span>]
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(6, 2.5)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.set_aspect(<span class="org-string">'equal'</span>, <span class="org-string">'datalim'</span>)

<span class="org-keyword">for</span> theta, fit <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(grid, fits):
  <span class="org-variable-name">c</span> = (np.log(theta) - np.log(1e-3)) / (-np.log(1e-3))
  ax[0].scatter(log_mean, fit[0], s=4, c=np.array(cm(c)).reshape(1, -1))
  ax[1].scatter(log_inv_disp, fit[1], s=4, c=np.array(cm(c)).reshape(1, -1))

<span class="org-variable-name">lim</span> = ax[0].get_xlim()
ax[0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(<span class="org-string">'$\ln(\mu)$'</span>)
ax[0].set_ylabel(<span class="org-string">'$\ln(\hat\mu)$'</span>)

<span class="org-variable-name">lim</span> = ax[1].get_ylim()
ax[1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(<span class="org-string">'$\ln(\phi)$'</span>)
ax[1].set_ylabel(<span class="org-string">'$\ln(\hat\phi)$'</span>)

<span class="org-variable-name">cb</span> = plt.colorbar(matplotlib.cm.ScalarMappable(matplotlib.colors.LogNorm(vmin=1e-3, vmax=1), cmap=cm),
                  fraction=0.05, shrink=0.5)
cb.set_label(r<span class="org-string">'Dispersion $\theta$'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex6.png" alt="sim-ex6.png">
</p>
</div>

<p>
Compare the estimated observation models, focusing on simulated genes 1 and 2.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = colorcet.cm[<span class="org-string">'fire'</span>]
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(8, 3)

<span class="org-keyword">for</span> i, a <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(ax):
  <span class="org-variable-name">y</span> = np.arange(x[:,i].<span class="org-builtin">max</span>() + 1)
  <span class="org-comment-delimiter"># </span><span class="org-comment">NB measurement =&gt; Monte Carlo integral</span>
  <span class="org-variable-name">pmf</span> = <span class="org-builtin">dict</span>()
  <span class="org-variable-name">n_samples</span> = 5000
  <span class="org-variable-name">query</span> = (0, 13, 23, 26, 30, 35)
  <span class="org-keyword">for</span> j <span class="org-keyword">in</span> query:
    <span class="org-variable-name">Ghat</span> = st.gamma(a=np.exp(fits[j][1][:,i]), scale=np.exp(fits[j][0][:,i] - fits[j][1][:,i]))
    <span class="org-variable-name">temp</span> = Ghat.rvs(size=(n_samples, y.shape[0], 1))
    pmf[rf<span class="org-string">'NB ($\theta$ = {grid[j]:.2g})'</span>] = st.nbinom(n=1 / grid[j], p=1 / (1 + s[0] * temp * grid[j])).pmf(y.reshape(-1, 1)).mean(axis=0)

  ax[i].hist(x[:,i], bins=y, color=<span class="org-string">'0.7'</span>, density=<span class="org-constant">True</span>)
  <span class="org-keyword">for</span> j, k <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(query, pmf):
    <span class="org-variable-name">z</span> = (np.log(grid[j]) - np.log(1e-3)) / (-np.log(1e-3))
    ax[i].plot(y + .5, pmf[k], c=cm(z), lw=1, label=k)
  ax[i].set_title(f<span class="org-string">'Gene {i+1}'</span>)
  ax[i].set_xlim(0, x[:,i].<span class="org-builtin">max</span>())

ax[0].set_ylabel(<span class="org-string">'Density'</span>)
ax[-1].legend(title=<span class="org-string">'Measurement model'</span>, frameon=<span class="org-constant">False</span>, bbox_to_anchor=(1, .5), loc=<span class="org-string">'center left'</span>)
<span class="org-variable-name">a</span> = fig.add_subplot(111, frameon=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_xlabel(<span class="org-string">'Number of molecules'</span>, labelpad=24)
fig.tight_layout(pad=0.5)
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-ex7.png" alt="sim-ex7.png">
</p>
</div>

<p>
Try again for a different simulated data set.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">theta0</span> = 0.5
<span class="org-variable-name">x</span>, <span class="org-variable-name">s</span>, <span class="org-variable-name">lam</span>, <span class="org-variable-name">u</span>, <span class="org-variable-name">log_mean</span>, <span class="org-variable-name">log_inv_disp</span>, <span class="org-variable-name">theta</span> = simulate_nb_gamma(n=100, p=5, theta=theta0, seed=10)
<span class="org-variable-name">grid</span> = np.logspace(-3, 0, 100)
<span class="org-variable-name">fits</span> = map_ebnbm_gamma(x, s, grid)
<span class="org-variable-name">elbo</span> = np.array([f[-1] <span class="org-keyword">for</span> f <span class="org-keyword">in</span> fits])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
plt.plot(grid, elbo, lw=1, c=<span class="org-string">'k'</span>)
plt.axvline(x=theta0, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
plt.xticks(np.logspace(-3, 0, 4))
plt.xlabel(r<span class="org-string">'Measurement dispersion $\theta$'</span>)
plt.ylabel(<span class="org-string">'ELBO'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-elbo-theta=0.5-seed=10.png" alt="sim-elbo-theta=0.5-seed=10.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">theta0</span> = 0.1
<span class="org-variable-name">x</span>, <span class="org-variable-name">s</span>, <span class="org-variable-name">lam</span>, <span class="org-variable-name">u</span>, <span class="org-variable-name">log_mean</span>, <span class="org-variable-name">log_inv_disp</span>, <span class="org-variable-name">theta</span> = simulate_nb_gamma(n=100, p=5, theta=theta0, seed=10)
<span class="org-variable-name">grid</span> = np.logspace(-3, 0, 100)
<span class="org-variable-name">fits</span> = map_ebnbm_gamma(x, s, grid)
<span class="org-variable-name">elbo</span> = np.array([f[-1] <span class="org-keyword">for</span> f <span class="org-keyword">in</span> fits])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
plt.plot(grid, elbo, lw=1, c=<span class="org-string">'k'</span>)
plt.axvline(x=theta0, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
plt.xticks(np.logspace(-3, 0, 4))
plt.xlabel(r<span class="org-string">'Measurement dispersion $\theta$'</span>)
plt.ylabel(<span class="org-string">'ELBO'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/sim-elbo-theta=0.1-seed=10.png" alt="sim-elbo-theta=0.1-seed=10.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org9a061c5" class="outline-3">
<h3 id="org9a061c5">Application to control data</h3>
<div class="outline-text-3" id="text-org9a061c5">
<p>
Fit the model to each control data set.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orga8877d5"><span class="org-keyword">def</span> <span class="org-function-name">_init</span>(j, x, s):
  <span class="org-keyword">return</span> scmodes.ebpm.ebpm_gamma(x[:,j].ravel(), s.ravel())

<span class="org-keyword">def</span> <span class="org-function-name">_fit</span>(theta, x, s, par):
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: ebpm_gamma can return np.inf is data is consistent with Poisson</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">observation model</span>
  <span class="org-variable-name">init</span> = np.ma.masked_invalid(np.hstack([
    np.exp(par[:,1]),
    np.exp(par[:,1] - par[:,0]),
    1e-3])).filled(1e6)
  <span class="org-keyword">return</span> scmodes.ebnbm.ebnbm_gamma(
    x,
    s,
    init=init,
    tol=1e-3,
    max_iters=100_000,
    extrapolate=<span class="org-constant">True</span>,
    fix_g=<span class="org-constant">False</span>,
    fix_theta=<span class="org-constant">True</span>)

<span class="org-variable-name">tasks</span> = control
<span class="org-variable-name">d</span> = tasks[<span class="org-builtin">int</span>(os.environ[<span class="org-string">'SLURM_ARRAY_TASK_ID'</span>])]
<span class="org-keyword">with</span> mp.Pool() <span class="org-keyword">as</span> pool:
  <span class="org-variable-name">dat</span> = data[d]()
  <span class="org-variable-name">x</span> = dat.X.A
  <span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
  <span class="org-variable-name">par</span> = pool.<span class="org-builtin">map</span>(ft.partial(_init, x=x, s=s), <span class="org-builtin">range</span>(x.shape[1]))
  <span class="org-variable-name">par</span> = np.array(par)
  <span class="org-variable-name">grid</span> = np.logspace(-3, 1, 20)
  <span class="org-variable-name">fits</span> = pool.<span class="org-builtin">map</span>(ft.partial(_fit, x=x, s=s, par=par), grid)
<span class="org-keyword">with</span> <span class="org-builtin">open</span>(f<span class="org-string">'/scratch/midway2/aksarkar/modes/ebnbm-{d}.pkl'</span>, <span class="org-string">'wb'</span>) <span class="org-keyword">as</span> f:
  pickle.dump(<span class="org-builtin">dict</span>(<span class="org-builtin">zip</span>(grid, fits)), f)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=gpu2 --gres=gpu:1 -w midway2-gpu05 -n1 -c28 --exclusive --time=24:00:00 -a 2
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">import multiprocessing as mp</span>
<span class="org-sh-heredoc">import pickle</span>
<span class="org-sh-heredoc">import os</span>
<span class="org-sh-heredoc">&lt;&lt;data&gt;&gt;</span>
<span class="org-sh-heredoc">&lt;&lt;fit&gt;&gt;</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<p>
Read the fitted models.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">elbo</span> = <span class="org-builtin">dict</span>()
<span class="org-keyword">for</span> k <span class="org-keyword">in</span> data:
  <span class="org-keyword">if</span> k <span class="org-keyword">in</span> control[:3]:
    <span class="org-keyword">with</span> <span class="org-builtin">open</span>(f<span class="org-string">'/scratch/midway2/aksarkar/modes/ebnbm-{k}.pkl'</span>, <span class="org-string">'rb'</span>) <span class="org-keyword">as</span> f:
      <span class="org-variable-name">fits</span> = pickle.load(f)
      <span class="org-variable-name">elbo</span>[k] = pd.Series({theta: fits[theta][-1] <span class="org-keyword">for</span> theta <span class="org-keyword">in</span> fits})
<span class="org-variable-name">elbo</span> = pd.DataFrame(elbo)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
plt.gcf().set_size_inches(3.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
<span class="org-keyword">for</span> i, k <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(elbo):
  plt.plot(elbo.index, elbo[k], lw=1, label=k, c=cm(i))
plt.legend(title=<span class="org-string">'Dataset'</span>, frameon=<span class="org-constant">False</span>, loc=<span class="org-string">'center left'</span>, bbox_to_anchor=(1, .5))
plt.xticks(np.logspace(-3, 1, 5))
plt.xlabel(r<span class="org-string">'Measurement dispersion'</span>)
plt.ylabel(<span class="org-string">'ELBO'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/ebnbm.org/ebnbm-control.png" alt="ebnbm-control.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = data[<span class="org-string">'indrops'</span>]()
<span class="org-variable-name">x</span> = dat.X.A
<span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">par</span> = np.array([scmodes.ebpm.ebpm_gamma(x[:,j].ravel(), s.ravel()) <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(x.shape[1])])
<span class="org-variable-name">init</span> = np.ma.masked_invalid(np.hstack([
  np.exp(par[:,1]),
  np.exp(par[:,1] - par[:,0]),
  1e-3])).filled(1e6)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">scmodes.ebnbm.ebnbm_gamma(
  x,
  s,
  init=init,
  tol=1e-3,
  max_iters=10_000,
  extrapolate=<span class="org-constant">True</span>,
  fix_g=<span class="org-constant">False</span>,
  fix_theta=<span class="org-constant">True</span>)
</pre>
</div>

<pre class="example">
(array([[ -7.68382635,  -1.5705429 ,  -4.58972578,  -2.63851718,
-5.21957773,  -9.95775709,  -9.81933889,  -9.08314382,
-10.51619082,  -2.35643432,  -7.77202749,  -6.11786917,
-10.31275327,  -7.21591208,  -9.41571775,  -2.35630979,
-8.37087558,  -8.41229882,  -7.08600131,  -2.35635002,
-9.93933094,  -9.74746508,  -4.9705232 ,  -5.18101723,
-7.37724959,  -3.63488734, -10.34277823,  -8.36730388,
-7.81897768,  -8.92658867, -10.22498517,  -9.87807411,
-8.79815753,  -5.61995968, -10.17145429,  -6.77873833,
-9.85820406,  -9.60490723,  -7.47988098, -10.71682089,
-1.84622738,  -9.34387974,  -6.0342135 ,  -9.15560746,
-7.97769752,  -7.36090524, -10.67601457,  -8.77269377,
-9.26641854,  -2.35626478,  -8.55696946,  -5.74014758,
-6.39954691,  -1.60083926,  -9.51831321,  -9.78311964,
-7.9369963 ,  -8.40643658,  -4.66739956, -10.47866198,
-5.06157435,  -6.73060607,  -2.99941656,  -6.18652123,
-9.71459998, -10.67520539,  -9.491491  ,  -9.2356603 ,
-1.86246841,  -6.50037837,  -9.24566254,  -4.01088253,
-10.28286967,  -8.61689711,  -2.35654768,  -9.33359859,
-7.85608109,  -5.03634943,  -8.94335001,  -9.02204987,
-9.63860936,  -9.23410296, -11.40453947,  -8.54985618,
-8.29251574,  -8.71606401,  -7.19087004,  -8.64454098,
-9.11852604,  -7.06693715,  -9.40317986,  -7.87494295,
-3.95760172,  -5.95802193,  -7.92387825,  -6.62701893,
-7.22664171,  -7.78497944,  -7.14075238,  -8.09898103,
-7.24823516,  -6.40236003,  -7.50341165]]),
array([[ 2.03922743e+00,  5.76706664e+00,  4.34078287e+00,
5.46514384e+00,  3.93918688e+00,  7.07716330e-01,
7.36383472e-01,  5.39368052e-01,  8.05801054e-06,
1.38155106e+01,  1.90471782e+00,  3.07694138e+00,
4.81909012e-01,  2.46797791e+00,  8.99334057e-01,
1.38155106e+01,  1.78343462e+00,  3.84079404e-01,
2.82732315e+00,  1.38155106e+01,  5.59378079e-01,
4.29143607e-01,  3.90037695e+00,  3.53860787e+00,
2.41609955e+00,  4.11675897e+00,  4.37803765e-01,
1.97265392e+00,  1.79670777e+00,  1.74171688e+00,
5.53525082e-01,  2.89913625e-01,  1.48547964e+00,
3.28351554e+00,  1.07205457e+00,  2.63601544e+00,
6.72554560e-01,  1.48582461e+00,  2.28684609e+00,
2.48423873e-01,  4.79952530e+00,  1.47007182e+00,
2.90990838e+00,  8.98320814e-01,  1.62996172e+00,
2.13592621e+00, -1.16889209e-04,  1.84761683e+00,
1.42729438e+00,  1.38155106e+01,  1.68000304e+00,
3.28910435e+00,  2.77248656e+00,  6.28424480e+00,
9.70176005e-01,  4.63133899e-02,  1.45622153e+00,
1.71715066e+00,  4.22357888e+00, -9.62778629e-04,
3.88837294e+00,  3.08437127e+00,  5.29905609e+00,
3.16539814e+00,  6.16619614e-01, -1.08585424e-03,
7.50459167e-01,  7.70626743e-01,  5.82929406e+00,
2.71937828e+00,  7.30230007e-01,  4.50146543e+00,
5.01365615e-01,  1.27335250e+00,  1.38155106e+01,
2.83514714e-01,  2.35211647e+00,  3.92533158e+00,
4.12571204e-01,  1.32810383e+00,  1.71989517e-04,
6.77370876e-01, -2.69873002e+00,  3.32786554e-01,
1.93832479e+00,  1.36946837e+00,  2.54074591e+00,
1.64351009e+00,  8.09048289e-01,  2.62050499e+00,
1.05433089e+00,  1.80842790e+00,  4.64728589e+00,
3.28120756e+00,  2.42432625e+00,  2.84244306e+00,
2.35615143e+00,  1.81219046e+00,  2.00685084e+00,
1.84177346e+00,  2.38104267e+00,  3.03714986e+00,
2.18607826e+00]]),
-6.907755278982137,
array([[  8.68466997, 498.59885645,  83.76761507, ...,  10.81617468,
21.84574527,   9.90024013],
[ 11.68466997, 565.59885645,  94.76761507, ...,  11.81617468,
25.84574527,   9.90024013],
[ 10.68466997, 563.59885645,  86.76761507, ...,  10.81617468,
20.84574527,   9.90024013],
...,
[  7.68466997, 551.59885645,  84.76761507, ...,  11.81617468,
22.84574527,   8.90024013],
[  8.68466997, 562.59885645,  86.76761507, ...,  14.81617468,
21.84574527,   8.90024013],
[  8.68466997, 537.59885645,  93.76761507, ...,  11.81617468,
20.84574527,   9.90024013]]),
array([[17638.80586169,  2468.34020627,  8497.00879257, ...,
16143.01716081, 13515.14249644, 17087.60717035],
[17994.38181152,  2815.00152311,  8856.44139851, ...,
16495.7050647 , 13870.97171612, 17439.52351373],
[17909.05257597,  2740.66801049,  8764.7824871 , ...,
16410.64783482, 13781.42681954, 17355.55470231],
...,
[17819.75853656,  2658.18785377,  8677.83532918, ...,
16325.81953106, 13697.7741546 , 17268.53091062],
[17999.78521366,  2820.93333506,  8856.59341879, ...,
16508.28947163, 13875.26899424, 17447.31653412],
[17852.80705273,  2678.15200432,  8718.35073896, ...,
16357.80071833, 13727.61134712, 17301.57108267]]),
array([[1001., 1179., 1007., ..., 1000., 1001., 1001.],
[1004., 1246., 1018., ..., 1001., 1005., 1001.],
[1003., 1244., 1010., ..., 1000., 1000., 1001.],
...,
[1000., 1232., 1008., ..., 1001., 1002., 1000.],
[1001., 1243., 1010., ..., 1004., 1001., 1000.],
[1001., 1218., 1017., ..., 1001., 1000., 1001.]]),
array([[1000.46281987, 1189.87776639, 1009.26697384, ..., 1000.62982057,
1001.51940688, 1000.54461843],
[1000.8389615 , 1259.59265618, 1013.82493861, ..., 1000.92548319,
1002.40738022, 1000.73345526],
[1000.72070151, 1248.41659624, 1011.9586857 , ..., 1000.79618667,
1001.82721721, 1000.68908717],
...,
[1000.48385615, 1232.82550029, 1010.96002177, ..., 1000.81207243,
1001.87132054, 1000.57828135],
[1000.62771614, 1259.4677099 , 1012.74583374, ..., 1001.16764631,
1002.04834332, 1000.66366724],
[1000.56137442, 1231.64819597, 1012.41150202, ..., 1000.83360018,
1001.75237989, 1000.66033755]]),
-549542.3630526108)
</pre>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2020-09-05 Sat 13:56</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
