<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-07-25 Sat 16:41 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Comparison of fitted values</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="css/bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="css/supp.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Comparison of fitted values</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org082644d">Introduction</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#orgf782be7">Results</a>
<ul>
<li><a href="#org296c455">Datasets</a></li>
<li><a href="#b-cells">B cells</a></li>
<li><a href="#org4075a13">T cells</a></li>
<li><a href="#org4757b63">iPSCs</a></li>
<li><a href="#orgfd759d0">T cell/B cell</a></li>
<li><a href="#orga214153">PBMC</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org082644d" class="outline-2">
<h2 id="org082644d">Introduction</h2>
<div class="outline-text-2" id="text-org082644d">
<p>
We previously found that NMF, GLM-PCA, and PVAE all had similar average
performance on a <a href="lra.html">binomial thinning benchmark</a>. Here, we
investigate the per-observation performance of these methods.
</p>
</div>
</div>

<div id="outline-container-org782386a" class="outline-2">
<h2 id="setup"><a id="org782386a"></a>Setup</h2>
<div class="outline-text-2" id="text-setup">
<div class="org-src-container">
<pre class="src src-ipython" id="org4264c3d"><span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> pandas <span class="org-keyword">as</span> pd
<span class="org-keyword">import</span> scipy.stats <span class="org-keyword">as</span> st
<span class="org-keyword">import</span> scmodes
<span class="org-keyword">import</span> torch
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'figure.facecolor'</span>] = <span class="org-string">'w'</span>
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'font.family'</span>] = <span class="org-string">'Nimbus Sans'</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf782be7" class="outline-2">
<h2 id="orgf782be7">Results</h2>
<div class="outline-text-2" id="text-orgf782be7">
</div>
<div id="outline-container-org296c455" class="outline-3">
<h3 id="org296c455">Datasets</h3>
<div class="outline-text-3" id="text-org296c455">
<p>
Follow the data processing for the <a href="lra.html#org42bd0a9">Poisson
thinning analysis</a>.
</p>
</div>
</div>

<div id="outline-container-org6844b70" class="outline-3">
<h3 id="b-cells"><a id="org6844b70"></a>B cells</h3>
<div class="outline-text-3" id="text-b-cells">
<p>
Split the data into training and validation sets using binomial thinning, then fit
NMF, GLMPCA, and PVAE.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">Important: this implicitly sets the random seed</span>
<span class="org-variable-name">x</span> = data[<span class="org-string">'b_cells'</span>]()
<span class="org-variable-name">train</span>, <span class="org-variable-name">test</span> = scmodes.benchmark.train_test_split(x)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train'</span>, train.values)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-test'</span>, test.values)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=broadwl -n1 --mem=8G --time=24:00:00
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')</span>
<span class="org-sh-heredoc">l, f, _ = scmodes.lra.nmf(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam0 = l @ f.T</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nmf-lam', lam0)</span>

<span class="org-sh-heredoc">l, f, _ = scmodes.lra.glmpca(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam1 = np.exp(l @ f.T)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-glmpca-lam', lam1)</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')</span>
<span class="org-sh-heredoc">xt = torch.tensor(train, dtype=torch.float)</span>
<span class="org-sh-heredoc">m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=8).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)</span>
<span class="org-sh-heredoc">lam2 = m.denoise(xt, n_samples=100)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-lam', lam2)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-trace', np.array(m.trace))</span>

<span class="org-sh-heredoc">m = scmodes.lra.NBVAE(input_dim=train.shape[1], latent_dim=8, disp_by_gene=True).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)</span>
<span class="org-sh-heredoc">lam3 = m.denoise(xt, n_samples=100)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-lam', lam3)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-trace', np.array(m.trace))</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<p>
Examine the VAE optimization traces.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
plt.clf()
plt.gcf().set_size_inches(4, 2)
<span class="org-variable-name">trace</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-trace.npy'</span>)
<span class="org-variable-name">trace2</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-trace.npy'</span>)
<span class="org-keyword">for</span> i, (t, s, k) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">zip</span>(trace.T, [900, 100], [<span class="org-string">'PVAE train'</span>, <span class="org-string">'PVAE val'</span>])):
  plt.plot(np.log(t / s), lw=1, c=cm(i), label=k)
<span class="org-keyword">for</span> i, (t, s, k) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">zip</span>(trace2.T, [900, 100], [<span class="org-string">'NBVAE train'</span>, <span class="org-string">'NBVAE val'</span>])):
  plt.plot(np.log(t / s), lw=1, c=cm(i + 2), label=k)
plt.legend(frameon=<span class="org-constant">False</span>)
plt.xlabel(<span class="org-string">'Epoch'</span>)
plt.ylabel(<span class="org-string">'Avg log neg ELBO'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-pvae-trace.png" alt="b_cells-pvae-trace.png">
</p>
</div>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">train</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy'</span>)
<span class="org-variable-name">test</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-test.npy'</span>)
<span class="org-variable-name">lam0</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nmf-lam.npy'</span>)
<span class="org-variable-name">lam1</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-glmpca-lam.npy'</span>)
<span class="org-variable-name">lam2</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-lam.npy'</span>)
<span class="org-variable-name">lam3</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-lam.npy'</span>)
</pre>
</div>

<p>
Compare the fitted values of each method against other.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 3, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(5.5, 2.5)

ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0].plot([0, 11], [0, 11], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(r<span class="org-string">'GLMPCA $\sqrt{\hat\lambda}$'</span>)
ax[0].set_ylabel(r<span class="org-string">'NMF $\sqrt{\hat\lambda}$'</span>)

ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1].plot([0, 11], [0, 11], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(r<span class="org-string">'PVAE $\sqrt{\hat\lambda}$'</span>)

ax[2].scatter(np.sqrt(lam3.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[2].plot([0, 11], [0, 11], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[2].set_xlabel(r<span class="org-string">'NBVAE $\sqrt{\hat\lambda}$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'B cell'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells.png" alt="b_cells.png">
</p>
</div>

<p>
Compare the fitted values of each method against each other, only for
observations which were 1 in the validation data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2)
fig.set_size_inches(4, 4)

<span class="org-variable-name">query</span> = np.isclose(test, 1)
<span class="org-variable-name">lim</span> = [-400, 5]
ax[0][0].scatter(np.log(lam1[query].ravel()), np.log(lam0[query].ravel()), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0][0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0][0].set_xlim(lim)
ax[0][0].set_ylim(lim)
ax[0][0].set_ylabel(r<span class="org-string">'NMF $\log\ \hat\lambda$'</span>)

ax[0][1].scatter(np.log(lam2[query].ravel()), np.log(lam0[query].ravel()), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0][1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0][1].set_xlim(lim)
ax[0][1].set_ylim(lim)

<span class="org-variable-name">lim</span> = [-20, 5]
ax[0][0].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=<span class="org-constant">False</span>, color=<span class="org-string">'b'</span>))
ax[0][1].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=<span class="org-constant">False</span>, color=<span class="org-string">'b'</span>))

ax[1][0].scatter(np.log(lam1[query].ravel()), np.log(lam0[query].ravel()), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1][0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1][0].set_xlim(lim)
ax[1][0].set_ylim(lim)
ax[1][0].set_xlabel(r<span class="org-string">'GLMPCA $\log\ \hat\lambda$'</span>)
ax[1][0].set_ylabel(r<span class="org-string">'NMF $\log\ \hat\lambda$'</span>)

ax[1][1].scatter(np.log(lam2[query].ravel()), np.log(lam0[query].ravel()), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1][1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1][1].set_xlim(lim)
ax[1][1].set_ylim(lim)
ax[1][1].set_xlabel(r<span class="org-string">'PVAE $\log\ \hat\lambda$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'B cell validation $x = 1$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-val-1.png" alt="b_cells-val-1.png">
</p>
</div>

<p>
Repeat for observations which were 0 in the validation data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2)
fig.set_size_inches(4, 4)

<span class="org-variable-name">query</span> = np.isclose(test, 0)
<span class="org-variable-name">lim</span> = [-400, 5]
ax[0][0].scatter(np.log(lam1[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0][0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0][0].set_xlim(lim)
ax[0][0].set_ylim(lim)
ax[0][0].set_ylabel(r<span class="org-string">'NMF $\log\ \hat\lambda$'</span>)

ax[0][1].scatter(np.log(lam2[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0][1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0][1].set_xlim(lim)
ax[0][1].set_ylim(lim)

<span class="org-variable-name">lim</span> = [-20, 5]
ax[0][0].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=<span class="org-constant">False</span>, color=<span class="org-string">'b'</span>))
ax[0][1].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=<span class="org-constant">False</span>, color=<span class="org-string">'b'</span>))

ax[1][0].scatter(np.log(lam1[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1][0].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1][0].set_xlim(lim)
ax[1][0].set_ylim(lim)
ax[1][0].set_xlabel(r<span class="org-string">'GLMPCA $\log\ \hat\lambda$'</span>)
ax[1][0].set_ylabel(r<span class="org-string">'NMF $\log\ \hat\lambda$'</span>)

ax[1][1].scatter(np.log(lam2[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1][1].plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1][1].set_xlim(lim)
ax[1][1].set_ylim(lim)
ax[1][1].set_xlabel(r<span class="org-string">'PVAE $\log\ \hat\lambda$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'B cell validation $x = 0$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-val-0.png" alt="b_cells-val-0.png">
</p>
</div>

<p>
Look at the average training log likelihoods.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">llik0</span> = st.poisson(lam0).logpmf(train)
<span class="org-variable-name">llik1</span> = st.poisson(lam1).logpmf(train)
<span class="org-variable-name">llik2</span> = st.poisson(lam2).logpmf(train)
pd.Series({<span class="org-string">'NMF'</span>: llik0.mean(), <span class="org-string">'GLMPCA'</span>: llik1.mean(), <span class="org-string">'PVAE'</span>: llik2.mean()})
</pre>
</div>

<pre class="example">
NMF      -0.163096
GLMPCA   -0.163275
PVAE     -0.161215
dtype: float64
</pre>

<p>
Look at the distribution of per-observation training log likelihood
differences, stratified by observed value.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(3, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 6)

<span class="org-variable-name">grid</span> = np.arange(train.<span class="org-builtin">max</span>() + 1)
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[0].boxplot((llik1 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[0].set_ylabel(<span class="org-string">'Improvement train\nlog lik over NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[1].boxplot((llik2 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[1].set_ylabel(<span class="org-string">'Improvement train\nlog lik over NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)

<span class="org-variable-name">h</span>, <span class="org-variable-name">e</span> = np.histogram(train.ravel(), bins=grid, density=<span class="org-constant">True</span>)
ax[2].bar(e[:-1], h, color=<span class="org-string">'k'</span>)
ax[2].set_ylabel(<span class="org-string">'Relative frequency'</span>)
ax[2].set_xticks(grid[::5])
ax[2].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[2].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[2].set_xlabel(<span class="org-string">'Observation in training set'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-train-llik-diff.png" alt="b_cells-train-llik-diff.png">
</p>
</div>

<p>
Look at the total training log likelihood differences, stratified by
observed value.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 4)

<span class="org-variable-name">grid</span> = np.arange(train.<span class="org-builtin">max</span>() + 1)
ax[0].bar(grid, np.array([(llik1 - llik0)[train == i].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[0].set_ylabel(<span class="org-string">'Improvement train\nlog lik over NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

ax[1].bar(grid, np.array([(llik2 - llik0)[train == i].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[1].set_ylabel(<span class="org-string">'Improvement train\nlog lik over NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)
ax[1].set_xticks(grid[::5])
ax[1].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[1].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[1].set_xlabel(<span class="org-string">'Observation in training set'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-train-sum-llik-diff.png" alt="b_cells-train-sum-llik-diff.png">
</p>
</div>

<p>
Repeat the analysis for the validation data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">s</span> = (test.<span class="org-builtin">sum</span>(axis=1) / train.<span class="org-builtin">sum</span>(axis=1)).reshape(-1, 1)
<span class="org-variable-name">llik0</span> = np.ma.masked_invalid(st.poisson(s * lam0).logpmf(test))
<span class="org-variable-name">llik1</span> = st.poisson(s * lam1).logpmf(test)
<span class="org-variable-name">llik2</span> = st.poisson(s * lam2).logpmf(test)
pd.Series({<span class="org-string">'NMF'</span>: llik0.mean(), <span class="org-string">'GLMPCA'</span>: llik1.mean(), <span class="org-string">'PVAE'</span>: llik2.mean()})
</pre>
</div>

<pre class="example">
NMF      -0.181994
GLMPCA   -0.166435
PVAE     -0.167921
dtype: float64
</pre>

<p>
Report observations which are non-zero in the validation set, but the NMF estimate
\(\hat\lambda_{ij} = 0\).
</p>

<div class="org-src-container">
<pre class="src src-ipython">test[np.where(llik0.mask)]
</pre>
</div>

<pre class="example">
array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
1., 1., 1., 1., 1., 1., 1., 1.])
</pre>

<p>
Report the corresponding observations in the training set.
</p>

<div class="org-src-container">
<pre class="src src-ipython">train[np.where(llik0.mask)]
</pre>
</div>

<pre class="example">
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0])
</pre>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(3, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 6)

<span class="org-variable-name">grid</span> = np.arange(test.<span class="org-builtin">max</span>())
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[0].boxplot((llik1 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[0].set_ylabel(<span class="org-string">'Improvement val log lik\nover NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[1].boxplot((llik2 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[1].set_ylabel(<span class="org-string">'Improvement val log lik\nover NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)

<span class="org-variable-name">h</span>, <span class="org-variable-name">e</span> = np.histogram(test.ravel(), bins=np.arange(test.<span class="org-builtin">max</span>() + 1), density=<span class="org-constant">True</span>)
ax[2].bar(e[:-1], h, color=<span class="org-string">'k'</span>)
ax[2].set_ylabel(<span class="org-string">'Relative frequency'</span>)
ax[2].set_xticks(grid[::5])
ax[2].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[2].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[2].set_xlabel(<span class="org-string">'Observation in validation set'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-llik-diff.png" alt="b_cells-llik-diff.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 4)

<span class="org-variable-name">grid</span> = np.arange(test.<span class="org-builtin">max</span>() + 1)
ax[0].bar(grid, np.array([(llik1 - llik0)[test == i].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>, zorder=-3)
ax[0].set_ylabel(<span class="org-string">'Improvement val log lik\nover NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

ax[1].bar(grid, np.array([(llik2 - llik0)[test == i].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>, zorder=-3)
ax[1].set_ylabel(<span class="org-string">'Improvement val log lik\nover NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)
ax[1].set_xticks(grid[::5])
ax[1].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[1].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[1].set_xlabel(<span class="org-string">'Observation in validation set'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-sum-llik-diff.png" alt="b_cells-sum-llik-diff.png">
</p>
</div>

<p>
Count the fraction of observations equal to one in the validation set.
</p>

<div class="org-src-container">
<pre class="src src-ipython">(test == 1).<span class="org-builtin">sum</span>() / np.prod(test.shape)
</pre>
</div>

<pre class="example">
0.033023219573009195

</pre>

<p>
For observations which were equal to one in validation set, look at the
distribution of training set values.
</p>

<div class="org-src-container">
<pre class="src src-ipython">pd.Series(<span class="org-builtin">dict</span>(<span class="org-builtin">enumerate</span>([np.logical_and(train == i, test == 1).<span class="org-builtin">sum</span>() / (test == 1).<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(4)])))
</pre>
</div>

<pre class="example">
0    0.786306
1    0.139441
2    0.040593
3    0.017644
dtype: float64
</pre>

<p>
Look at the distribution of (a random sample of) randomized quantiles for
each method.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">train_qs</span> = []
<span class="org-variable-name">test_qs</span> = []
<span class="org-keyword">for</span> i, l <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>([lam0, lam1, lam2]):
  <span class="org-variable-name">F</span> = st.poisson(l)
  <span class="org-variable-name">q</span> = np.sort((F.cdf(train - 1) + np.random.uniform(size=train.shape) * F.pmf(train)).ravel()[::10])
  train_qs.append(q)
  <span class="org-variable-name">q</span> = np.sort((F.cdf(test - 1) + np.random.uniform(size=test.shape) * F.pmf(test)).ravel()[::10])
  test_qs.append(q)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(5.5, 3)
<span class="org-variable-name">lim</span> = [4e-7, 1]
<span class="org-keyword">for</span> a, qs, t <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), [train_qs, test_qs], [<span class="org-string">'Training'</span>, <span class="org-string">'Validation'</span>]):
  a.set_xscale(<span class="org-string">'log'</span>)
  a.set_yscale(<span class="org-string">'log'</span>)
  <span class="org-keyword">for</span> i, (q, k) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">zip</span>(qs, [<span class="org-string">'NMF'</span>, <span class="org-string">'GLMPCA'</span>, <span class="org-string">'PVAE'</span>])):
    <span class="org-variable-name">x</span> = np.linspace(0, 1, q.shape[0] + 1)[1:]
    a.plot(x, np.sort(q), lw=1, c=cm(i), label=k)
    a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'0.7'</span>)
    a.set_xlim(lim)
    a.set_ylim(lim)
  a.set_xlabel(<span class="org-string">'Theoretical quantile'</span>)
  a.set_title(t)
ax[0].set_ylabel(<span class="org-string">'Randomized quantile'</span>)
ax[1].legend(frameon=<span class="org-constant">False</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-rpp.png" alt="b_cells-rpp.png">
</p>
</div>

<p>
Randomly mask 10% of the entries.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">w</span> = scmodes.benchmark.imputation._mask_entries(x.values, frac=0.1, seed=0)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w'</span>, w)
</pre>
</div>

<p>
Fit WNMF, WGLMPCA, and WPVAE.
</p>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=mstephens -n1 -c8 --mem=8G --time=60:00
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">&lt;&lt;data&gt;&gt;</span>
<span class="org-sh-heredoc">train = data['b_cells']().values</span>
<span class="org-sh-heredoc">w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')</span>
<span class="org-sh-heredoc">l, f, _ = scmodes.lra.nmf(train, w=w, rank=8, tol=1e-4, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam0 = l @ f.T</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wnmf-lam', lam0)</span>

<span class="org-sh-heredoc">l, f, _ = scmodes.lra.glmpca(train, w=w, rank=8, tol=1e-4, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam1 = np.exp(l @ f.T)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wglmpca-lam', lam1)</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">&lt;&lt;data&gt;&gt;</span>
<span class="org-sh-heredoc">train = data['b_cells']().values</span>
<span class="org-sh-heredoc">w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')</span>
<span class="org-sh-heredoc">xt = torch.tensor(train, dtype=torch.float)</span>
<span class="org-sh-heredoc">wt = torch.tensor(w, dtype=torch.float)</span>
<span class="org-sh-heredoc">m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=10).fit(xt, w=wt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)</span>
<span class="org-sh-heredoc">lam2 = m.denoise(xt, n_samples=100)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-lam', lam2)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-trace', np.array(m.trace))</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<p>
Examine the PVAE optimization trace.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
plt.gcf().set_size_inches(4, 2)
<span class="org-variable-name">trace</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-trace.npy'</span>)
<span class="org-keyword">for</span> i, (t, s, k) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">zip</span>(trace.T, [900, 100], [<span class="org-string">'Training'</span>, <span class="org-string">'Validation'</span>])):
  plt.plot(np.log(t / s), lw=1, c=cm(i), label=k)
plt.legend(frameon=<span class="org-constant">False</span>)
plt.title(<span class="org-string">'Weighted PVAE'</span>)
plt.xlabel(<span class="org-string">'Epoch'</span>)
plt.ylabel(<span class="org-string">'Avg log neg ELBO'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-wpvae-trace.png" alt="b_cells-wpvae-trace.png">
</p>
</div>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">train</span> = data[<span class="org-string">'b_cells'</span>]().values
<span class="org-variable-name">w</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy'</span>)
<span class="org-variable-name">lam0</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wnmf-lam.npy'</span>)
<span class="org-variable-name">lam1</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wglmpca-lam.npy'</span>)
<span class="org-variable-name">lam2</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-lam.npy'</span>)
<span class="org-variable-name">llik0</span> = st.poisson(lam0).logpmf(train)
<span class="org-variable-name">llik1</span> = st.poisson(lam1).logpmf(train)
<span class="org-variable-name">llik2</span> = st.poisson(lam2).logpmf(train)
</pre>
</div>

<p>
Report the log likelihood of masked entries.
</p>

<div class="org-src-container">
<pre class="src src-ipython">pd.Series({<span class="org-string">'NMF'</span>: llik0[~w].mean(), <span class="org-string">'GLMPCA'</span>: llik1[~w].mean(), <span class="org-string">'PVAE'</span>: llik2[~w].mean()})
</pre>
</div>

<pre class="example">
NMF      -0.259506
GLMPCA   -0.256485
PVAE     -0.262147
dtype: float64
</pre>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(3, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 6)

<span class="org-variable-name">grid</span> = np.arange(train.<span class="org-builtin">max</span>() + 1)
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[0].boxplot((llik1 - llik0)[np.logical_and(w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[0].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[1].boxplot((llik2 - llik0)[np.logical_and(w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[1].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)

<span class="org-variable-name">h</span>, <span class="org-variable-name">e</span> = np.histogram(train[w].ravel(), bins=grid, density=<span class="org-constant">True</span>)
ax[2].bar(e[:-1], h, color=<span class="org-string">'k'</span>)
ax[2].set_ylabel(<span class="org-string">'Relative frequency'</span>)
ax[2].set_xticks(grid[::5])
ax[2].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[2].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[2].set_xlabel(<span class="org-string">'Observation in unmasked data'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-unmasked-llik-diff.png" alt="b_cells-unmasked-llik-diff.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 4)

<span class="org-variable-name">grid</span> = np.arange(train.<span class="org-builtin">max</span>() + 1)
ax[0].bar(grid, np.array([(llik1 - llik0)[np.logical_and(w, train == i)].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>, zorder=-3)
ax[0].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

ax[1].bar(grid, np.array([(llik2 - llik0)[np.logical_and(w, train == i)].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>, zorder=-3)
ax[1].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)
ax[1].set_xticks(grid[::5])
ax[1].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[1].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[1].set_xlabel(<span class="org-string">'Observation in unmasked data'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-unmasked-sum-llik-diff.png" alt="b_cells-unmasked-sum-llik-diff.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(3, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 6)

<span class="org-variable-name">grid</span> = np.arange(train.<span class="org-builtin">max</span>() + 1)
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[0].boxplot((llik1 - llik0)[np.logical_and(~w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[0].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

<span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid:
  ax[1].boxplot((llik2 - llik0)[np.logical_and(~w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>)
ax[1].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)

<span class="org-variable-name">h</span>, <span class="org-variable-name">e</span> = np.histogram(train[~w].ravel(), bins=grid, density=<span class="org-constant">True</span>)
ax[2].bar(e[:-1], h, color=<span class="org-string">'k'</span>)
ax[2].set_ylabel(<span class="org-string">'Relative frequency'</span>)
ax[2].set_xticks(grid[::5])
ax[2].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[2].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[2].set_xlabel(<span class="org-string">'Observation in masked data'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-masked-llik-diff.png" alt="b_cells-masked-llik-diff.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(7, 4)

<span class="org-variable-name">grid</span> = np.arange(train.<span class="org-builtin">max</span>() + 1)
ax[0].bar(grid, np.array([(llik1 - llik0)[np.logical_and(~w, train == i)].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[0].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>, zorder=-3)
ax[0].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[0].set_title(<span class="org-string">'GLMPCA'</span>)

ax[1].bar(grid, np.array([(llik2 - llik0)[np.logical_and(~w, train == i)].<span class="org-builtin">sum</span>() <span class="org-keyword">for</span> i <span class="org-keyword">in</span> grid]), color=<span class="org-string">'k'</span>)
ax[1].axhline(y=0, ls=<span class="org-string">':'</span>, lw=1, c=<span class="org-string">'r'</span>, zorder=-3)
ax[1].set_ylabel(<span class="org-string">'Improvement log lik\nover NMF'</span>)
ax[1].set_title(<span class="org-string">'PVAE'</span>)
ax[1].set_xticks(grid[::5])
ax[1].set_xticklabels(grid[::5].astype(<span class="org-builtin">int</span>))
ax[1].set_xlim(-.5, grid.<span class="org-builtin">max</span>() - .5)
ax[1].set_xlabel(<span class="org-string">'Observation in masked data'</span>)

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-masked-sum-llik-diff.png" alt="b_cells-masked-sum-llik-diff.png">
</p>
</div>

<p>
Examine the case where GLM-PCA appears to fail.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">train</span> = data[<span class="org-string">'b_cells'</span>]().values
<span class="org-variable-name">w</span> = np.load(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy'</span>)
<span class="org-variable-name">l</span>, <span class="org-variable-name">f</span>, <span class="org-variable-name">_</span> = scmodes.lra.glmpca(train, w=w, rank=4, tol=1e-2, max_iters=10000, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam</span> = np.exp(l @ f.T)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">-np.where(w, st.poisson(mu=lam).logpmf(train), 0).<span class="org-builtin">sum</span>()
</pre>
</div>

<pre class="example">
469460.7112869973

</pre>

<div class="org-src-container">
<pre class="src src-ipython">-np.where(~w, st.poisson(mu=lam).logpmf(train), 0).mean()
</pre>
</div>

<pre class="example">
1.5974443522458214e+50

</pre>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.scatter(train[~w].ravel(), lam[~w].ravel(), s=1, alpha=0.1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Masked value'</span>)
plt.ylabel(<span class="org-string">'Fitted value'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-wglmpca-4.png" alt="b_cells-wglmpca-4.png">
</p>
</div>

<p>
Find the outlier.
</p>

<div class="org-src-container">
<pre class="src src-ipython">np.where(lam == lam.<span class="org-builtin">max</span>()), train[np.where(lam == lam.<span class="org-builtin">max</span>())]
</pre>
</div>

<pre class="example">
((array([895]), array([353])), array([1.]))

</pre>

<div class="org-src-container">
<pre class="src src-ipython">l[895], f[353]
</pre>
</div>

<pre class="example">
(array([ 0.40541451,  0.54979576,  0.95922746, -1.09842433]),
array([ -3.27497815, 235.22646683,   5.0478365 ,   4.01345086]))
</pre>

<p>
Look at the remainder of the fitted values.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(3, 3)
<span class="org-variable-name">lim</span> = [0, 97]
plt.scatter(train[~w].ravel(), lam[~w].ravel(), s=1, alpha=0.1, c=<span class="org-string">'k'</span>)
plt.plot(lim, lim, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
plt.xlim(lim)
plt.ylim(lim)
plt.xlabel(<span class="org-string">'Masked value'</span>)
plt.ylabel(<span class="org-string">'Fitted value'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/b_cells-wglmpca-4-inset.png" alt="b_cells-wglmpca-4-inset.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l1</span>, <span class="org-variable-name">f1</span>, <span class="org-variable-name">loss1</span> = scmodes.lra.glmpca(train, w=w, rank=4, tol=5e-2, max_iters=10000, verbose=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">-np.where(~w, st.poisson(mu=np.exp(l1 @ f1.T)).logpmf(train), 0).mean()
</pre>
</div>

<pre class="example">
6.651556782196484e+18

</pre>
</div>
</div>

<div id="outline-container-org4075a13" class="outline-3">
<h3 id="org4075a13">T cells</h3>
<div class="outline-text-3" id="text-org4075a13">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = data[<span class="org-string">'cytotoxic_t'</span>]()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span>, <span class="org-variable-name">f</span>, <span class="org-variable-name">_</span> = scmodes.lra.nmf(x.values, rank=3, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam0</span> = l @ f.T
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span>, <span class="org-variable-name">f</span>, <span class="org-variable-name">_</span> = scmodes.lra.glmpca(x.values, rank=3, atol=.1, max_iters=500, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam1</span> = np.exp(l @ f.T)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">xt</span> = torch.tensor(x.values, dtype=torch.<span class="org-builtin">float</span>)
<span class="org-variable-name">m</span> = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam2</span> = m.denoise(xt)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4, 2.5)

ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0].plot([0, 8], [0, 8], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xticks([0, 4, 8])
ax[0].set_yticks([0, 4, 8])
ax[0].set_xlabel(r<span class="org-string">'GLMPCA $\sqrt{\hat\lambda}$'</span>)
ax[0].set_ylabel(r<span class="org-string">'NMF $\sqrt{\hat\lambda}$'</span>)

ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1].plot([0, 8], [0, 8], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xticks([0, 4, 8])
ax[1].set_yticks([0, 4, 8])
ax[1].set_xlabel(r<span class="org-string">'PVAE $\sqrt{\hat\lambda}$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'T cell'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/t_cells.png" alt="t_cells.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org4757b63" class="outline-3">
<h3 id="org4757b63">iPSCs</h3>
<div class="outline-text-3" id="text-org4757b63">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = data[<span class="org-string">'ipsc'</span>]()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span>, <span class="org-variable-name">f</span>, <span class="org-variable-name">_</span> = scmodes.lra.nmf(x.values, rank=2, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam0</span> = l @ f.T
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span>, <span class="org-variable-name">f</span>, <span class="org-variable-name">_</span> = scmodes.lra.glmpca(x.values, rank=2, atol=.1, max_iters=500, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam1</span> = np.exp(l @ f.T)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">xt</span> = torch.tensor(x.values, dtype=torch.<span class="org-builtin">float</span>)
<span class="org-variable-name">m</span> = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">lam2</span> = m.denoise(xt)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4, 2.5)

ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0].plot([0, 30], [0, 30], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(r<span class="org-string">'GLMPCA $\sqrt{\hat\lambda}$'</span>)
ax[0].set_ylabel(r<span class="org-string">'NMF $\sqrt{\hat\lambda}$'</span>)

ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1].plot([0, 30], [0, 30], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(r<span class="org-string">'PVAE $\sqrt{\hat\lambda}$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'iPSC'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/ipsc.png" alt="ipsc.png">
</p>
</div>
</div>
</div>

<div id="outline-container-orgfd759d0" class="outline-3">
<h3 id="orgfd759d0">T cell/B cell</h3>
<div class="outline-text-3" id="text-orgfd759d0">
<p>
Split the data into training and validation sets using binomial thinning, then fit
NMF, GLMPCA, and PVAE.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">Important: this implicitly sets the random seed</span>
<span class="org-variable-name">x</span> = data[<span class="org-string">'cytotoxic_t-b_cells'</span>]()
<span class="org-variable-name">train</span>, <span class="org-variable-name">test</span> = scmodes.benchmark.train_test_split(x)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-train'</span>, train.values)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-test'</span>, test.values)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=broadwl -n1 --mem=8G --time=24:00:00
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-train.npy')</span>
<span class="org-sh-heredoc">l, f, _ = scmodes.lra.nmf(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam0 = l @ f.T</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-nmf-lam', lam0)</span>

<span class="org-sh-heredoc">l, f, _ = scmodes.lra.glmpca(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam1 = np.exp(l @ f.T)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-glmpca-lam', lam1)</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-train.npy')</span>
<span class="org-sh-heredoc">xt = torch.tensor(train, dtype=torch.float)</span>
<span class="org-sh-heredoc">m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=8).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)</span>
<span class="org-sh-heredoc">lam2 = m.denoise(xt, n_samples=100)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-pvae-lam', lam2)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-pvae-trace', np.array(m.trace))</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4, 2.5)

ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0].plot([0, 10], [0, 10], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(r<span class="org-string">'GLMPCA $\sqrt{\hat\lambda}$'</span>)
ax[0].set_ylabel(r<span class="org-string">'NMF $\sqrt{\hat\lambda}$'</span>)

ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1].plot([0, 10], [0, 10], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(r<span class="org-string">'PVAE $\sqrt{\hat\lambda}$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'T cell/B cell'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/cytotoxic_t-b_cells.png" alt="cytotoxic_t-b_cells.png">
</p>
</div>
</div>
</div>
<div id="outline-container-orga214153" class="outline-3">
<h3 id="orga214153">PBMC</h3>
<div class="outline-text-3" id="text-orga214153">
<p>
Split the data into training and validation sets using binomial thinning, then fit
NMF, GLMPCA, and PVAE.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">Important: this implicitly sets the random seed</span>
<span class="org-variable-name">x</span> = data[<span class="org-string">'pbmcs_68k'</span>]()
<span class="org-variable-name">train</span>, <span class="org-variable-name">test</span> = scmodes.benchmark.train_test_split(x)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-train'</span>, train.values)
np.save(<span class="org-string">'/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-test'</span>, test.values)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=broadwl -n1 --mem=8G --time=24:00:00
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-train.npy')</span>
<span class="org-sh-heredoc">l, f, _ = scmodes.lra.nmf(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam0 = l @ f.T</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-nmf-lam', lam0)</span>

<span class="org-sh-heredoc">l, f, _ = scmodes.lra.glmpca(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)</span>
<span class="org-sh-heredoc">lam1 = np.exp(l @ f.T)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-glmpca-lam', lam1)</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scmodes
python &lt;&lt;EOF
<span class="org-sh-heredoc">&lt;&lt;imports&gt;&gt;</span>
<span class="org-sh-heredoc">train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-train.npy')</span>
<span class="org-sh-heredoc">xt = torch.tensor(train, dtype=torch.float)</span>
<span class="org-sh-heredoc">m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=8).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)</span>
<span class="org-sh-heredoc">lam2 = m.denoise(xt, n_samples=100)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-pvae-lam', lam2)</span>
<span class="org-sh-heredoc">np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-pvae-trace', np.array(m.trace))</span>
<span class="org-sh-heredoc">EOF</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4, 2.5)

ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0].plot([0, 10], [0, 10], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[0].set_xlabel(r<span class="org-string">'GLMPCA $\sqrt{\hat\lambda}$'</span>)
ax[0].set_ylabel(r<span class="org-string">'NMF $\sqrt{\hat\lambda}$'</span>)

ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1].plot([0, 10], [0, 10], lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
ax[1].set_xlabel(r<span class="org-string">'PVAE $\sqrt{\hat\lambda}$'</span>)

<span class="org-variable-name">a</span> = fig.add_subplot(111, frame_on=<span class="org-constant">False</span>, xticks=[], yticks=[])
a.set_title(<span class="org-string">'T cell/B cell'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/fitted-values.org/pbmcs_68k.png" alt="pbmcs_68k.png">
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2020-07-25 Sat 16:41</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
