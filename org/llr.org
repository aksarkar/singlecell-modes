#+TITLE: Marginal log likelihood comparison of expression models
#+SETUPFILE: setup.org

* Introduction

  We previously used a [[file:gof.org][goodness of fit test]] and
  [[file:deconvolution.org][out-of-sample (marginal) log likelihood]] to assess
  whether the data were adequately described by a given expression model. Here,
  we compute the in-sample marginal log likelihood, in order to make direct
  comparisons between expression models.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "llr.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="mstephens",memory="16G") :exports none :dir /scratch/midway2/aksarkar/modes

  #+BEGIN_SRC ipython
    import anndata
    import numpy as np
    import os
    import pandas as pd
    import scanpy as sc
    import scmodes
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Results
** Data

   Prepare the data in ~h5ad~.

   #+NAME: data
   #+BEGIN_SRC ipython
     def read_chromium(sample):
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/svensson_chromium_control.h5ad')
       x = x[x.obs['sample'] == sample,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_dropseq():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/macosko_dropseq_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_indrops():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/klein_indrops_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_gemcode():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/zheng_gemcode_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def _read_10x(k, return_df=False, min_detect=0.01):
       return scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k}/filtered_matrices_mex/hg19/',
                                       return_adata=not return_df, return_df=return_df, min_detect=min_detect)

     def _mix_10x(k1, k2, min_detect=0.01, return_y=False):
       x1 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k1}/filtered_matrices_mex/hg19/', return_adata=True, return_df=False, min_detect=0)
       x2 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k2}/filtered_matrices_mex/hg19/', return_adata=True, return_df=False, min_detect=0)
       x = x1.concatenate(x2)
       sc.pp.filter_genes(x, min_cells=min_detect * x.shape[0])
       return x

     def _cd8_cd19_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'b_cells', **kwargs)

     def _cyto_naive_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'naive_t', **kwargs)

     def read_ipsc(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/ipsc/ipsc.h5ad')
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_liver(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/liver-caudate-lobe/liver-caudate-lobe.h5ad')
       x.obs['size'] = x.X.sum(axis=1).A.ravel()
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_kidney(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/kidney/kidney.h5ad')
       x.obs['size'] = x.X.sum(axis=1).A.ravel()
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_brain(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/gtex-droncseq/gtex-droncseq.h5ad')
       sc.pp.filter_genes(x, min_counts=.01 * x.shape[0])
       x.obs['size'] = x.X.sum(axis=1).A.ravel()
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_retina(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/adult-retina/adult-retina.h5ad')
       query = x.obs['donor_organism.provenance.document_id'] == '427c0a62-9baf-42ab-a3a3-f48d10544280'
       y = x[query]
       sc.pp.filter_genes(y, min_cells=.01 * y.shape[0])
       y.obs['size'] = y.X.sum(axis=1).A.ravel()
       if chunk is None:
         return y
       else:
         return y[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_pbmcs_68k(chunk=None, chunksize=500):
       x = _read_10x('fresh_68k_pbmc_donor_a', return_df=False)
       x.obs['size'] = x.X.sum(axis=1).A.ravel()
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     data = {
       'dropseq': read_dropseq,
       'indrops': read_indrops,
       'chromium1': lambda: read_chromium('20311'),
       'chromium2': lambda: read_chromium('20312'),
       'gemcode': read_gemcode,
       'cytotoxic_t': lambda: _read_10x('cytotoxic_t'),
       'b_cells': lambda: _read_10x('b_cells'),
       'ipsc': read_ipsc,
       'cytotoxic_t-b_cells': _cd8_cd19_mix,
       'cytotoxic_t-naive_t': _cyto_naive_mix,
       'pbmcs_68k': read_pbmcs_68k,
       'liver-caudate-lobe': read_liver,
       'kidney': read_kidney,
       'brain': read_brain,
       'retina': read_retina,
     }

     chunks = {
       'brain': 11744 // 500,
       'kidney': 15496 // 500,
       'liver-caudate-lobe': 3181 // 500,
       'pbmcs_68k': 6502 // 500,
       'retina': 10047 // 500,
     }

     control = list(data.keys())[:5]
     non_control = list(data.keys())[5:]
   #+END_SRC

   #+RESULTS: data
   :RESULTS:
   # Out[4]:
   :END:

** Estimate marginal log likelihood

   Estimate the marginal likelihood for each data set, for each gene, for each
   family of expression models.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 -c28 --exclusive --job-name=llik --time=24:00:00 -a 66-69,71-74
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import anndata
     import multiprocessing as mp
     import os
     <<data>>
     tasks = [(m, d) for m in ('point', 'gamma', 'point_gamma', 'unimodal', 'npmle') for d in data]
     m, d = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool() as pool:
       x = data[d]()
       res = scmodes.benchmark.evaluate_llik(x, pool=pool, methods=[m])
       res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{d}-{m}.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3421359

   Shard data sets to fit unimodal/non-parametric expression models within the
   ~midway2~ time/memory limits.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 -c28 --exclusive --job-name=llik --time=8:00:00 -a 59-69,71
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import multiprocessing as mp
     import os
     <<data>>
     method = 'npmle'
     tasks = [(d, c) for d in chunks for c in range(chunks[d])]
     d, c = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool(maxtasksperchild=20) as pool:
       x = data[d](chunk=c)
       res = scmodes.benchmark.evaluate_llik(x, s=x.obs['size'], pool=pool, methods=[method])
       res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{d}-{method}-{c}.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3436059

   Move the results to permanent storage.

   #+BEGIN_SRC sh
     rsync -au /scratch/midway2/aksarkar/modes/llik/ /project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/
   #+END_SRC

   #+RESULTS:

   Combine the sharded results.

   #+BEGIN_SRC ipython :async t
     for m in ('unimodal', 'npmle'):
       for k in chunks:
         if os.path.exists(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}-0.txt.gz'):
           (pd.concat([pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}-{i}.txt.gz', index_col=0, sep='\t')
                       for i in range(chunks[k])])
            .to_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   Read the results.

   #+BEGIN_SRC ipython :async t
     llik = (pd.concat(
       {
         k: pd.concat([
           pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz', index_col=0, sep='\t')
           for m in ('point', 'gamma', 'point_gamma', 'unimodal', 'npmle')
           if os.path.exists(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz')])
         for k in data
       })
             .reset_index(level=0)
             .rename({'level_0': 'dataset'}, axis=1))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

** Application to control data sets

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the point mass expression model.

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['point'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['point']
     res[['gamma', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   #+BEGIN_EXAMPLE
     method     gamma  point_gamma  unimodal  npmle
     dataset
     chromium1     15           13        17     17
     chromium2     48           48        51     50
     dropseq       77           77        78     78
     gemcode       52           52        56     56
     indrops        4            4         4      4
   #+END_EXAMPLE
   :END:

   The case where (the improvement over point mass expression model of) the
   NPMLE expression model appears worse than the unimodal expression model
   appears to be a [[file:npmle-grid.org][problem with our iterative refinement
   scheme]].
   
   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the Gamma expression model.

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['gamma'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['gamma']
     res[['point', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   #+BEGIN_EXAMPLE
     method     point  point_gamma  unimodal  npmle
     dataset
     chromium1      0            0         8      8
     chromium2      0            0         4      5
     dropseq        0            2         6     20
     gemcode        1            1        53     53
     indrops        1            0         2      2
   #+END_EXAMPLE
   :END:

   Find the genes where a point-Gamma model improved over a Gamma model.

   #+BEGIN_SRC ipython
     temp = []
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       temp.append(query.loc[query['point_gamma'] > query['gamma'] + thresh])
     query = pd.concat(temp)[['point', 'gamma', 'point_gamma', 'unimodal', 'npmle']]
     query
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[137]:
   #+BEGIN_EXAMPLE
     method            point        gamma  point_gamma     unimodal        npmle
     gene
     ERCC-00078  -765.076024  -279.353443  -264.522869  -263.565367  -261.759913
     ERCC-00131  -723.520929  -356.755781  -341.742929  -347.518213  -337.364384
     ERCC-00002 -6108.645264 -6148.879840 -6132.663007 -5944.693604 -5944.424540
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/llr.org/dropseq-point-gamma.png
     x = data['dropseq']()
     plt.clf()
     fig, ax = plt.subplots(1, 2)
     fig.set_size_inches(4, 2.5)
     for (k, _), a in zip(query.iterrows(), ax):
       y = x[:,x.var['index'] == k].X.A.ravel()
       a.hist(y, bins=np.arange(y.max() + 2), density=True, color='0.7')
       a.set_title(k)
     ax[0].set_ylabel('Density')
     a = fig.add_subplot(111, frameon=False, xticks=[], yticks=[])
     a.set_xlabel('Number of molecules', labelpad=16)
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[155]:
   [[file:figure/llr.org/dropseq-point-gamma.png]]
   :END:

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the unimodal expression model.

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['unimodal'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['unimodal']
     res[['point', 'gamma', 'point_gamma', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[77]:
   #+BEGIN_EXAMPLE
     method     point  gamma  point_gamma  npmle
     dataset
     chromium1      0      0            0      0
     chromium2      0      0            0      0
     dropseq        0      0            0      1
     gemcode        0      0            0      0
     indrops        0      0            0      0
   #+END_EXAMPLE
   :END:

** Application to biological data sets

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the Gamma expression model.

   #+BEGIN_SRC ipython :async t
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(non_control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['gamma'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0]
            [['point', 'point_gamma', 'unimodal', 'npmle']])
     res
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   #+BEGIN_EXAMPLE
     method               point  point_gamma  unimodal   npmle
     dataset
     b_cells               24.0         64.0     624.0   615.0
     brain                  0.0        303.0    1057.0   828.0
     cytotoxic_t           21.0         83.0     710.0   716.0
     cytotoxic_t-b_cells   26.0        259.0       NaN  1434.0
     cytotoxic_t-naive_t   22.0        186.0       NaN  1482.0
     ipsc                   0.0          1.0      25.0    24.0
     kidney                 0.0        222.0    7097.0  1650.0
     liver-caudate-lobe     0.0         49.0       0.0    63.0
     pbmcs_68k              6.0       1302.0    4454.0  2931.0
     retina               164.0        350.0    1647.0  1449.0
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(non_control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['unimodal'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0]
            [['point', 'point_gamma', 'unimodal', 'npmle']])
     res
   #+END_SRC
