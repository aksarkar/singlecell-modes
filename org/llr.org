#+TITLE: Marginal log likelihood comparison of expression models
#+SETUPFILE: setup.org

* Introduction

  We previously used a [[file:gof.org][goodness of fit test]] and
  [[file:deconvolution.org][out-of-sample (marginal) log likelihood]] to assess
  whether the data were adequately described by a given expression model. Here,
  we compute the in-sample marginal log likelihood, in order to make direct
  comparisons between expression models.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "llr.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="gpu2",opts="--gres=gpu:1",memory="16G") :exports none :dir /scratch/midway2/aksarkar/modes

  #+BEGIN_SRC ipython
    import anndata
    import numpy as np
    import os
    import pandas as pd
    import scanpy as sc
    import scmodes
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Results
** Data

   Prepare the data in ~h5ad~.

   #+NAME: data
   #+BEGIN_SRC ipython
     def read_chromium(sample):
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/svensson_chromium_control.h5ad')
       x = x[x.obs['sample'] == sample,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_dropseq():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/macosko_dropseq_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_indrops():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/klein_indrops_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_gemcode():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/zheng_gemcode_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def _read_10x(k, return_df=False, min_detect=0.01):
       return scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k}/filtered_matrices_mex/hg19/',
                                       return_adata=not return_df, return_df=return_df, min_detect=min_detect)

     def _mix_10x(k1, k2, min_detect=0.01, return_y=False):
       x1 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k1}/filtered_matrices_mex/hg19/', return_adata=True, return_df=False, min_detect=0)
       x2 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k2}/filtered_matrices_mex/hg19/', return_adata=True, return_df=False, min_detect=0)
       x = x1.concatenate(x2)
       sc.pp.filter_genes(x, min_cells=min_detect * x.shape[0])
       return x

     def _cd8_cd19_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'b_cells', **kwargs)

     def _cyto_naive_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'naive_t', **kwargs)

     def read_ipsc(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/ipsc/ipsc.h5ad')
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_liver():
       return anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/liver-caudate-lobe/liver-caudate-lobe.h5ad')

     def read_kidney():
       return anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/kidney/kidney.h5ad')

     def read_brain(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/gtex-droncseq/gtex-droncseq.h5ad')
       sc.pp.filter_genes(x, min_counts=.01 * x.shape[0])
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_retina(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/adult-retina/adult-retina.h5ad')
       query = x.obs['donor_organism.provenance.document_id'] == '427c0a62-9baf-42ab-a3a3-f48d10544280'
       y = x[query]
       sc.pp.filter_genes(y, min_cells=.01 * y.shape[0])
       if chunk is None:
         return y
       else:
         return y[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_pbmcs_68k(chunk=None, chunksize=500):
       x = _read_10x('fresh_68k_pbmc_donor_a', return_df=False)
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     data = {
       'dropseq': read_dropseq,
       'indrops': read_indrops,
       'chromium1': lambda: read_chromium('20311'),
       'chromium2': lambda: read_chromium('20312'),
       'gemcode': read_gemcode,
       'cytotoxic_t': lambda: _read_10x('cytotoxic_t'),
       'b_cells': lambda: _read_10x('b_cells'),
       'ipsc': read_ipsc,
       'cytotoxic_t-b_cells': _cd8_cd19_mix,
       'cytotoxic_t-naive_t': _cyto_naive_mix,
       'pbmcs_68k': read_pbmcs_68k,
       'liver-caudate-lobe': read_liver,
       'kidney': read_kidney,
       'brain': read_brain,
       'retina': read_retina,
     }

     chunks = {
       'liver-caudate-lobe': 12170 // 500,
       'pbmcs_68k': 6502 // 500,
       'retina': 11446 // 500,
     }
   #+END_SRC

   #+RESULTS: data
   :RESULTS:
   # Out[4]:
   :END:

** Estimate marginal log likelihood

   Run the GPU-based methods.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=16G --job-name=llik --time=1:00:00 -a 11,12
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import os
     <<data>>
     tasks = list(data.keys())
     task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     x = data[task]()
     res = scmodes.benchmark.evaluate_llik(x, methods=['gamma', 'point_gamma'])
     res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{task}-gpu.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3311600

   Run the CPU-based methods.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 -c28 --exclusive --job-name=llik-point --time=24:00:00 -a 7-9
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import anndata
     import multiprocessing as mp
     import os
     <<data>>
     tasks = [(m, d) for m in ('point', 'unimodal', 'npmle') for d in data]
     m, d = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool(maxtasksperchild=20) as pool:
       x = data[d]()
       res = scmodes.benchmark.evaluate_llik(x, pool=pool, methods=[m])
       res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{d}-{m}.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3311618

   Shard data sets to fit unimodal expression models within the ~midway2~ time
   limits.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 -c28 --exclusive --job-name=llik --time=24:00:00 -a 0
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import multiprocessing as mp
     import os
     <<data>>
     tasks = [(d, c) for d in chunks for c in range(chunks[d])]
     m, d = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool(maxtasksperchild=20) as pool:
       x = data[d](chunk=c)
       res = scmodes.benchmark.evaluate_llik(x, pool=pool, methods=[m])
       res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{d}-unimodal-{c}.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3309196

   Move the results to permanent storage.

   #+BEGIN_SRC sh
     rsync -au /scratch/midway2/aksarkar/modes/llik/ /project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/
   #+END_SRC

   #+RESULTS:

   Read the results.

   #+BEGIN_SRC ipython :async t
     llik = (pd.concat(
       {
         k: pd.concat([
           pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz', index_col=0, sep='\t')
           for m in ('point', 'gpu', 'unimodal', 'npmle')
           if os.path.exists(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz')])
         for k in data
       })
             .reset_index(level=0)
             .rename({'level_0': 'dataset'}, axis=1))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[87]:
   :END:

** Application to control data sets

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the point mass expression model.

   #+BEGIN_SRC ipython :async t
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['point'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['point']
     res[['gamma', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[95]:
   #+BEGIN_EXAMPLE
     method     gamma  point_gamma  unimodal  npmle
     dataset
     chromium1     14           14        17     17
     chromium2     49           49        51     48
     dropseq       77           77        78     78
     gemcode       53           53        56     56
     indrops        4            4         4      4
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :async t
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['gamma'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['gamma']
     res[['point', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[96]:
   #+BEGIN_EXAMPLE
     method     point  point_gamma  unimodal  npmle
     dataset
     chromium1      1            0        10     10
     chromium2      0            0         9      9
     dropseq        0            2         6     17
     gemcode        0            0        52     51
     indrops        0            0         1      1
   #+END_EXAMPLE
   :END:

** Application to biological data sets

   #+BEGIN_SRC ipython
     non_control = list(data.keys())[5:]
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(non_control)].groupby('dataset'):
       # Hack
       g['gene'] = g['gene'].fillna(g['level_1'])
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['gamma'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['gamma']
     res[['point', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[245]:
   #+BEGIN_EXAMPLE
     method               point  point_gamma  unimodal    npmle
     dataset
     b_cells               18.0          8.0     546.0    426.0
     brain                  7.0          8.0       NaN   1441.0
     cytotoxic_t           10.0         10.0     632.0    556.0
     cytotoxic_t-b_cells    NaN       1575.0       NaN      NaN
     cytotoxic_t-naive_t    NaN       1460.0       NaN      NaN
     ipsc                   NaN          9.0       NaN      NaN
     kidney                 0.0          0.0    8463.0   8463.0
     liver-caudate-lobe     0.0          0.0   10646.0  10646.0
     pbmcs_68k             44.0         76.0       NaN   1979.0
     retina                 9.0        135.0       NaN    649.0
   #+END_EXAMPLE
   :END:
