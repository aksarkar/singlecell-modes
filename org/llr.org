#+TITLE: Marginal log likelihood comparison of expression models
#+SETUPFILE: setup.org

* Introduction

  We previously used a [[file:gof.org][goodness of fit test]] and
  [[file:deconvolution.org][out-of-sample (marginal) log likelihood]] to assess
  whether the data were adequately described by a given expression model. Here,
  we compute the in-sample marginal log likelihood, in order to make direct
  comparisons between expression models.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "llr.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="mstephens",memory="16G") :exports none :dir /scratch/midway2/aksarkar/modes

  #+BEGIN_SRC ipython
    import anndata
    import numpy as np
    import os
    import pandas as pd
    import scanpy as sc
    import scmodes
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Results
** Data

   Prepare the data in ~h5ad~.

   #+NAME: data
   #+BEGIN_SRC ipython
     def read_chromium(sample):
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/svensson_chromium_control.h5ad')
       x = x[x.obs['sample'] == sample,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_dropseq():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/macosko_dropseq_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_indrops():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/klein_indrops_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def read_gemcode():
       x = sc.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/zheng_gemcode_control.h5ad')
       x = x[:,x.var.filter(like='ERCC', axis='index').index]
       sc.pp.filter_genes(x, min_cells=1)
       x.var = x.var.reset_index()
       return x

     def _read_10x(k, return_df=False, min_detect=0.01):
       return scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k}/filtered_matrices_mex/hg19/',
                                       return_adata=not return_df, return_df=return_df, min_detect=min_detect)

     def _mix_10x(k1, k2, min_detect=0.01, return_y=False):
       x1 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k1}/filtered_matrices_mex/hg19/', return_adata=True, return_df=False, min_detect=0)
       x2 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k2}/filtered_matrices_mex/hg19/', return_adata=True, return_df=False, min_detect=0)
       x = x1.concatenate(x2)
       sc.pp.filter_genes(x, min_cells=min_detect * x.shape[0])
       return x

     def _cd8_cd19_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'b_cells', **kwargs)

     def _cyto_naive_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'naive_t', **kwargs)

     def read_ipsc(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/ipsc/ipsc.h5ad')
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_liver():
       return anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/liver-caudate-lobe/liver-caudate-lobe.h5ad')

     def read_kidney():
       return anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/kidney/kidney.h5ad')

     def read_brain(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/gtex-droncseq/gtex-droncseq.h5ad')
       sc.pp.filter_genes(x, min_counts=.01 * x.shape[0])
       x.obs['size'] = x.X.sum(axis=1).A.ravel()
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_retina(chunk=None, chunksize=500):
       x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/adult-retina/adult-retina.h5ad')
       query = x.obs['donor_organism.provenance.document_id'] == '427c0a62-9baf-42ab-a3a3-f48d10544280'
       y = x[query]
       sc.pp.filter_genes(y, min_cells=.01 * y.shape[0])
       y.obs['size'] = y.X.sum(axis=1).A.ravel()
       if chunk is None:
         return y
       else:
         return y[:,chunk * chunksize:(chunk + 1) * chunksize]

     def read_pbmcs_68k(chunk=None, chunksize=500):
       x = _read_10x('fresh_68k_pbmc_donor_a', return_df=False)
       x.obs['size'] = x.X.sum(axis=1).A.ravel()
       if chunk is None:
         return x
       else:
         return x[:,chunk * chunksize:(chunk + 1) * chunksize]

     data = {
       'dropseq': read_dropseq,
       'indrops': read_indrops,
       'chromium1': lambda: read_chromium('20311'),
       'chromium2': lambda: read_chromium('20312'),
       'gemcode': read_gemcode,
       'cytotoxic_t': lambda: _read_10x('cytotoxic_t'),
       'b_cells': lambda: _read_10x('b_cells'),
       'ipsc': read_ipsc,
       'cytotoxic_t-b_cells': _cd8_cd19_mix,
       'cytotoxic_t-naive_t': _cyto_naive_mix,
       'pbmcs_68k': read_pbmcs_68k,
       'liver-caudate-lobe': read_liver,
       'kidney': read_kidney,
       'brain': read_brain,
       'retina': read_retina,
     }

     chunks = {
       'brain': 11744 // 500,
       'pbmcs_68k': 6502 // 500,
       'retina': 10047 // 500,
     }

     control = list(data.keys())[:5]
     non_control = list(data.keys())[5:]
   #+END_SRC

   #+RESULTS: data
   :RESULTS:
   # Out[114]:
   :END:

** Estimate marginal log likelihood

   Estimate the marginal likelihood for each data set, for each gene, for each
   family of expression models.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 -c28 --exclusive --job-name=llik --time=24:00:00 -a 60-64
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import anndata
     import multiprocessing as mp
     import os
     <<data>>
     tasks = [(m, d) for m in ('point', 'gamma', 'point_gamma', 'unimodal', 'npmle') for d in data]
     m, d = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     if m == 'npmle':
       kwargs = {'processes': 8}
     else:
       kwargs = dict()
     with mp.Pool(**kwargs) as pool:
       x = data[d]()
       res = scmodes.benchmark.evaluate_llik(x, pool=pool, methods=[m])
       res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{d}-{m}.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3398000

   Shard data sets to fit unimodal expression models within the ~midway2~
   time/memory limits.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 -c28 --exclusive --job-name=llik --time=24:00:00 -a 1,3-56
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     import multiprocessing as mp
     import os
     <<data>>
     tasks = [(d, c) for d in chunks for c in range(chunks[d])]
     d, c = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool(maxtasksperchild=20) as pool:
       x = data[d](chunk=c)
       res = scmodes.benchmark.evaluate_llik(x, s=x.obs['size'], pool=pool, methods=['unimodal'])
       res.to_csv(f'/scratch/midway2/aksarkar/modes/llik/{d}-unimodal-{c}.txt.gz', compression='gzip', sep='\t')
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3379505

   Move the results to permanent storage.

   #+BEGIN_SRC sh
     rsync -au /scratch/midway2/aksarkar/modes/llik/ /project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/
   #+END_SRC

   #+RESULTS:

   Combine the sharded results for unimodal expression models.

   #+BEGIN_SRC ipython :async t
     for k in chunks:
       (pd.concat([pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-unimodal-{i}.txt.gz', index_col=0, sep='\t')
                   for i in range(chunks[k])])
        .to_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-unimodal.txt.gz', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[25]:
   :END:

   Read the results.

   #+BEGIN_SRC ipython :async t
     llik = (pd.concat(
       {
         k: pd.concat([
           pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz', index_col=0, sep='\t')
           for m in ('point', 'gamma', 'point_gamma', 'unimodal', 'npmle')
           if os.path.exists(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/llik/{k}-{m}.txt.gz')])
         for k in data
       })
             .reset_index(level=0)
             .rename({'level_0': 'dataset'}, axis=1))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

** Application to control data sets

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the point mass expression model.

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['point'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['point']
     res[['gamma', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   #+BEGIN_EXAMPLE
     method     gamma  point_gamma  unimodal  npmle
     dataset
     chromium1     13            0        17     17
     chromium2     47           31        51     48
     dropseq       77           77        78     76
     gemcode       52           24        56     56
     indrops        4            0         4      4
   #+END_EXAMPLE
   :END:

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the Gamma expression model.

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['gamma'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['gamma']
     res[['point', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   #+BEGIN_EXAMPLE
     method     point  point_gamma  unimodal  npmle
     dataset
     chromium1      0            0        10     10
     chromium2      0            0         7      6
     dropseq        0            2         6     17
     gemcode        1            0        53     52
     indrops        3            0         7      7
   #+END_EXAMPLE
   :END:

** Application to biological data sets

   For each control data set, for each expression model, report the number of
   genes which have improvement in marginal log likelihood above some threshold
   over the Gamma expression model.

   #+BEGIN_SRC ipython
     thresh = 10
     res = dict()
     for k, g in llik[llik['dataset'].isin(non_control)].groupby('dataset'):
       query = g.pivot_table(index='gene', columns='method', values='llik')
       res[k] = (query.sub(query['gamma'], axis=0) > thresh).sum(axis=0)
     res = (pd.concat(res)
            .reset_index()
            .rename({'level_0': 'dataset'}, axis=1)
            .pivot_table(index='dataset', columns='method')
            [0])
     del res['gamma']
     res[['point', 'point_gamma', 'unimodal', 'npmle']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   #+BEGIN_EXAMPLE
     method                point  point_gamma  unimodal   npmle
     dataset
     b_cells                14.0         15.0     541.0   422.0
     brain                   7.0         10.0       NaN  1441.0
     cytotoxic_t             9.0         13.0     634.0   555.0
     cytotoxic_t-b_cells  1238.0         23.0       NaN     NaN
     cytotoxic_t-naive_t  1225.0         17.0       NaN     NaN
     ipsc                    0.0          1.0       NaN    25.0
     kidney                  0.0        110.0    7096.0  7076.0
     liver-caudate-lobe      0.0          2.0       0.0     0.0
     pbmcs_68k              44.0         84.0       NaN  1979.0
     retina                  9.0        188.0       NaN   649.0
   #+END_EXAMPLE
   :END:
