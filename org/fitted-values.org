#+TITLE: Comparison of fitted values
#+SETUPFILE: setup.org

* Introduction

  We previously found that NMF, GLM-PCA, and PVAE all had similar average
  performance on a [[file:lra.org][binomial thinning benchmark]]. Here, we
  investigate the per-observation performance of these methods.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "lra.org")
    (org-babel-lob-ingest "fitted-values.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="mstephens",memory="16G") :exports none :dir /scratch/midway2/aksarkar/modes

  #+RESULTS:
  : Submitted batch job 66423771

  #+NAME: imports
  #+BEGIN_SRC ipython
    import numpy as np
    import pandas as pd
    import scipy.stats as st
    import scmodes
    import torch
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Results
** Datasets

   Follow the data processing for the [[file:lra.org::*Datasets][Poisson
   thinning analysis]].

   #+CALL: data()

   #+RESULTS:
   :RESULTS:
   # Out[29]:
   :END:

** B cells
   :PROPERTIES:
   :CUSTOM_ID: b-cells
   :END:

   Split the data into training and validation sets using binomial thinning, then fit
   NMF, GLMPCA, and PVAE.

   #+BEGIN_SRC ipython :async t
     # Important: this implicitly sets the random seed
     x = data['b_cells']()
     train, test = scmodes.benchmark.train_test_split(x)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train', train.values)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-test', test.values)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   :END:

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 --mem=8G --time=24:00:00
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')
     l, f, _ = scmodes.lra.nmf(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)
     lam0 = l @ f.T
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nmf-lam', lam0)

     l, f, _ = scmodes.lra.glmpca(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-glmpca-lam', lam1)
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3204066

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')
     xt = torch.tensor(train, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=8).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)
     lam2 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-lam', lam2)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-trace', np.array(m.trace))

     m = scmodes.lra.NBVAE(input_dim=train.shape[1], latent_dim=8, disp_by_gene=True).fit(xt, test_size=0.1, lr=1e-3, max_epochs=400, trace=True)
     lam3 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-lam', lam3)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-trace', np.array(m.trace))
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 3216621

   Examine the VAE optimization traces.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-pvae-trace.png
     cm = plt.get_cmap('Paired')
     plt.clf()
     plt.gcf().set_size_inches(4, 2)
     trace = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-trace.npy')
     trace2 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-trace.npy')
     for i, (t, s, k) in enumerate(zip(trace.T, [900, 100], ['PVAE train', 'PVAE val'])):
       plt.plot(np.log(t / s), lw=1, c=cm(i), label=k)
     for i, (t, s, k) in enumerate(zip(trace2.T, [900, 100], ['NBVAE train', 'NBVAE val'])):
       plt.plot(np.log(t / s), lw=1, c=cm(i + 2), label=k)
     plt.legend(frameon=False)
     plt.xlabel('Epoch')
     plt.ylabel('Avg log neg ELBO')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   [[file:figure/fitted-values.org/b_cells-pvae-trace.png]]
   :END:

   Read the results.

   #+BEGIN_SRC ipython
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')
     test = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-test.npy')
     lam0 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nmf-lam.npy')
     lam1 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-glmpca-lam.npy')
     lam2 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-lam.npy')
     lam3 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nbvae-lam.npy')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Compare the fitted values of each method against other.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells.png
     plt.clf()
     fig, ax = plt.subplots(1, 3, sharey=True)
     fig.set_size_inches(5.5, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 11], [0, 11], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 11], [0, 11], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     ax[2].scatter(np.sqrt(lam3.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[2].plot([0, 11], [0, 11], lw=1, ls=':', c='r')
     ax[2].set_xlabel(r'NBVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('B cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   [[file:figure/fitted-values.org/b_cells.png]]
   :END:

   Compare the fitted values of each method against each other, only for
   observations which were 1 in the validation data.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-val-1.png
     plt.clf()
     fig, ax = plt.subplots(2, 2)
     fig.set_size_inches(4, 4)

     query = np.isclose(test, 1)
     lim = [-400, 5]
     ax[0][0].scatter(np.log(lam1[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[0][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][0].set_xlim(lim)
     ax[0][0].set_ylim(lim)
     ax[0][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[0][1].scatter(np.log(lam2[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[0][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][1].set_xlim(lim)
     ax[0][1].set_ylim(lim)

     lim = [-20, 5]
     ax[0][0].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))
     ax[0][1].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))

     ax[1][0].scatter(np.log(lam1[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[1][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][0].set_xlim(lim)
     ax[1][0].set_ylim(lim)
     ax[1][0].set_xlabel(r'GLMPCA $\log\ \hat\lambda$')
     ax[1][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[1][1].scatter(np.log(lam2[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[1][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][1].set_xlim(lim)
     ax[1][1].set_ylim(lim)
     ax[1][1].set_xlabel(r'PVAE $\log\ \hat\lambda$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('B cell validation $x = 1$')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[57]:
   [[file:figure/fitted-values.org/b_cells-val-1.png]]
   :END:

   Repeat for observations which were 0 in the validation data.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-val-0.png
     plt.clf()
     fig, ax = plt.subplots(2, 2)
     fig.set_size_inches(4, 4)

     query = np.isclose(test, 0)
     lim = [-400, 5]
     ax[0][0].scatter(np.log(lam1[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][0].set_xlim(lim)
     ax[0][0].set_ylim(lim)
     ax[0][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[0][1].scatter(np.log(lam2[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][1].set_xlim(lim)
     ax[0][1].set_ylim(lim)

     lim = [-20, 5]
     ax[0][0].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))
     ax[0][1].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))

     ax[1][0].scatter(np.log(lam1[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][0].set_xlim(lim)
     ax[1][0].set_ylim(lim)
     ax[1][0].set_xlabel(r'GLMPCA $\log\ \hat\lambda$')
     ax[1][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[1][1].scatter(np.log(lam2[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][1].set_xlim(lim)
     ax[1][1].set_ylim(lim)
     ax[1][1].set_xlabel(r'PVAE $\log\ \hat\lambda$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('B cell validation $x = 0$')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[53]:
   [[file:figure/fitted-values.org/b_cells-val-0.png]]
   :END:

   Look at the average training log likelihoods.

   #+BEGIN_SRC ipython
     llik0 = st.poisson(lam0).logpmf(train)
     llik1 = st.poisson(lam1).logpmf(train)
     llik2 = st.poisson(lam2).logpmf(train)
     llik3 = st.poisson(lam3).logpmf(train)
     pd.Series({'NMF': llik0.mean(), 'GLMPCA': llik1.mean(), 'PVAE': llik2.mean(), 'NBVAE': llik3.mean()})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   #+BEGIN_EXAMPLE
     NMF      -1.038635
     GLMPCA   -1.035292
     PVAE     -1.055085
     NBVAE    -0.829223
     dtype: float64
   #+END_EXAMPLE
   :END:

   Look at the distribution of per-observation training log likelihood
   differences, stratified by observed value.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-train-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(4, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(train.max() + 1)
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement train\nlog lik over NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement train\nlog lik over NMF')
     ax[1].set_title('PVAE')

     for i in grid:
       ax[2].boxplot((llik3 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[2].axhline(y=0, ls=':', lw=1, c='r')
     ax[2].set_ylabel('Improvement train\nlog lik over NMF')
     ax[2].set_title('NBVAE')

     h, e = np.histogram(train.ravel(), bins=grid, density=True)
     ax[3].bar(e[:-1], h, color='k')
     ax[3].set_ylabel('Relative frequency')
     ax[3].set_xticks(grid[::5])
     ax[3].set_xticklabels(grid[::5].astype(int))
     ax[3].set_xlim(-.5, grid.max() - .5)
     ax[3].set_xlabel('Observation in training set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   [[file:figure/fitted-values.org/b_cells-train-llik-diff.png]]
   :END:

   Look at the total training log likelihood differences, stratified by
   observed value.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-train-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(train.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[train == i].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement train\nlog lik over NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[train == i].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement train\nlog lik over NMF')
     ax[1].set_title('PVAE')

     ax[2].bar(grid, np.array([(llik3 - llik0)[train == i].sum() for i in grid]), color='k')
     ax[2].axhline(y=0, ls=':', lw=1, c='r')
     ax[2].set_ylabel('Improvement train\nlog lik over NMF')
     ax[2].set_title('NBVAE')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in training set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   [[file:figure/fitted-values.org/b_cells-train-sum-llik-diff.png]]
   :END:

   Repeat the analysis for the validation data.

   #+BEGIN_SRC ipython
     s = (test.sum(axis=1) / train.sum(axis=1)).reshape(-1, 1)
     llik0 = np.ma.masked_invalid(st.poisson(s * lam0).logpmf(test))
     llik1 = st.poisson(s * lam1).logpmf(test)
     llik2 = st.poisson(s * lam2).logpmf(test)
     llik3 = st.poisson(s * lam3).logpmf(test)
     pd.Series({'NMF': llik0.mean(), 'GLMPCA': llik1.mean(), 'PVAE': llik2.mean(), 'NBVAE': llik3.mean()})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   #+BEGIN_EXAMPLE
     NMF      -1.190322
     GLMPCA   -1.089458
     PVAE     -1.070860
     NBVAE    -1.129492
     dtype: float64
   #+END_EXAMPLE
   :END:

   Report observations which are non-zero in the validation set, but the NMF estimate
   \(\hat\lambda_{ij} = 0\).

   #+BEGIN_SRC ipython
     test[np.where(llik0.mask)]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   #+BEGIN_EXAMPLE
     array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
     1., 1., 1., 1., 1., 1., 1., 1.])
   #+END_EXAMPLE
   :END:

   Report the corresponding observations in the training set.

   #+BEGIN_SRC ipython
     train[np.where(llik0.mask)]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   #+BEGIN_EXAMPLE
     array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
     0, 0, 0])
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(4, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(test.max())
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement val log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement val log lik\nover NMF')
     ax[1].set_title('PVAE')

     for i in grid:
       ax[2].boxplot((llik3 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[2].axhline(y=0, ls=':', lw=1, c='r')
     ax[2].set_ylabel('Improvement val log lik\nover NMF')
     ax[2].set_title('NBVAE')

     h, e = np.histogram(test.ravel(), bins=np.arange(test.max() + 1), density=True)
     ax[3].bar(e[:-1], h, color='k')
     ax[3].set_ylabel('Relative frequency')
     ax[3].set_xticks(grid[::5])
     ax[3].set_xticklabels(grid[::5].astype(int))
     ax[3].set_xlim(-.5, grid.max() - .5)
     ax[3].set_xlabel('Observation in validation set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   [[file:figure/fitted-values.org/b_cells-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(test.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[test == i].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[0].set_ylabel('Improvement val log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[test == i].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[1].set_ylabel('Improvement val log lik\nover NMF')
     ax[1].set_title('PVAE')

     ax[2].bar(grid, np.array([(llik3 - llik0)[test == i].sum() for i in grid]), color='k')
     ax[2].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[2].set_ylabel('Improvement val log lik\nover NMF')
     ax[2].set_title('NBPVAE')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in validation set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   [[file:figure/fitted-values.org/b_cells-sum-llik-diff.png]]
   :END:

   Count the fraction of observations equal to one in the validation set.

   #+BEGIN_SRC ipython
     (test == 1).sum() / np.prod(test.shape)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   : 0.18916266666666667
   :END:

   For observations which were equal to one in validation set, look at the
   distribution of training set values.

   #+BEGIN_SRC ipython
     pd.Series(dict(enumerate([np.logical_and(train == i, test == 1).sum() / (test == 1).sum() for i in range(4)])))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   #+BEGIN_EXAMPLE
     0    0.540092
     1    0.252876
     2    0.108506
     3    0.050398
     dtype: float64
   #+END_EXAMPLE
   :END:

   Look at the distribution of (a random sample of) randomized quantiles for
   each method.

   #+BEGIN_SRC ipython :async t
     train_qs = []
     test_qs = []
     for i, l in enumerate([lam0, lam1, lam2]):
       F = st.poisson(l)
       q = np.sort((F.cdf(train - 1) + np.random.uniform(size=train.shape) * F.pmf(train)).ravel()[::10])
       train_qs.append(q)
       q = np.sort((F.cdf(test - 1) + np.random.uniform(size=test.shape) * F.pmf(test)).ravel()[::10])
       test_qs.append(q)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[53]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-rpp.png
     cm = plt.get_cmap('Dark2')
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(5.5, 3)
     lim = [4e-7, 1]
     for a, qs, t in zip(ax.ravel(), [train_qs, test_qs], ['Training', 'Validation']):
       a.set_xscale('log')
       a.set_yscale('log')
       for i, (q, k) in enumerate(zip(qs, ['NMF', 'GLMPCA', 'PVAE'])):
         x = np.linspace(0, 1, q.shape[0] + 1)[1:]
         a.plot(x, np.sort(q), lw=1, c=cm(i), label=k)
         a.plot(lim, lim, lw=1, ls=':', c='0.7')
         a.set_xlim(lim)
         a.set_ylim(lim)
       a.set_xlabel('Theoretical quantile')
       a.set_title(t)
     ax[0].set_ylabel('Randomized quantile')
     ax[1].legend(frameon=False)
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[56]:
   [[file:figure/fitted-values.org/b_cells-rpp.png]]
   :END:

   Randomly mask 10% of the entries.

   #+BEGIN_SRC ipython
     w = scmodes.benchmark.imputation._mask_entries(x.values, frac=0.1, seed=0)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w', w)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[64]:
   :END:

   Fit WNMF, WGLMPCA, and WPVAE.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=mstephens -n1 -c8 --mem=8G --time=60:00
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     <<data>>
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     l, f, _ = scmodes.lra.nmf(train, w=w, rank=8, tol=1e-4, max_iters=100000, verbose=True)
     lam0 = l @ f.T
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wnmf-lam', lam0)

     l, f, _ = scmodes.lra.glmpca(train, w=w, rank=8, tol=1e-4, max_iters=100000, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wglmpca-lam', lam1)
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66239883

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     <<data>>
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     xt = torch.tensor(train, dtype=torch.float)
     wt = torch.tensor(w, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=10).fit(xt, w=wt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)
     lam2 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-lam', lam2)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-trace', np.array(m.trace))
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66240077

   Examine the PVAE optimization trace.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-wpvae-trace.png
     cm = plt.get_cmap('Dark2')
     plt.clf()
     plt.gcf().set_size_inches(4, 2)
     trace = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-trace.npy')
     for i, (t, s, k) in enumerate(zip(trace.T, [900, 100], ['Training', 'Validation'])):
       plt.plot(np.log(t / s), lw=1, c=cm(i), label=k)
     plt.legend(frameon=False)
     plt.title('Weighted PVAE')
     plt.xlabel('Epoch')
     plt.ylabel('Avg log neg ELBO')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   [[file:figure/fitted-values.org/b_cells-wpvae-trace.png]]
   :END:

   Read the results.

   #+BEGIN_SRC ipython :async t
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     lam0 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wnmf-lam.npy')
     lam1 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wglmpca-lam.npy')
     lam2 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-lam.npy')
     llik0 = st.poisson(lam0).logpmf(train)
     llik1 = st.poisson(lam1).logpmf(train)
     llik2 = st.poisson(lam2).logpmf(train)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Report the log likelihood of masked entries.

   #+BEGIN_SRC ipython
     pd.Series({'NMF': llik0[~w].mean(), 'GLMPCA': llik1[~w].mean(), 'PVAE': llik2[~w].mean()})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   #+BEGIN_EXAMPLE
     NMF      -0.259506
     GLMPCA   -0.256485
     PVAE     -0.262147
     dtype: float64
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-unmasked-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(train.max() + 1)
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[np.logical_and(w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[np.logical_and(w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')

     h, e = np.histogram(train[w].ravel(), bins=grid, density=True)
     ax[2].bar(e[:-1], h, color='k')
     ax[2].set_ylabel('Relative frequency')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in unmasked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   [[file:figure/fitted-values.org/b_cells-unmasked-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-unmasked-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(2, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(train.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[np.logical_and(w, train == i)].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[np.logical_and(w, train == i)].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')
     ax[1].set_xticks(grid[::5])
     ax[1].set_xticklabels(grid[::5].astype(int))
     ax[1].set_xlim(-.5, grid.max() - .5)
     ax[1].set_xlabel('Observation in unmasked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   [[file:figure/fitted-values.org/b_cells-unmasked-sum-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-masked-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(train.max() + 1)
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[np.logical_and(~w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[np.logical_and(~w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')

     h, e = np.histogram(train[~w].ravel(), bins=grid, density=True)
     ax[2].bar(e[:-1], h, color='k')
     ax[2].set_ylabel('Relative frequency')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in masked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   [[file:figure/fitted-values.org/b_cells-masked-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-masked-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(2, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(train.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[np.logical_and(~w, train == i)].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[np.logical_and(~w, train == i)].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')
     ax[1].set_xticks(grid[::5])
     ax[1].set_xticklabels(grid[::5].astype(int))
     ax[1].set_xlim(-.5, grid.max() - .5)
     ax[1].set_xlabel('Observation in masked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   [[file:figure/fitted-values.org/b_cells-masked-sum-llik-diff.png]]
   :END:

   Examine the case where GLM-PCA appears to fail.

   #+BEGIN_SRC ipython :async t
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     l, f, _ = scmodes.lra.glmpca(train, w=w, rank=4, tol=1e-2, max_iters=10000, verbose=True)
     lam = np.exp(l @ f.T)
   #+END_SRC

   #+BEGIN_SRC ipython
     -np.where(w, st.poisson(mu=lam).logpmf(train), 0).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[108]:
   : 469460.7112869973
   :END:

   #+BEGIN_SRC ipython
     -np.where(~w, st.poisson(mu=lam).logpmf(train), 0).mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[97]:
   : 1.5974443522458214e+50
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-wglmpca-4.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.scatter(train[~w].ravel(), lam[~w].ravel(), s=1, alpha=0.1, c='k')
     plt.xlabel('Masked value')
     plt.ylabel('Fitted value')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[99]:
   [[file:figure/fitted-values.org/b_cells-wglmpca-4.png]]
   :END:

   Find the outlier.

   #+BEGIN_SRC ipython
     np.where(lam == lam.max()), train[np.where(lam == lam.max())]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[140]:
   : ((array([895]), array([353])), array([1.]))
   :END:

   #+BEGIN_SRC ipython
     l[895], f[353]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[141]:
   #+BEGIN_EXAMPLE
     (array([ 0.40541451,  0.54979576,  0.95922746, -1.09842433]),
     array([ -3.27497815, 235.22646683,   5.0478365 ,   4.01345086]))
   #+END_EXAMPLE
   :END:

   Look at the remainder of the fitted values.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-wglmpca-4-inset.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     lim = [0, 97]
     plt.scatter(train[~w].ravel(), lam[~w].ravel(), s=1, alpha=0.1, c='k')
     plt.plot(lim, lim, c='r', lw=1, ls=':')
     plt.xlim(lim)
     plt.ylim(lim)
     plt.xlabel('Masked value')
     plt.ylabel('Fitted value')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[128]:
   [[file:figure/fitted-values.org/b_cells-wglmpca-4-inset.png]]
   :END:

   #+BEGIN_SRC ipython :async t
     l1, f1, loss1 = scmodes.lra.glmpca(train, w=w, rank=4, tol=5e-2, max_iters=10000, verbose=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[142]:
   :END:

   #+BEGIN_SRC ipython
     -np.where(~w, st.poisson(mu=np.exp(l1 @ f1.T)).logpmf(train), 0).mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[145]:
   : 6.651556782196484e+18
   :END:

** T cells

   #+BEGIN_SRC ipython :async t
     x = data['cytotoxic_t']()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.nmf(x.values, rank=3, verbose=True)
     lam0 = l @ f.T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.glmpca(x.values, rank=3, atol=.1, max_iters=500, verbose=True)
     lam1 = np.exp(l @ f.T)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC ipython :async t
     xt = torch.tensor(x.values, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=True)
     lam2 = m.denoise(xt)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/t_cells.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 8], [0, 8], lw=1, ls=':', c='r')
     ax[0].set_xticks([0, 4, 8])
     ax[0].set_yticks([0, 4, 8])
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 8], [0, 8], lw=1, ls=':', c='r')
     ax[1].set_xticks([0, 4, 8])
     ax[1].set_yticks([0, 4, 8])
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('T cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   [[file:figure/fitted-values.org/t_cells.png]]
   :END:

** iPSCs

   #+BEGIN_SRC ipython :async t
     x = data['ipsc']()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.nmf(x.values, rank=2, verbose=True)
     lam0 = l @ f.T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.glmpca(x.values, rank=2, atol=.1, max_iters=500, verbose=True)
     lam1 = np.exp(l @ f.T)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[12]:
   :END:

   #+BEGIN_SRC ipython :async t
     xt = torch.tensor(x.values, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=True)
     lam2 = m.denoise(xt)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   :END:

   #+BEGIN_SRC ipython :async t :ipyfile figure/fitted-values.org/ipsc.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 30], [0, 30], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 30], [0, 30], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('iPSC')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   [[file:figure/fitted-values.org/ipsc.png]]
   :END:

** T cell/B cell

   Split the data into training and validation sets using binomial thinning, then fit
   NMF, GLMPCA, and PVAE.

   #+BEGIN_SRC ipython :async t
     # Important: this implicitly sets the random seed
     x = data['cytotoxic_t-b_cells']()
     train, test = scmodes.benchmark.train_test_split(x)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-train', train.values)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-test', test.values)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 --mem=8G --time=24:00:00
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-train.npy')
     l, f, _ = scmodes.lra.nmf(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)
     lam0 = l @ f.T
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-nmf-lam', lam0)

     l, f, _ = scmodes.lra.glmpca(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-glmpca-lam', lam1)
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66424054

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-train.npy')
     xt = torch.tensor(train, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=8).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)
     lam2 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-pvae-lam', lam2)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-pvae-trace', np.array(m.trace))
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66424053

   #+BEGIN_SRC ipython :async t :ipyfile figure/fitted-values.org/cytotoxic_t-b_cells.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 10], [0, 10], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 10], [0, 10], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('T cell/B cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   [[file:figure/fitted-values.org/cytotoxic_t-b_cells.png]]
   :END:
** PBMC

   Split the data into training and validation sets using binomial thinning, then fit
   NMF, GLMPCA, and PVAE.

   #+BEGIN_SRC ipython :async t
     # Important: this implicitly sets the random seed
     x = data['pbmcs_68k']()
     train, test = scmodes.benchmark.train_test_split(x)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-train', train.values)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-test', test.values)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -n1 --mem=8G --time=24:00:00
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-train.npy')
     l, f, _ = scmodes.lra.nmf(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)
     lam0 = l @ f.T
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-nmf-lam', lam0)

     l, f, _ = scmodes.lra.glmpca(train, rank=8, tol=1e-2, max_iters=100000, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-glmpca-lam', lam1)
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66424128

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-train.npy')
     xt = torch.tensor(train, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=8).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)
     lam2 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-pvae-lam', lam2)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/pbmcs_68k-pvae-trace', np.array(m.trace))
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66424075

   #+BEGIN_SRC ipython :async t :ipyfile figure/fitted-values.org/pbmcs_68k.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 10], [0, 10], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 10], [0, 10], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('T cell/B cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   [[file:figure/fitted-values.org/pbmcs_68k.png]]
   :END:
