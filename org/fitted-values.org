#+TITLE: Comparison of fitted values
#+SETUPFILE: setup.org

* Introduction

  We previously found that NMF, GLM-PCA, and PVAE all had similar average
  performance on a [[file:lra.org][binomial thinning benchmark]]. Here, we
  investigate the per-observation performance of these methods.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "fitted-values.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="mstephens",memory="16G") :exports none :dir /scratch/midway2/aksarkar/modes

  #+RESULTS:
  : Submitted batch job 66244790

  #+NAME: imports
  #+BEGIN_SRC ipython
    import numpy as np
    import pandas as pd
    import scipy.stats as st
    import scmodes
    import torch
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[4]:
  :END:

* Results
** Datasets

   Follow the data processing we used for [[file:imputation.org][masked value
   estimation]].

   #+NAME: data
   #+BEGIN_SRC ipython
     def _read_10x(k, min_detect=0.01, n_cells=1000, seed=1):
       return scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k}/filtered_matrices_mex/hg19/', min_detect=0.01, return_df=True).sample(n=n_cells, axis=0, random_state=seed)

     def _mix_10x(k1, k2, min_detect=0.01, n_cells=1000, seed=1):
       x1 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k1}/filtered_matrices_mex/hg19/', return_df=True, min_detect=0)
       x2 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k2}/filtered_matrices_mex/hg19/', return_df=True, min_detect=0)
       return scmodes.dataset.synthetic_mix(x1, x2, min_detect=min_detect)[0].sample(n=n_cells, axis=0, random_state=seed)

     def _cd8_cd19_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'b_cells', **kwargs)

     def _cyto_naive_mix(**kwargs):
       return _mix_10x('cytotoxic_t', 'naive_t', **kwargs)

     data = {
       'cytotoxic_t': lambda: _read_10x('cytotoxic_t'),
       'b_cells': lambda: _read_10x('b_cells'),
       'ipsc': lambda: scmodes.dataset.ipsc('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/', return_df=True).sample(n=1000, axis=0, random_state=1),
       'cytotoxic_t-b_cells': _cd8_cd19_mix,
       'cytotoxic_t-naive_t': _cyto_naive_mix,
       'pbmcs_68k': lambda: _read_10x('fresh_68k_pbmc_donor_a'),
     }
   #+END_SRC

   #+RESULTS: data
   :RESULTS:
   # Out[5]:
   :END:

   Report the data dimensions.

   #+BEGIN_SRC ipython :async t
     pd.DataFrame([data[k]().shape for k in data],
                  columns=['num_cells', 'num_genes'],
                  index=data.keys())
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   #+BEGIN_EXAMPLE
     num_cells  num_genes
     cytotoxic_t               1000       6530
     b_cells                   1000       6417
     ipsc                      1000       9957
     cytotoxic_t-b_cells       1000       6647
     cytotoxic_t-naive_t       1000       6246
     pbmcs_68k                 1000       6502
   #+END_EXAMPLE
   :END:

** B cells
   :PROPERTIES:
   :CUSTOM_ID: b-cells
   :END:

   Split the data into training and validation sets using binomial thinning, then fit
   NMF, GLMPCA, and PVAE.

   #+BEGIN_SRC ipython :async t
     # Important: this implicitly sets the random seed
     x = data['b_cells']()
     train, test = scmodes.benchmark.train_test_split(x)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train', train.values)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-test', test.values)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[63]:
   :END:

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=mstephens -n1 -c8 --mem=8G --time=60:00
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')
     l, f, _ = scmodes.lra.nmf(train, rank=2, tol=1e-4, max_iters=100000, verbose=True)
     lam0 = l @ f.T
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nmf-lam', lam0)

     l, f, _ = scmodes.lra.glmpca(train, rank=2, tol=1e-4, max_iters=100000, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-glmpca-lam', lam1)
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66213427

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')
     xt = torch.tensor(train, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=10).fit(xt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)
     lam2 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-lam', lam2)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-trace', np.array(m.trace))
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66239199

   Examine the PVAE optimization trace.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-pvae-trace.png
     cm = plt.get_cmap('Dark2')
     plt.clf()
     plt.gcf().set_size_inches(4, 2)
     trace = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-trace.npy')
     for i, (t, s, k) in enumerate(zip(trace.T, [900, 100], ['Training', 'Validation'])):
       plt.plot(np.log(t / s), lw=1, c=cm(i), label=k)
     plt.legend(frameon=False)
     plt.xlabel('Epoch')
     plt.ylabel('Avg log neg ELBO')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[43]:
   [[file:figure/fitted-values.org/b_cells-pvae-trace.png]]
   :END:

   Read the results.

   #+BEGIN_SRC ipython
     train = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-train.npy')
     test = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-test.npy')
     lam0 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-nmf-lam.npy')
     lam1 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-glmpca-lam.npy')
     lam2 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-pvae-lam.npy')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   :END:

   Compare the fitted values of each method against other.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 11], [0, 11], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 11], [0, 11], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('B cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[45]:
   [[file:figure/fitted-values.org/b_cells.png]]
   :END:

   Compare the fitted values of each method against each other, only for
   observations which were 1 in the validation data.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-val-1.png
     plt.clf()
     fig, ax = plt.subplots(2, 2)
     fig.set_size_inches(4, 4)

     query = np.isclose(test, 1)
     lim = [-400, 5]
     ax[0][0].scatter(np.log(lam1[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[0][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][0].set_xlim(lim)
     ax[0][0].set_ylim(lim)
     ax[0][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[0][1].scatter(np.log(lam2[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[0][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][1].set_xlim(lim)
     ax[0][1].set_ylim(lim)

     lim = [-20, 5]
     ax[0][0].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))
     ax[0][1].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))

     ax[1][0].scatter(np.log(lam1[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[1][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][0].set_xlim(lim)
     ax[1][0].set_ylim(lim)
     ax[1][0].set_xlabel(r'GLMPCA $\log\ \hat\lambda$')
     ax[1][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[1][1].scatter(np.log(lam2[query].ravel()), np.log(lam0[query].ravel()), s=1, c='k', alpha=0.1)
     ax[1][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][1].set_xlim(lim)
     ax[1][1].set_ylim(lim)
     ax[1][1].set_xlabel(r'PVAE $\log\ \hat\lambda$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('B cell validation $x = 1$')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[57]:
   [[file:figure/fitted-values.org/b_cells-val-1.png]]
   :END:

   Repeat for observations which were 0 in the validation data.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-val-0.png
     plt.clf()
     fig, ax = plt.subplots(2, 2)
     fig.set_size_inches(4, 4)

     query = np.isclose(test, 0)
     lim = [-400, 5]
     ax[0][0].scatter(np.log(lam1[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][0].set_xlim(lim)
     ax[0][0].set_ylim(lim)
     ax[0][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[0][1].scatter(np.log(lam2[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[0][1].set_xlim(lim)
     ax[0][1].set_ylim(lim)

     lim = [-20, 5]
     ax[0][0].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))
     ax[0][1].add_patch(plt.Rectangle((lim[0], lim[0]), lim[1] - lim[0], lim[1] - lim[0], fill=False, color='b'))

     ax[1][0].scatter(np.log(lam1[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1][0].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][0].set_xlim(lim)
     ax[1][0].set_ylim(lim)
     ax[1][0].set_xlabel(r'GLMPCA $\log\ \hat\lambda$')
     ax[1][0].set_ylabel(r'NMF $\log\ \hat\lambda$')

     ax[1][1].scatter(np.log(lam2[query].ravel()[::50]), np.log(lam0[query].ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1][1].plot(lim, lim, lw=1, ls=':', c='r')
     ax[1][1].set_xlim(lim)
     ax[1][1].set_ylim(lim)
     ax[1][1].set_xlabel(r'PVAE $\log\ \hat\lambda$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('B cell validation $x = 0$')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[53]:
   [[file:figure/fitted-values.org/b_cells-val-0.png]]
   :END:

   Look at the average training log likelihoods.

   #+BEGIN_SRC ipython
     llik0 = st.poisson(lam0).logpmf(train)
     llik1 = st.poisson(lam1).logpmf(train)
     llik2 = st.poisson(lam2).logpmf(train)
     pd.Series({'NMF': llik0.mean(), 'GLMPCA': llik1.mean(), 'PVAE': llik2.mean()})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   #+BEGIN_EXAMPLE
     NMF      -0.163096
     GLMPCA   -0.163275
     PVAE     -0.161215
     dtype: float64
   #+END_EXAMPLE
   :END:

   Look at the distribution of per-observation training log likelihood
   differences, stratified by observed value.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-train-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(train.max() + 1)
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement train\nlog lik over NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[train == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement train\nlog lik over NMF')
     ax[1].set_title('PVAE')

     h, e = np.histogram(train.ravel(), bins=grid, density=True)
     ax[2].bar(e[:-1], h, color='k')
     ax[2].set_ylabel('Relative frequency')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in training set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[48]:
   [[file:figure/fitted-values.org/b_cells-train-llik-diff.png]]
   :END:

   Look at the total training log likelihood differences, stratified by
   observed value.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-train-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(2, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(train.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[train == i].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement train\nlog lik over NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[train == i].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement train\nlog lik over NMF')
     ax[1].set_title('PVAE')
     ax[1].set_xticks(grid[::5])
     ax[1].set_xticklabels(grid[::5].astype(int))
     ax[1].set_xlim(-.5, grid.max() - .5)
     ax[1].set_xlabel('Observation in training set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[49]:
   [[file:figure/fitted-values.org/b_cells-train-sum-llik-diff.png]]
   :END:

   Repeat the analysis for the validation data.

   #+BEGIN_SRC ipython
     s = (test.sum(axis=1) / train.sum(axis=1)).reshape(-1, 1)
     llik0 = np.ma.masked_invalid(st.poisson(s * lam0).logpmf(test))
     llik1 = st.poisson(s * lam1).logpmf(test)
     llik2 = st.poisson(s * lam2).logpmf(test)
     pd.Series({'NMF': llik0.mean(), 'GLMPCA': llik1.mean(), 'PVAE': llik2.mean()})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[50]:
   #+BEGIN_EXAMPLE
     NMF      -0.181994
     GLMPCA   -0.166435
     PVAE     -0.167921
     dtype: float64
   #+END_EXAMPLE
   :END:

   Report observations which are non-zero in the validation set, but the NMF estimate
   \(\hat\lambda_{ij} = 0\).

   #+BEGIN_SRC ipython
     test[np.where(llik0.mask)]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   #+BEGIN_EXAMPLE
     array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
     1., 1., 1., 1., 1., 1., 1., 1.])
   #+END_EXAMPLE
   :END:

   Report the corresponding observations in the training set.

   #+BEGIN_SRC ipython
     train[np.where(llik0.mask)]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   #+BEGIN_EXAMPLE
     array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
     0, 0, 0])
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(test.max())
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement val log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[test == i].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement val log lik\nover NMF')
     ax[1].set_title('PVAE')

     h, e = np.histogram(test.ravel(), bins=np.arange(test.max() + 1), density=True)
     ax[2].bar(e[:-1], h, color='k')
     ax[2].set_ylabel('Relative frequency')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in validation set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[51]:
   [[file:figure/fitted-values.org/b_cells-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(2, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(test.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[test == i].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[0].set_ylabel('Improvement val log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[test == i].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[1].set_ylabel('Improvement val log lik\nover NMF')
     ax[1].set_title('PVAE')
     ax[1].set_xticks(grid[::5])
     ax[1].set_xticklabels(grid[::5].astype(int))
     ax[1].set_xlim(-.5, grid.max() - .5)
     ax[1].set_xlabel('Observation in validation set')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[52]:
   [[file:figure/fitted-values.org/b_cells-sum-llik-diff.png]]
   :END:

   Count the fraction of observations equal to one in the validation set.

   #+BEGIN_SRC ipython
     (test == 1).sum() / np.prod(test.shape)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   : 0.033023219573009195
   :END:

   For observations which were equal to one in validation set, look at the
   distribution of training set values.

   #+BEGIN_SRC ipython
     pd.Series(dict(enumerate([np.logical_and(train == i, test == 1).sum() / (test == 1).sum() for i in range(4)])))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   #+BEGIN_EXAMPLE
     0    0.786306
     1    0.139441
     2    0.040593
     3    0.017644
     dtype: float64
   #+END_EXAMPLE
   :END:

   Look at the distribution of (a random sample of) randomized quantiles for
   each method.

   #+BEGIN_SRC ipython :async t
     train_qs = []
     test_qs = []
     for i, l in enumerate([lam0, lam1, lam2]):
       F = st.poisson(l)
       q = np.sort((F.cdf(train - 1) + np.random.uniform(size=train.shape) * F.pmf(train)).ravel()[::10])
       train_qs.append(q)
       q = np.sort((F.cdf(test - 1) + np.random.uniform(size=test.shape) * F.pmf(test)).ravel()[::10])
       test_qs.append(q)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[53]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-rpp.png
     cm = plt.get_cmap('Dark2')
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(5.5, 3)
     lim = [4e-7, 1]
     for a, qs, t in zip(ax.ravel(), [train_qs, test_qs], ['Training', 'Validation']):
       a.set_xscale('log')
       a.set_yscale('log')
       for i, (q, k) in enumerate(zip(qs, ['NMF', 'GLMPCA', 'PVAE'])):
         x = np.linspace(0, 1, q.shape[0] + 1)[1:]
         a.plot(x, np.sort(q), lw=1, c=cm(i), label=k)
         a.plot(lim, lim, lw=1, ls=':', c='0.7')
         a.set_xlim(lim)
         a.set_ylim(lim)
       a.set_xlabel('Theoretical quantile')
       a.set_title(t)
     ax[0].set_ylabel('Randomized quantile')
     ax[1].legend(frameon=False)
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[56]:
   [[file:figure/fitted-values.org/b_cells-rpp.png]]
   :END:

   Randomly mask 10% of the entries.

   #+BEGIN_SRC ipython
     w = scmodes.benchmark.imputation._mask_entries(x.values, frac=0.1, seed=0)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w', w)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[64]:
   :END:

   Fit WNMF, WGLMPCA, and WPVAE.

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=mstephens -n1 -c8 --mem=8G --time=60:00
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     <<data>>
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     l, f, _ = scmodes.lra.nmf(train, w=w, rank=2, tol=1e-4, max_iters=100000, verbose=True)
     lam0 = l @ f.T
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wnmf-lam', lam0)

     l, f, _ = scmodes.lra.glmpca(train, w=w, rank=2, tol=1e-4, max_iters=100000, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wglmpca-lam', lam1)
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66239883

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     <<data>>
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     xt = torch.tensor(train, dtype=torch.float)
     wt = torch.tensor(w, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=train.shape[1], latent_dim=10).fit(xt, w=wt, test_size=0.1, lr=1e-3, max_epochs=200, trace=True)
     lam2 = m.denoise(xt, n_samples=100)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-lam', lam2)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-trace', np.array(m.trace))
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 66240077

   Examine the PVAE optimization trace.

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-wpvae-trace.png
     cm = plt.get_cmap('Dark2')
     plt.clf()
     plt.gcf().set_size_inches(4, 2)
     trace = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-trace.npy')
     for i, (t, s, k) in enumerate(zip(trace.T, [900, 100], ['Training', 'Validation'])):
       plt.plot(np.log(t / s), lw=1, c=cm(i), label=k)
     plt.legend(frameon=False)
     plt.title('Weighted PVAE')
     plt.xlabel('Epoch')
     plt.ylabel('Avg log neg ELBO')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   [[file:figure/fitted-values.org/b_cells-wpvae-trace.png]]
   :END:

   Read the results.

   #+BEGIN_SRC ipython :async t
     train = data['b_cells']().values
     w = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-w.npy')
     lam0 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wnmf-lam.npy')
     lam1 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wglmpca-lam.npy')
     lam2 = np.load('/scratch/midway2/aksarkar/modes/fitted-values/b_cells-wpvae-lam.npy')
     llik0 = st.poisson(lam0).logpmf(train)
     llik1 = st.poisson(lam1).logpmf(train)
     llik2 = st.poisson(lam2).logpmf(train)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Report the log likelihood of masked entries.

   #+BEGIN_SRC ipython
     pd.Series({'NMF': llik0[~w].mean(), 'GLMPCA': llik1[~w].mean(), 'PVAE': llik2[~w].mean()})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   #+BEGIN_EXAMPLE
     NMF      -0.259506
     GLMPCA   -0.256485
     PVAE     -0.262147
     dtype: float64
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-unmasked-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(train.max() + 1)
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[np.logical_and(w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[np.logical_and(w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')

     h, e = np.histogram(train[w].ravel(), bins=grid, density=True)
     ax[2].bar(e[:-1], h, color='k')
     ax[2].set_ylabel('Relative frequency')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in unmasked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   [[file:figure/fitted-values.org/b_cells-unmasked-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-unmasked-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(2, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(train.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[np.logical_and(w, train == i)].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[np.logical_and(w, train == i)].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')
     ax[1].set_xticks(grid[::5])
     ax[1].set_xticklabels(grid[::5].astype(int))
     ax[1].set_xlim(-.5, grid.max() - .5)
     ax[1].set_xlabel('Observation in unmasked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   [[file:figure/fitted-values.org/b_cells-unmasked-sum-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-masked-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(3, 1, sharex=True)
     fig.set_size_inches(7, 6)

     grid = np.arange(train.max() + 1)
     for i in grid:
       ax[0].boxplot((llik1 - llik0)[np.logical_and(~w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[0].axhline(y=0, ls=':', lw=1, c='r')
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     for i in grid:
       ax[1].boxplot((llik2 - llik0)[np.logical_and(~w, train == i)].ravel(), positions=[i], widths=[0.5], medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 2})
     ax[1].axhline(y=0, ls=':', lw=1, c='r')
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')

     h, e = np.histogram(train[~w].ravel(), bins=grid, density=True)
     ax[2].bar(e[:-1], h, color='k')
     ax[2].set_ylabel('Relative frequency')
     ax[2].set_xticks(grid[::5])
     ax[2].set_xticklabels(grid[::5].astype(int))
     ax[2].set_xlim(-.5, grid.max() - .5)
     ax[2].set_xlabel('Observation in masked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   [[file:figure/fitted-values.org/b_cells-masked-llik-diff.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/b_cells-masked-sum-llik-diff.png
     plt.clf()
     fig, ax = plt.subplots(2, 1, sharex=True)
     fig.set_size_inches(7, 4)

     grid = np.arange(train.max() + 1)
     ax[0].bar(grid, np.array([(llik1 - llik0)[np.logical_and(~w, train == i)].sum() for i in grid]), color='k')
     ax[0].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[0].set_ylabel('Improvement log lik\nover NMF')
     ax[0].set_title('GLMPCA')

     ax[1].bar(grid, np.array([(llik2 - llik0)[np.logical_and(~w, train == i)].sum() for i in grid]), color='k')
     ax[1].axhline(y=0, ls=':', lw=1, c='r', zorder=-3)
     ax[1].set_ylabel('Improvement log lik\nover NMF')
     ax[1].set_title('PVAE')
     ax[1].set_xticks(grid[::5])
     ax[1].set_xticklabels(grid[::5].astype(int))
     ax[1].set_xlim(-.5, grid.max() - .5)
     ax[1].set_xlabel('Observation in masked data')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   [[file:figure/fitted-values.org/b_cells-masked-sum-llik-diff.png]]
   :END:


** T cells

   #+BEGIN_SRC ipython :async t
     x = data['cytotoxic_t']()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.nmf(x.values, rank=3, verbose=True)
     lam0 = l @ f.T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.glmpca(x.values, rank=3, atol=.1, max_iters=500, verbose=True)
     lam1 = np.exp(l @ f.T)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC ipython :async t
     xt = torch.tensor(x.values, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=True)
     lam2 = m.denoise(xt)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/fitted-values.org/t_cells.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 8], [0, 8], lw=1, ls=':', c='r')
     ax[0].set_xticks([0, 4, 8])
     ax[0].set_yticks([0, 4, 8])
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 8], [0, 8], lw=1, ls=':', c='r')
     ax[1].set_xticks([0, 4, 8])
     ax[1].set_yticks([0, 4, 8])
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('T cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   [[file:figure/fitted-values.org/t_cells.png]]
   :END:

** iPSCs

   #+BEGIN_SRC ipython :async t
     x = data['ipsc']()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.nmf(x.values, rank=2, verbose=True)
     lam0 = l @ f.T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.glmpca(x.values, rank=2, atol=.1, max_iters=500, verbose=True)
     lam1 = np.exp(l @ f.T)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[12]:
   :END:

   #+BEGIN_SRC ipython :async t
     xt = torch.tensor(x.values, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=True)
     lam2 = m.denoise(xt)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   :END:

   #+BEGIN_SRC ipython :async t :ipyfile figure/fitted-values.org/ipsc.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 30], [0, 30], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 30], [0, 30], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('iPSC')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   [[file:figure/fitted-values.org/ipsc.png]]
   :END:
** T cell/B cell

   #+BEGIN_SRC ipython :async t
     x = data['cytotoxic_t-b_cells']()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.nmf(x.values, rank=3, verbose=True)
     lam0 = l @ f.T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   :END:

   #+BEGIN_SRC ipython :async t
     l, f, _ = scmodes.lra.glmpca(x.values, rank=3, atol=.1, max_iters=500, verbose=True)
     lam1 = np.exp(l @ f.T)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-wglmpca', lam1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   0 - 805adc4a-e03c-49cc-84a8-194be1441dd2
   :END:

   #+BEGIN_SRC ipython :async t
     xt = torch.tensor(x.values, dtype=torch.float)
     m = scmodes.lra.PVAE(input_dim=x.shape[1], latent_dim=5).fit(xt, lr=1e-3, max_epochs=2000, verbose=True)
     lam2 = m.denoise(xt)
     np.save('/scratch/midway2/aksarkar/modes/fitted-values/cytotoxic_t-b_cells-pvae', lam2)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[27]:
   :END:

   #+BEGIN_SRC ipython :async t :ipyfile figure/fitted-values.org/cytotoxic_t-b_cells.png
     plt.clf()
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 2.5)

     ax[0].scatter(np.sqrt(lam1.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[0].plot([0, 10], [0, 10], lw=1, ls=':', c='r')
     ax[0].set_xlabel(r'GLMPCA $\sqrt{\hat\lambda}$')
     ax[0].set_ylabel(r'NMF $\sqrt{\hat\lambda}$')

     ax[1].scatter(np.sqrt(lam2.ravel()[::50]), np.sqrt(lam0.ravel()[::50]), s=1, c='k', alpha=0.1)
     ax[1].plot([0, 10], [0, 10], lw=1, ls=':', c='r')
     ax[1].set_xlabel(r'PVAE $\sqrt{\hat\lambda}$')

     a = fig.add_subplot(111, frame_on=False, xticks=[], yticks=[])
     a.set_title('T cell/B cell')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   [[file:figure/fitted-values.org/cytotoxic_t-b_cells.png]]
   :END:
