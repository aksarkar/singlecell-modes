#+TITLE: Differential expression based on distribution deconvolution
#+SETUPFILE: setup.org

* Introduction

  For gene \(j\), consider the generative model for counts \(x_i, i=1, \ldots,
  n\):

  \[ x_i \mid s_i, \lambda_i \sim \mathrm{Pois}(s_i \lambda_i) \]

  \[ \lambda_i \sim g_{z_i}(\cdot) \]

  where \(z_i\) denotes group membership. *How do we use this model to test for
  differential expression?*

  Joyce Hsiao
  [[https://stephenslab.github.io/dsc-log-fold-change/eval_initial_type1.html][reports]]
  that commonly used count-based methods (deSeq2, edgeR) do not successfully
  control Type 1 error. But our preliminary results show a relatively simple
  count-based approach adequately controls Type 1 error here. There are two
  possible reasons:

  1. We are comparing much larger groups
  2. We are not shrinking dispersion parameters across genes

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="mstephens") :exports none :dir /scratch/midway2/aksarkar/modes

  #+RESULTS:
  : Submitted batch job 60555765

  #+BEGIN_SRC ipython
    import numpy as np
    import pandas as pd
    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import scipy.stats as st
    import scmodes
    import scqtl.simple

    mass = rpy2.robjects.packages.importr('MASS')
    rpy2.robjects.pandas2ri.activate()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Methods
** Deconvolution-based test

   In the simplest case, suppose \(g_k = \delta_{\mu_k}\). Then,

   \[ \hat\mu_k = \frac{\sum_i [z_i = k] x_i}{\sum_i [z_i = k] s_i} \]

   This suggests a simple likelihood ratio test, comparing the null model

   \[ x_i \sim \mathrm{Pois}(s_i \mu_0) \]

   against an alternative model:

   \[ x_i \sim \mathrm{Pois}(s_i \mu_{z_i}) \]

   More generally, we can compare the null model:

   \[ x_i \sim \mathrm{Pois}(s_i \lambda_i) \]

   \[ \lambda_i \sim g_0(\cdot) \]

   against an alternative model:

   \[ x_i \sim \mathrm{Pois}(s_i \lambda_i) \]

   \[ \lambda_i \sim g_{z_i}(\cdot) \]

   In the general case, it will not be true that \(-2 \ln(l_0 - l_1) \sim
   \chi^2_1\). However, for the case where \(g\) is assumed to be Gamma
   distributed, it will be \(\chi^2_1\) or \(\chi^2_2\), depending on whether
   we allow dispersions to vary across groups also.

** Realistic null simulation

   Take a real homogeneous data set (sorted cells from Zheng et al. 2017), and
   randomly partition samples into two groups.

   #+BEGIN_SRC ipython
     cd8 = scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19/', return_df=True)
     s = cd8.sum(axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   #+BEGIN_SRC ipython
     np.random.seed(0)
     z = np.random.uniform(size=cd8.shape[0]) < 0.5
     z.mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   : 0.5071015770398668
   :END:

* Results
** Point-mass deconvolution
   :PROPERTIES:
   :CUSTOM_ID: poisson
   :END:

   First look at an idealized case where
   [[https://stephens999.github.io/misc/simple_transform_simulation.html][log-transform
   fails]].

   #+BEGIN_SRC ipython :async t
     np.random.seed(0)
     N = 100
     onehot = np.zeros((2 * N, 2))
     onehot[:N, 0] = 1
     onehot[N:, 1] = 1
     s = onehot.dot(np.array([1e5, 2e5]))
     mu = 1e-5

     llrs = []
     pvals = []
     for trial in range(1000):
       x = np.random.poisson(lam=s * mu)
       mu0 = x.sum() / s.sum()
       mu1 = x[:N].sum() / s[:N].sum()
       mu2 = x[N:].sum() / s[N:].sum()
       llr = st.poisson(mu=mu0).logpmf(x).sum() - st.poisson(mu=onehot.dot(np.array([mu1, mu2]))).logpmf(x).sum()
       llrs.append(llr)
     llrs = np.array(llrs)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[74]:
   :END:

   Look at the QQ plot.

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/idealized-qq.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.scatter(st.chi2(1).ppf(np.linspace(0, 1, llrs.shape[0])), np.sort(-2 * llrs), c='k', s=2)
     plt.plot([0, 11], [0, 11], c='r', lw=1, ls=':')
     plt.xlabel('Expected chi-square')
     plt.ylabel('Observed chi-square')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[88]:
   : Text(0, 0.5, 'Observed chi-square')
   [[file:figure/deconv-de.org/idealized-qq.png]]
   :END:

   Look at the histogram of p-values.

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/idealized.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(st.chi2(1).sf(-2 * llrs), np.linspace(0, 1, 11), density=True, color='black')
     plt.axhline(y=1, lw=1, ls=':', c='r')
     plt.xlabel('P-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[92]:
   [[file:figure/deconv-de.org/idealized.png]]
   :END:



   Deconvolve gene expression assuming \(g\) is a point mass (counts are
   marginally Poisson distributed). Naively, this should work because the data
   are informative about the mean.

   #+BEGIN_SRC ipython
     def de(x, s, z):
       """Return LRT p-value

       x - counts (n,)
       s - size factors (n,)
       z - boolean group assignment (n,)

       """
       mu0 = x.sum() / s.sum()
       mu1 = x[z].sum() / s[z].sum()
       mu2 = x[~z].sum() / s[~z].sum()
       onehot = pd.get_dummies(z)
       llr = st.poisson(mu=mu0).logpmf(x).sum() - st.poisson(mu=onehot.dot(np.array([mu1, mu2]))).logpmf(x).sum()
       return pd.Series({'mu0': mu0, 'mu1': mu1, 'mu2': mu2, 'llr': llr, 'p': st.chi2(1).sf(-2 * llr)})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   :END:

   #+BEGIN_SRC ipython :async t
     de_res = cd8.apply(de, axis=0, args=(s, z)).T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[138]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/zheng-null.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(de_res.loc[:,'p'], np.linspace(0, 1, 11), density=True, color='black')
     plt.axhline(y=1, lw=1, ls=':', c='r')
     plt.xlabel('P-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[144]:
   [[file:figure/deconv-de.org/zheng-null.png]]
   :END:

   Report the proportion of genes for which the null model fit better than the
   alternative model.

   #+BEGIN_SRC ipython
     (de_res['llr'] > 0).mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[154]:
   : 0.6529284164859002
   :END:

   Look at the gene where the null model did best against the alternative.

   #+NAME: read-gene-info
   #+BEGIN_SRC ipython
     gene_info = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS: read-gene-info
   :RESULTS:
   # Out[159]:
   :END:

   #+BEGIN_SRC ipython
     k = de_res['llr'].idxmax()
     x = cd8.loc[:,k]
     gene_info.loc[k]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[172]:
   #+BEGIN_EXAMPLE
     chr             hs15
     start       69745123
     end         69748255
     name           RPLP1
     strand             +
     source    H. sapiens
     Name: ENSG00000137818, dtype: object
   #+END_EXAMPLE
   :END:

   Look at the deconvolved distributions for this gene. Superimpose the Poisson
   point-mass estimates for the two groups (dotted lines), and the Gamma mean
   estimate (dashed line).

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/cd8-rplp1.png
     plt.clf()
     fig, ax = plt.subplots(2, 1)
     fig.set_size_inches(6, 4)
     ax[0].hist(x[z], bins=np.arange(x.max() + 1), alpha=0.6, color='k', label='Group 1')
     ax[0].hist(x[~z], bins=np.arange(x.max() + 1), alpha=0.6, color='r', label='Group 2')
     ax[0].legend(frameon=False)
     ax[0].set_xlabel('Num mols')
     ax[0].set_ylabel('Num cells')

     for c, m in zip(plt.get_cmap('Dark2').colors, ['Gamma', 'ZIG', 'Unimodal', 'ZIEF', 'NPMLE']):
       ax[1].plot(*getattr(scmodes.deconvolve, f'fit_{m.lower()}')(x, s), color=c, lw=1, label=m)

     ax[1].axvline(x=scqtl.simple.fit_nb(x, s)[0], c=plt.get_cmap('Dark2').colors[0], ls='--', lw=1)
     ax[1].axvline(x=de_res.loc[k, 'mu1'], c='k', ls=':', lw=1)
     ax[1].axvline(x=de_res.loc[k, 'mu2'], c='r', ls=':', lw=1)

     ax[1].set_xlabel('Latent gene expression')
     ax[1].set_ylabel('CDF')
     ax[1].legend(frameon=False)
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[190]:
   [[file:figure/deconv-de.org/cd8-rplp1.png]]
   :END:

   Check whether also allowing dispersions to vary across groups fixes this
   gene.

   #+BEGIN_SRC ipython
     llr = scqtl.simple.fit_nb(x, s)[-1] - (scqtl.simple.fit_nb(x[z], s[z])[-1] + scqtl.simple.fit_nb(x[~z], s[~z])[-1])
     llr, st.chi2(2).sf(-2 * llr)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[198]:
   : (-2.176938147920737, 0.11338817750598136)
   :END:

   This result suggests that the Poisson sampling variance is not correctly
   estimated.

** Gamma deconvolution
   :PROPERTIES:
   :CUSTOM_ID: nb
   :END:

   Deconvolve gene expression assuming group-specific Gammas under the
   alternative.

   #+BEGIN_SRC ipython
     def fit_nb_collapse(x, s):
       """Return NB or Poisson solution, whichever is more sensible"""
       try:
         res = scqtl.simple.fit_nb(x, s)
       except:
         # Failure to converge
         res = scqtl.simple.fit_pois(x, s)
       # Converged to solution with large inverse overdispersion, so log likelihood
       # is nonsense
       if res[-1] > 0:
         res = scqtl.simple.fit_pois(x, s)
       return res

     def de_nb(x, s, z):
       """Return LRT p-value

       x - counts (n,)
       s - size factors (n,)
       z - boolean group assignment (n,)

       """
       res0 = fit_nb_collapse(x, s)
       res1 = fit_nb_collapse(x[z], s[z])
       res2 = fit_nb_collapse(x[~z], s[~z])
       llr = res0[-1] - (res1[-1] + res2[-1])
       return pd.Series({'mu0': res0[0],
                         'mu1': res1[0],
                         'mu2': res2[0],
                         'llr': llr,
                         'p': st.chi2(2).sf(-2 * llr)})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   #+BEGIN_SRC ipython :async t
     de_nb_res = cd8.sample(n=100, axis=1, random_state=1).apply(de_nb, axis=0, args=(s, z)).T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[230]:
   :END:

   Look at the histogram of p-values.

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/zheng-cd8-nb.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(de_nb_res['p'], np.linspace(0, 1, 11), density=True, color='black')
     plt.axhline(y=1, lw=1, ls=':', c='r')
     plt.xlabel('P-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[231]:
   [[file:figure/deconv-de.org/zheng-cd8-nb.png]]
   :END:

   Look at the QQ plot.

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/zheng-cd8-nb-qq.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.scatter(st.chi2(2).ppf(np.linspace(0, 1, de_nb_res.shape[0])), np.sort(-2 * de_nb_res['llr']), c='k', s=2)
     plt.plot([0, 11], [0, 11], c='r', lw=1, ls=':')
     plt.xlabel('Expected chi-square')
     plt.ylabel('Observed chi-square')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[233]:
   : Text(0, 0.5, 'Observed chi-square')
   [[file:figure/deconv-de.org/zheng-cd8-nb-qq.png]]
   :END:

** NB GLM
   :PROPERTIES:
   :CUSTOM_ID: glm
   :END:

   The Gamma deconvolution approach above corresponds to a generalized linear model:

   \[ x_i \sim \mathrm{NB}(\mu_i, \phi_{z_i}) \]

   \[ \ln(\mu_i) = \mathbf{z}_i + \ln s_i \]

   where \(\mathrm{NB}(\mu, \phi)\) denotes the negative binomial distribution
   with mean \(\mu\) and variance \(\mu^2\phi\) and \(\mathbf{z}_i\) denotes a
   one-hot vector representing the group membership.

   This level of flexibility in the dispersion parameters isn't readily
   available in existing GLM implementations. However, it is not obvious this
   level of flexibility is actually required.

   If we consider the Gamma deconvolution approach essentially a \(t\)-test
   (mean and variance per group), we can compare the GLM approach with a single
   dispersion parameter \(\phi\) to a \(t\)-test with pooled variance.

   #+BEGIN_SRC ipython
     def de_glm(x, s, z):
       f = rpy2.robjects.Formula('x ~ z + offset(log(s))')
       f.environment['x'] = x
       f.environment['z'] = pd.Series(z.astype(int))
       f.environment['s'] = s
       res = mass.glm_nb(f)
       pval = np.array(rpy2.robjects.r['coef'](rpy2.robjects.r['summary'](res)))[1,-1]
       return pval
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[53]:
   :END:

   #+BEGIN_SRC ipython :async t
     de_glm_res = cd8.sample(n=100, axis=1, random_state=1).apply(de_glm, axis=0, args=(s, z)).T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[54]:
   :END:

   Look at the histogram of p-values.

   #+BEGIN_SRC ipython :ipyfile figure/deconv-de.org/zheng-cd8-glm.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(de_glm_res, np.linspace(0, 1, 11), density=True, color='black')
     plt.axhline(y=1, lw=1, ls=':', c='r')
     plt.xlabel('P-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[61]:
   [[file:figure/deconv-de.org/zheng-cd8-glm.png]]
   :END:

** Debugging NB GLM

   Figure out what happened in the [[https://github.com/aksarkar/dsc-log-fold-change][DSC]].

   #+BEGIN_SRC sh :session mstephens :exports none
     srun --pty --partition=mstephens bash
     source activate dsc-log-fold-change
     export TMPDIR=/scratch/midway2/aksarkar/
     R --quiet --no-save
   #+END_SRC

   #+RESULTS:
   : 
   : source activate dsc-log-fold-change
   : export TMPDIR=/scratch/midway2/aksarkar/
   : R --quiet --no-save

   #+BEGIN_SRC emacs-lisp :exports none
     (load-library "aksarkar-ess")
     (setq org-babel-temporary-directory "/scratch/midway2/aksarkar/")
     (with-current-buffer "mstephens" (ess-remote))
   #+END_SRC

   #+RESULTS:

   #+BEGIN_SRC R
     library(dplyr)
     res = dscrutils::dscquery("/project2/mstephens/aksarkar/projects/dsc-log-fold-change/dsc/benchmark",
                               targets=c("data_poisthin.prop_null", "data_poisthin.nsamp", "type1error"), verbose=FALSE)
     out = plyr::ddply(res, c("data_poisthin.prop_null", "data_poisthin.nsamp", "type1error.output.file"),
                       function (x) {readRDS(sprintf("/project2/mstephens/aksarkar/projects/dsc-log-fold-change/dsc/benchmark/%s.rds",
                                                     x$type1error.output.file))$type_one_error})
     out %>% group_by(data_poisthin.nsamp, data_poisthin.prop_null) %>% summarise(mean(V1), sd(V1))
   #+END_SRC

   #+ATTR_HTML: :class table
   #+RESULTS:
   | 100 | 0.9 | 0.0233333333333333 |  0.0114155814869796 |
   | 100 |   1 |             0.0235 |  0.0104163333279998 |
   | 500 | 0.9 | 0.0448888888888889 | 0.00838379781743461 |
   | 500 |   1 |             0.0426 | 0.00783439709089205 |


   #+BEGIN_SRC R
     head(out)
   #+END_SRC

   #+ATTR_HTML: :class table
   #+RESULTS:
   | 0.9 | 100 | type1error/data_poisthin_1_glm_nb_1_type1error_1  | 0.0133333333333333 |
   | 0.9 | 100 | type1error/data_poisthin_13_glm_nb_2_type1error_2 | 0.0333333333333333 |
   | 0.9 | 100 | type1error/data_poisthin_17_glm_nb_2_type1error_2 | 0.0244444444444444 |
   | 0.9 | 100 | type1error/data_poisthin_21_glm_nb_2_type1error_2 | 0.0166666666666667 |
   | 0.9 | 100 | type1error/data_poisthin_25_glm_nb_2_type1error_2 | 0.0244444444444444 |
   | 0.9 | 100 | type1error/data_poisthin_29_glm_nb_2_type1error_2 |               0.05 |

   Look at a false positive.

   #+BEGIN_SRC R
     dat = readRDS("/project2/mstephens/aksarkar/projects/dsc-log-fold-change/dsc/benchmark/data_poisthin/data_poisthin_29.rds")
     glm_res = readRDS("/project2/mstephens/aksarkar/projects/dsc-log-fold-change/dsc/benchmark/glm_nb/data_poisthin_29_glm_nb_2.rds")
     parsed = data.frame(beta=dat$beta, betahat=glm_res$log_fold_change_est, shat=glm_res$s_hat, p=glm_res$pval)
   #+END_SRC

   #+RESULTS:

   #+BEGIN_SRC R
     y = dat$Y[10,]
     s = colSums(dat$Y)
     z = dat$X[,2]
     fit = MASS::glm.nb(y ~ z + offset(log(s)))
     summary(fit)
   #+END_SRC

   #+BEGIN_EXAMPLE

     Call:
     MASS::glm.nb(formula = y ~ z + offset(log(s)), init.theta = 0.3319585934, 
         link = log)

     Deviance Residuals: 
         Min       1Q   Median       3Q      Max  
     -1.0912  -0.8465  -0.5935  -0.0329   3.6257  

     Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
     (Intercept)  -7.6827     0.2914 -26.360  < 2e-16 ***
     z            -1.2983     0.4794  -2.708  0.00676 ** 
     ---
     Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

     (Dispersion parameter for Negative Binomial(0.332) family taken to be 1)

         Null deviance: 70.030  on 99  degrees of freedom
     Residual deviance: 62.383  on 98  degrees of freedom
     AIC: 184.42

     Number of Fisher Scoring iterations: 1


                   Theta:  0.332 
               Std. Err.:  0.105 

      2 x log-likelihood:  -178.425 

   #+END_EXAMPLE

   #+BEGIN_SRC R
     summary(y)
   #+END_SRC

   #+BEGIN_EXAMPLE
        Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
        0.00    0.00    0.00    0.59    1.00   27.00 
   #+END_EXAMPLE

   Is the false positive explained by differential proportion of zeros between
   the two groups?

   #+BEGIN_SRC R
     c(mean(y[z == 0]), mean(y[z == 1]))
   #+END_SRC

   #+ATTR_HTML: :class table
   #+RESULTS:
   | 0.92 |
   | 0.26 |

   Can we fix this by fitting a ZINB GLM instead?

   #+BEGIN_SRC R
     zinb_fit = pscl::zeroinfl(y ~ z + offset(log(s)) | 1, dist="negbin")
     summary(zinb_fit)
   #+END_SRC

   #+BEGIN_EXAMPLE
     Call:
     pscl::zeroinfl(formula = y ~ z + offset(log(s)) | 1, dist = "negbin")

     Pearson residuals:
          Min       1Q   Median       3Q      Max 
     -0.52605 -0.46814 -0.36971 -0.03213 13.28411 

     Count model coefficients (negbin with log link):
                 Estimate Std. Error z value Pr(>|z|)    
     (Intercept)  -7.6827     0.2896 -26.526  < 2e-16 ***
     z            -1.2983     0.4759  -2.728 0.006367 ** 
     Log(theta)   -1.1027     0.3161  -3.488 0.000486 ***

     Zero-inflation model coefficients (binomial with logit link):
                 Estimate Std. Error z value Pr(>|z|)
     (Intercept)   -10.35     100.73  -0.103    0.918
     ---
     Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

     Theta = 0.332 
     Number of iterations in BFGS optimization: 168 
     Log-likelihood: -89.21 on 4 Df

   #+END_EXAMPLE

   Can we fix this by fitting group-specific dispersions?

   #+BEGIN_SRC ipython
     dat = rpy2.robjects.r['readRDS']('/project2/mstephens/aksarkar/projects/dsc-log-fold-change/dsc/benchmark/data_poisthin/data_poisthin_29.rds')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   #+BEGIN_SRC ipython
     x = np.array(dat.rx2('Y')).T
     s = x.sum(axis=1)
     z = np.zeros(100)
     z[:50] = 1
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   :END:

   #+BEGIN_SRC ipython
     de_nb(x[:,10], s, z.astype(bool))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   #+BEGIN_EXAMPLE
     mu0    0.000120
     mu1    0.000115
     mu2    0.000126
     llr   -0.026038
     p      0.974298
     dtype: float64
   #+END_EXAMPLE
   :END:
