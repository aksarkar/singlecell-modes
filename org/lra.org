#+TITLE: Low rank approximation
#+SETUPFILE: setup.org

* Introduction

  Suppose we have observations \(x_{ij} \sim
  \operatorname{Pois}(\lambda_{ij})\). Rather than making a distributional
  assumption \(\lambda_j \sim g_j(\cdot)\) (as in
  [[file:deconvolution.org][expression deconvolution]]), we might make a /low
  rank assumption/ \(h(\lambda_{ij}) = [\mathbf{L F}]_{ij}\).  This assumption
  can be interpreted as regularizing cells/genes towards each other, or as
  discovering clusters in the data.

  A number of methods have been proposed to estimate low rank structure from
  count data, several specialized for scRNA-seq data. 

  - Non-negative matrix factorization
    ([[https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf][Lee
    and Seung 2001]], [[https://arxiv.org/abs/1010.1763][FÃ©votte and Idier
    2011]])
  - Latent dirichlet allocation
    ([[http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf][Blei et al
    2003]],
    [[https://papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation][Hoffman
    et al. 2010]], [[http://proceedings.mlr.press/v22/taddy12.html][Taddy
    2012]])
  - Hierarchical Bayesian Poisson Factorization
    ([[http://www.cs.columbia.edu/~blei/papers/GopalanHofmanBlei2015.pdf][Gopalan
    et al. 2015]],
    [[https://onlinelibrary.wiley.com/doi/full/10.15252/msb.20188557][Levitin
    et al. 2019]])
  - ZINB-WAVE ([[https://www.nature.com/articles/s41467-017-02554-5][Risso et
    al. 2018]])
  - scVI ([[https://www.nature.com/articles/s41592-018-0229-2][Lopez et al.
    2018]])
  - DCA ([[https://www.nature.com/articles/s41467-018-07931-2][Eraslan et
    al. 2019]])
  - GLM-PCA ([[https://www.biorxiv.org/content/10.1101/574574v1][Townes et
    al. 2019]])

  There is one fundamental modelling decision which is not obvious from first
  principles: what precisely is low rank? In other words, what is the
  functional form of \(h(\cdot)\)? The methods above use either: \(h(x) = x\),
  \(h(x) = \ln(x)\), or learn \(h\) from the data.

  Here, we evaluate methods on their ability to generalize to new data. We use
  real data, assuming:

  \begin{align*}
    x_{ij} &\sim \mathrm{Poisson}(s_i \lambda_{ij})\\
    h(\lambda_{ij}) &= [\mathbf{L F}]_{ij}
  \end{align*}

  and hold out molecules by randomly thinning the observed counts:

  \begin{align*}
    y_{ij} &\sim \mathrm{Binomial}(x_{ij}, 0.5)\\
    \tilde{y}_{ij} &= x_{ij} - y_{ij}\\
  \end{align*}

  This approach leaves the relative abundance of the transcripts unchanged in
  expectation, implying that the low rank structure learned in \(\mathbf{Y}\)
  should explain the data in \(\tilde{\mathbf{Y}}\).

  Our metric is then the likelihood of the held-out data. We simply need to
  re-scale to account for different size factors \(s_i\).

* Setup

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "lra.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scmodes",partition="mstephens",memory="16G") :dir /scratch/midway2/aksarkar/modes

  #+RESULTS:
  : Submitted batch job 62145068

  #+NAME: imports
  #+BEGIN_SRC ipython
    import numpy as np
    import pandas as pd
    import scmodes
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import sklearn.decomposition as skd
    import scipy.stats as st
    import wlra

    rpy2.robjects.pandas2ri.activate()
    glmpca = rpy2.robjects.packages.importr('glmpca')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[4]:
  :END:

  #+BEGIN_SRC ipython
    import colorcet
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[5]:
  :END:

* Methods
** Datasets

   We use real scRNA-seq datasets in heterogeneous tissues to benchmark
   methods:

   1. Mouse neuron cells sequenced on the Fluidigm C1 platform
      ([[https://science.sciencemag.org/content/347/6226/1138.full][Zeisel et
      al. 2015]])

   2. Fresh PBMCs sequenced on the 10X platform
      ([[https://www.nature.com/articles/ncomms14049][Zheng et al. 2017]])

** Implementation

   Wrap around GLM-PCA.

   #+BEGIN_SRC ipython
     def _glmpca(x, n_components, max_iters=None, eps=None):
       ctl = {'maxIter': 100, 'eps': 1e-4}
       if max_iters is not None:
         ctl['maxIter'] = max_iters
       if eps is not None:
         ctl['eps'] = eps
       ctl = rpy2.robjects.ListVector(ctl)
       # GLM-PCA expects [genes, samples]
       res = glmpca.glmpca(x.T, L=n_components, ctl=ctl)
       # Follow GLM-PCA code for size factors, not the paper
       s = np.log(x.mean(axis=1))
       L = np.array(res.rx2('loadings'))
       F = np.array(res.rx2('factors'))
       etahat = s.reshape(-1, 1) + F.T.dot(L)
       trace = np.array(res.rx2('dev'))
       return etahat, trace
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   :END:

* Results
** PCA on (log) counts
   :PROPERTIES:
   :CUSTOM_ID: ipsc
   :END:

   Investigate whether PCA on counts or log counts gives better log likelihood.
   We can write principal components analysis as a generative model (Tipping
   1999):

   \[ \mathbf{y}_i \sim \mathcal{N}(\mathbf{y}_i; \mathbf{W z}_i, \sigma^2 \mathbf{I}) \]

   Now, suppose \(y_{ij} = \ln(x_{ij} + \epsilon)\). Then, via
   change of variables we have:

   \[ p(\mathbf{x}_i) = \frac{1}{\mathbf{x}_i + \epsilon}
   \mathcal{N}(\ln(\mathbf{x}_i + \epsilon); \mathbf{W z}_i, \sigma^2
   \mathbf{I}) \]

   where we abuse notation for element-wise operations. In general, this means
   we can compare the likelihood of the observed data under models of different
   transformations of the observations.

   #+NAME: pca
   #+BEGIN_SRC ipython :eval never
     <<imports>>
     import scipy.stats as st
     import sklearn.decomposition as skd

     ipsc = scmodes.dataset.ipsc('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/')
     res0 = skd.PCA(n_components=10).fit(ipsc)
     z_0 = res0.transform(ipsc)
     llik0 = st.norm(loc=z_0.dot(res0.components_), scale=np.sqrt(res0.noise_variance_)).logpdf(ipsc).sum()

     log_ipsc = np.log(ipsc + 1)
     res1 = skd.PCA(n_components=10).fit(log_ipsc)
     z_1 = res1.transform(ipsc)
     llik1 = (-log_ipsc + st.norm(loc=z_1.dot(res1.components_), scale=np.sqrt(res1.noise_variance_)).logpdf(log_ipsc)).sum()
     print(f'PCA of untransformed counts: {llik0:.4g}')
     print(f'PCA of log1p counts: {llik1:.4g}')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=mstephens --mem=8G
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<pca>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60034134

   #+BEGIN_EXAMPLE
     PCA of untransformed counts: -4.712e+08
     PCA of log1p counts: -3.57e+09
   #+END_EXAMPLE

** GLM-PCA on simulated data

   Make sure we understand GLM-PCA on a simulated dataset.

   \begin{align*}
     x_{ij} &\sim \operatorname{Pois}(\exp(\eta_{ij}))\\
     \eta_{ij} &= \sum_k l_{ik} f_{jk}\\
     l_{ik} &\sim \mathcal{N}(0, 1)\\
     f_{jk} &\sim \mathcal{N}(0, 1)
   \end{align*}

   #+BEGIN_SRC ipython
     x, eta = scmodes.dataset.simulate_pois(500, 1000, 3, eta_max=3)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   :END:

   Compute the oracle log likliehood.

   #+BEGIN_SRC ipython
     st.poisson(mu=np.exp(eta)).logpmf(x).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   : -655323.8735824303
   :END:

   Fit the model using PLRA1.

   #+BEGIN_SRC ipython
     etahat = wlra.plra(x, rank=3)
     st.poisson(mu=np.exp(etahat)).logpmf(x).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   : -653862.7854399089
   :END:

   We simulated the data assuming \([\eta_{ij}]\) was low rank. Get the oracle
   rank of \([\exp(\eta_{ij})]\).

   #+BEGIN_SRC ipython :ipyfile figure/lra.org/sim-spectrum.png
     d = np.linalg.svd(np.exp(eta))[1]
     plt.clf()
     plt.gcf().set_size_inches(5, 3)
     plt.plot(d, lw=1, c='k')
     plt.xlabel('Singular value')
     plt.ylabel('Magnitude')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[28]:
   [[file:figure/lra.org/sim-spectrum.png]]
   :END:

   For comparison, fit NMF using the oracle rank.

   #+BEGIN_SRC ipython :async t
     m = skd.NMF(n_components=100, beta_loss=1, solver='mu', max_iter=1000)
     L = m.fit_transform(x)
     F = m.components_
     lam = (L / L.sum(axis=0)).dot(F)
     st.poisson(mu=lam).logpmf(x).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[27]:
   : -2144790.5600828375
   :END:

   Fit GLM-PCA using the oracle rank and default optimization
   parameters. Compute the log likelihood of the fit.

   #+BEGIN_SRC ipython :async t
     etahat, trace = _glmpca(x, n_components=3)
     st.poisson(mu=np.exp(etahat)).logpmf(x).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   : -656295.9809819672
   :END:

   Check whether GLM-PCA actually converged. By default, it runs 100
   iterations.

   #+BEGIN_SRC ipython :ipyfile figure/lra.org/glmpca-trace0.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.plot(trace, lw=1, c='k')
     plt.xlabel('Iteration')
     plt.ylabel('Deviance')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   [[file:figure/lra.org/glmpca-trace0.png]]
   :END:

   Run GLM-PCA with stricter stopping criteria.

   #+BEGIN_SRC ipython :async t
     etahat, trace = _glmpca(x, n_components=3, eps=1e-8)
     st.poisson(mu=np.exp(etahat)).logpmf(x).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   : -656216.9528662462
   :END:

   Check convergence.

   #+BEGIN_SRC ipython :ipyfile figure/lra.org/glmpca-trace1.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.plot(trace, lw=1, c='k')
     plt.xlabel('Iteration')
     plt.ylabel('Deviance')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   [[file:figure/lra.org/glmpca-trace1.png]]
   :END:
   
   GLM-PCA still does worse than oracle even on this simple simulated dataset.

** Cortex
   :PROPERTIES:
   :CUSTOM_ID: cortex
   :END:

   Figure out why GLM-PCA broke. There is a bug in the software in fitting a
   rank 1 model. /Townes et al. did not analyze this dataset in their paper./

   #+BEGIN_SRC ipython
     X = scmodes.dataset.cortex('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/zeisel-2015/GSE60361_C1-3005-Expression.txt.gz', return_df=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   #+BEGIN_SRC ipython :async t
     llik = []
     for k in range(2, 11):
       try:
         res = scmodes.benchmark.training_score_glmpca(X, n_components=k)
       except:
         res = np.nan
       llik.append(res)
     llik = np.array(llik)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/lra.org/cortex-glmpca.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.plot(llik, lw=1, c='k')
     plt.xlabel('Rank')
     plt.ylabel('Training llik')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   [[file:figure/lra.org/cortex-glmpca.png]]
   :END:

   Is the problem initialization? GLM-PCA uses a random initialization, so try
   multiple restarts.

   #+BEGIN_SRC ipython :async t
     for i in range(10):
       try:
         res = scmodes.benchmark.training_score_glmpca(X, n_components=10)
       except:
         continue
     res
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[25]:
   : -25499577.33000473
   :END:

   Try our Python implementation.

   #+BEGIN_SRC ipython
     import scmodes.pois
     res1 = scmodes.pois.pois_fa_glm(X, n_components=1, verbose=True)
   #+END_SRC

   Run the benchmark.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-modes/code/cortex-bench.py
     <<imports>>
     import os
     tasks = ['nmf', 'glmpca']
     task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     cortex = scmodes.dataset.cortex('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/zeisel-2015/GSE60361_C1-3005-Expression.txt.gz', return_df=True)
     res = scmodes.benchmark.evaluate_lra_generalization(cortex, methods=[task], n_trials=1, n_components=5, max_restarts=10)
     res.to_csv(f'/scratch/midway2/aksarkar/modes/lra-generalization/cortex-{task}.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -a 1 -n1 --mem=16G --time=60:00 --job-name=lra-benchmark --out=lra-benchmark.out   
     #!/bin/bash
     source activate scmodes
     python /project2/mstephens/aksarkar/projects/singlecell-modes/code/cortex-bench.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 62075344

** Sorted cells benchmark

   #+NAME: zheng-bench
   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-modes/code/zheng-bench-lra.py
     <<imports>>
     import os
     methods = ['nmf', 'glmpca', 'scvi']
     datasets = ['b_cells', 'cytotoxic_t', 'naive_t']
     d = datasets[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     data = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{d}/filtered_matrices_mex/hg19/', return_df=True)
     res = scmodes.benchmark.evaluate_lra_generalization(data, methods=methods, n_trials=10)
     res.to_csv(f'/scratch/midway2/aksarkar/modes/lra-generalization/{d}.txt.gz')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes
     sbatch --partition=broadwl -a 0-2 -n1 --exclusive --time=3:00:00 --job-name=lra-benchmark
     #!/bin/bash
     source activate scmodes
     python /project2/mstephens/aksarkar/projects/singlecell-modes/code/zheng-bench-lra.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 62145781

** Synthetic mixtures benchmark

   #+NAME: synthetic-mix-bench
   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-modes/code/synthetic-mix-lra.py
     <<imports>>
     import os
     methods = ['nmf', 'glmpca', 'scvi']
     datasets = [('cytotoxic_t', 'b_cells'), ('cytotoxic_t', 'naive_t')]
     d1, d2 = datasets[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     x1 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{d1}/filtered_matrices_mex/hg19/', return_df=True, min_detect=0)
     x2 = scmodes.dataset.read_10x(f'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{d2}/filtered_matrices_mex/hg19/', return_df=True, min_detect=0)
     x, y = scmodes.dataset.synthetic_mix(x1, x2, min_detect=.25)
     res = scmodes.benchmark.evaluate_lra_generalization(x, methods=methods, n_trials=10)
     res.to_csv(f'/scratch/midway2/aksarkar/modes/lra-generalization/{d1}-{d2}.txt.gz')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -a 0-1 -n1 --exclusive --time=6:00:00 --job-name=lra-benchmark
     #!/bin/bash
     source activate scmodes
     python /project2/mstephens/aksarkar/projects/singlecell-modes/code/synthetic-mix-lra.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 62145912

** PBMCs benchmark
   :PROPERTIES:
   :CUSTOM_ID: pbmc
   :END:

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-modes/code/pbmc-bench-lra.py
     <<imports>>
     import os
     tasks = ['nmf', 'glmpca', 'scvi']
     task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     data = scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/fresh_68k_pbmc_donor_a/filtered_matrices_mex/hg19/', return_df=True)
     res = scmodes.benchmark.evaluate_lra_generalization(data, methods=[task], n_trials=10)
     res.to_csv(f'/scratch/midway2/aksarkar/modes/lra-generalization/pbmcs-{task}.txt.gz')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -a 1-2 -n1 -c28 --exclusive --time=3:00:00 --job-name=lra-benchmark
     #!/bin/bash
     source activate scmodes
     python /project2/mstephens/aksarkar/projects/singlecell-modes/code/pbmc-bench-lra.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 62156286

** Plot the results

   #+BEGIN_SRC sh
     rsync -au /scratch/midway2/aksarkar/modes/lra-generalization/ /project2/mstephens/aksarkar/projects/singlecell-modes/data/lra-generalization/
   #+END_SRC

   #+RESULTS:

   Read the results.

   #+BEGIN_SRC ipython
     data = ['b_cells', 'cytotoxic_t', 'naive_t', 'cytotoxic_t-b_cells', 'cytotoxic_t-naive_t']
     titles = ['B cells', 'Cytotoxic T', 'Naive T', 'B cell/T cell', 'Naive/cytotoxic T']
     results = {k: pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/lra-generalization/{k}.txt.gz', header=[0, 1], index_col=0)
                for k in data}
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[43]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/lra.org/mlcb-bench-lra.png
     plt.clf()
     fig, ax = plt.subplots(1, len(results), sharey=True)
     fig.set_size_inches(7, 2)
     for a, k, t in zip(ax, results, titles):
       llik = results[k]['validation']
       for x, m in enumerate(llik):
         a.scatter(x + np.random.normal(scale=0.1, size=llik.shape[0]), llik[m].values, s=1, c='k', zorder=3)
       a.grid(c='0.8', lw=1, axis='x')
       a.set_xlim(-0.5, 2.5)
       a.set_xticks(np.arange(3))
       a.set_xticklabels(['NMF', 'GLMPCA', 'SCVI'], rotation=90)
       a.set_title(t)
     ax[0].set_ylabel('Validation log lik')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   [[file:figure/lra.org/mlcb-bench-lra.png]]
   :END:
