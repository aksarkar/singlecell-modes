#+TITLE: Comparison of expression deconvolution approaches
#+SETUPFILE: setup.org

* Introduction
  :PROPERTIES:
  :CUSTOM_ID: introduction
  :END:

  Suppose we have observations \(x_i \sim f(\theta_i), i = 1, \ldots, n\), and
  \(\theta_i \sim g(\cdot)\). /Distribution deconvolution/ is the problem of
  estimating \(g \in \mathcal{G}\) from \(x_1, \ldots, x_n\), assuming \(f\) is known
  ([[https://academic.oup.com/biomet/article/103/1/1/2390141][Efron
  2016]]).

  Recent work suggests that scRNA-seq data follows this generative model
  ([[http://dx.doi.org/10.1073/pnas.1721085115][Wang et al. 2018]]). Here, we
  investigate the trade-off between model complexity/flexibility and
  generalization for different choices of \(\mathcal{G}\) in real data.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "deconvolution.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(memory="16G",partition="broadwl",venv="scmodes") :dir /scratch/midway2/aksarkar/modes :exports none

  #+RESULTS:
  : Submitted batch job 60399393

  #+NAME: imports
  #+BEGIN_SRC ipython
    import functools as ft
    import multiprocessing as mp
    import numpy as np
    import pandas as pd
    import scanpy
    import scipy.stats as st
    import scipy.special as sp
    import scmodes
    import sklearn.model_selection as skms

    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import rpy2.robjects.numpy2ri

    rpy2.robjects.pandas2ri.activate()
    rpy2.robjects.numpy2ri.activate()

    ashr = rpy2.robjects.packages.importr('ashr')
    descend = rpy2.robjects.packages.importr('descend')
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import colorcet
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Methods
** Distribution deconvolution
   :PROPERTIES:
   :CUSTOM_ID: deconvolution
   :END:

   The general form of distribution deconvolution for scRNA-seq is:

   \[ x_{ij} \sim \mathrm{Poisson}(\exp(\mathbf{z}_i' \mathbf{b}_j) \lambda_{ij}) \]

   \[ \lambda_{ij} \sim g_j(\cdot) \]

   where:

   - \(x_{ij}\) is the count of molecules of gene \(j\) in cell \(i\)
   - \(\mathbf{z}_i\) is a \(q\)-vector of covariates for cell \(i\)
   - \(\mathbf{b}_j\) is a \(q\)-vector of confounding effects on gene \(j\)
   - \(\lambda_{ij}\) is proportional to the relative abundance of gene \(j\)
     in cell \(i\)

   The primary inference goal is to recover \(g_j\). A secondary goal could be
   to recover \(\lambda_{ij}\). We can trade off flexibility and complexity of
   \(g_j\) for ease of implementation and speed.

   1. *Point mass:* \(g_j = \delta_\mu\). We mention it for completeness.
   2. *Gamma:* \(g_j = \mathrm{Gamma}(\cdot)\). This leads to the negative
      binomial marginal likelihood, and can be motivated by the empirical
      observation that the counts are overdispersed.
   3. *Point-Gamma:* \(g_j = \pi_j \delta_0(\cdot) + (1 - \pi_j)
      \mathrm{Gamma}(\cdot)\). This leads to the zero-inflated negative
      binomial marginal likelihood, which is still analytic and therefore
      computationally favorable. The inclusion of the point mass can be
      motivated by theory suggesting a biological mechanism for bimodal gene
      expression ([[http://dx.doi.org/10.1126/science.1216379][Munsky et
      al. 2013]], [[http://dx.doi.org/10.1186/gb-2013-14-1-r7][Kim and Marioni
      2013]]).
   4. *Unimodal:* \(g_j\) is some unimodal distribution over non-negative
      reals. In practice, we represent this family of distribution as \(g_j =
      \sum_k \pi_k \mathrm{Uniform}(\cdot; \lambda_0, a_{jk})\), where \(k = 1,
      \ldots, K\) are sufficiently many and \(\lambda_0\) is the mode
      ([[http://dx.doi.org/10.1093/biostatistics/kxw041][Stephens 2016]]).
   5. *Zero-inflated exponential family:* \(g_j = \exp(\mathbf{Q}\alpha -
      \phi(\alpha))\), where \(\mathbf{Q}\) is a
      [[https://en.wikipedia.org/wiki/B-spline][B spline spline basis matrix]]
      for a [[https://en.wikipedia.org/wiki/Cubic_Hermite_spline][natural cubic
      spline]]
      ([[https://www.rdocumentation.org/packages/splines/topics/ns][~ns~
      function]];
      [[https://academic.oup.com/biomet/article/103/1/1/2390141][Efron
      2016]]). The key idea of the method is use spline regression to find the
      sufficient statistic and natural parameters which maximizes the penalized
      likelihood of the observed data. The method has been extended to include
      a point mass on zero ([[http://dx.doi.org/10.1073/pnas.1721085115][Wang
      et al. 2018]]).
   6. *Nonparametric:* \(g_j\) is some distribution over non-negative reals
      ([[https://projecteuclid.org/euclid.aoms/1177728066][Kiefer and Wolfowitz
      1956]]). In practice, we discretize the representation
      ([[https://amstat.tandfonline.com/doi/abs/10.1080/01621459.2013.869224][Koenker
      and Mizera 2014]]). In full detail, we use the representation \(g_j =
      \sum_k \pi_k \mathrm{Uniform}(\cdot; ak, a(k + 1))\), where \(a\) is a
      fixed step size, which allows us to re-use the ~ash~ implementation.

   In order to evaluate methods on their ability to estimate \(g_j\), we hold
   out a validation set, and compute the validation set log likelihood. Based
   on our preliminary experiments, we compare all methods against Gamma.

   The benchmarking code is implemented in the Python package
   [[https://github.com/aksarkar/scmodes][scmodes]].

** Benchmarking data
   :PROPERTIES:
   :CUSTOM_ID: data
   :END:

   We deconvolve ERCC spike-in data generated on multiple platforms,
   pre-processed as in
   [[https://www.biorxiv.org/content/10.1101/582064v1][Svensson 2019]].

   1. Drop-seq (Macosko et al., 2015)
   2. InDrops (Klein et al., 2015)
   3. 10x Genomics, v1 chemistry (Zheng et al., 2017);
   4. 10x Genomics, ??? (Svensson et al., 2017).

   We additionally deconvolve spike-in data included in iPSCs derived from 53
   donor individuals. We
   [[https://jdblischak.github.io/singlecell-qtl/descriptive-stats.html][previously
   observed]] individual-specific heterogeneity in this data.

   As examples of homogeneous cell populations, we use:

   1. Sorted immune cells sequenced on the 10X platform
      ([[https://www.nature.com/articles/ncomms14049][Zheng et al. 2017]])

   2. iPSCs derived from Yoruba LCLs, sequenced on the Fluidigm C1 platform
      ([[http://dx.doi.org/10.1371/journal.pgen.1008045][Sarkar et al. 2018]])

   We use the homogeneous cells populations to generate synthetic mixtures with
   known cell type labels.

   As examples of heterogeneous cell populations, we use:

   1. Fresh PBMCs sequenced on the 10X platform
      ([[https://www.nature.com/articles/ncomms14049][Zheng et al. 2017]])

   2. Mouse neuron cells sequenced on the Fluidigm C1 platform
      ([[https://science.sciencemag.org/content/347/6226/1138.full][Zeisel et
      al. 2015]])

* Results
** Example
   :PROPERTIES:
   :CUSTOM_ID: examples
   :END:

   As an example, use the highest expressed genes in 10K sorted CD8+ cytotoxic
   T cells [[https://www.nature.com/articles/ncomms14049][Zheng et al. 2017]].

   #+BEGIN_SRC ipython
     x = scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19')
     xj = pd.Series(x[:,x.mean(axis=0).argmax()])
     size_factor = pd.Series(x.sum(axis=1))
     lam = xj / size_factor
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   Fit unimodal distribution.

   #+BEGIN_SRC ipython :async t
     unimix_res = ashr.ash_workhorse(
       pd.Series(np.zeros(x.shape[0])),
       1,
       lik=ashr.lik_pois(y=xj, scale=size_factor, link='identity'),
       outputlevel='fitted_g',
       mixsd=pd.Series(np.geomspace(lam.min(), lam.max(), 25)),
       mode=pd.Series([lam.min(), lam.max()]))
     unimix_cdf = ashr.cdf_ash(unimix_res, np.linspace(lam.min(), lam.max(), 1000))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Fit NPMLE.

   #+BEGIN_SRC ipython :async t
     K = 200
     grid = np.linspace(lam.min(), lam.max(), K + 1)
     npmle_res = ashr.ash_workhorse(
       pd.Series(np.zeros(x.shape[0])),
       1,
       outputlevel='fitted_g',
       lik=ashr.lik_pois(y=xj, scale=size_factor, link='identity'),
       g=ashr.unimix(pd.Series(np.ones(K) / K), pd.Series(grid[:-1]), pd.Series(grid[1:])))
     npmle_cdf = ashr.cdf_ash(npmle_res, np.linspace(lam.min(), lam.max(), 1000))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   :END:

   Fit DESCEND.

   #+BEGIN_SRC ipython
     descend_res = descend.deconvSingle(xj, scaling_consts=size_factor, verbose=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   Fit NB/ZINB.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-modes/code/fit-nb.py
     import numpy as np
     import pandas as pd
     import scipy.io
     import scmodes
     import scqtl

     x = scmodes.read10x(prefix='/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19/')
     size_factor = x.sum(axis=1).reshape(-1, 1)
     onehot = np.ones((x.shape[0], 1))
     design = np.zeros((x.shape[0], 1))
     init = scqtl.tf.fit(
       umi=x.astype(np.float32),
       onehot=onehot.astype(np.float32),
       design=design.astype(np.float32),
       size_factor=size_factor.astype(np.float32),
       learning_rate=1e-3,
       max_epochs=30000,
       verbose=True)
     pd.DataFrame(init[0]).to_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-nb-log-mu.txt.gz', compression='gzip', sep='\t')
     pd.DataFrame(init[1]).to_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-nb-log-phi.txt.gz', compression='gzip', sep='\t')
     log_mu, log_phi, logodds, nb_llik, zinb_llik = scqtl.tf.fit(
       umi=x.astype(np.float32),
       onehot=onehot.astype(np.float32),
       design=design.astype(np.float32),
       size_factor=size_factor.astype(np.float32),
       learning_rate=1e-3,
       max_epochs=30000,
       warm_start=init[:3],
       verbose=True)
     pd.DataFrame(log_mu).to_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-zinb-log-mu.txt.gz', compression='gzip', sep='\t')
     pd.DataFrame(log_phi).to_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-zinb-log-phi.txt.gz', compression='gzip', sep='\t')
     pd.DataFrame(logodds).to_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-zinb-logodds.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=16G --time=60:00 --job-name=fit-nb
     #!/bin/bash
     source activate scmodes
     python /project2/mstephens/aksarkar/projects/singlecell-modes/code/fit-nb.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58803475

   #+BEGIN_SRC ipython
     j = str(x.mean(axis=0).argmax())
     nb_log_mu = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-nb-log-mu.txt.gz', sep='\t')
     nb_log_phi = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-nb-log-phi.txt.gz', sep='\t')
     # Gamma (Use MATLAB and MATHEMATICA (b=theta=scale, a=alpha=shape) definition)
     # https://github.com/scipy/scipy/blob/v1.2.1/scipy/stats/_continuous_distns.py#L2479
     gamma_cdf = st.gamma(a=np.exp(-nb_log_phi[j]), scale=np.exp(nb_log_mu[j] + nb_log_phi[j])).cdf(np.linspace(lam.min(), lam.max(), 1000))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   #+BEGIN_SRC ipython
     zinb_log_mu = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-zinb-log-mu.txt.gz', sep='\t')
     zinb_log_phi = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-zinb-log-phi.txt.gz', sep='\t')
     zinb_logodds = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-example/zheng-cd8-zinb-logodds.txt.gz', sep='\t')
     point_gamma_cdf = st.gamma(a=np.exp(-zinb_log_phi[j]), scale=np.exp(zinb_log_mu[j] + zinb_log_phi[j])).cdf(np.linspace(lam.min(), lam.max(), 1000))
     point_gamma_cdf *= sp.expit(-zinb_logodds[j].values)
     point_gamma_cdf += sp.expit(zinb_logodds[j].values)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Plot the observed counts and deconvolved distributions.

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/deconv-example.png
     cm = plt.get_cmap('Dark2').colors
     fig, ax = plt.subplots(2, 1)
     h = ax[0].hist(xj, bins=np.arange(xj.max() + 1), color='k')
     ax[0].set_xlabel('Molecule count')
     ax[0].set_ylabel('Number of cells')

     ax[1].plot(np.linspace(lam.min(), lam.max(), 1000), gamma_cdf, color=cm[0], lw=1, label='Gamma')
     ax[1].plot(np.linspace(lam.min(), lam.max(), 1000), point_gamma_cdf, color=cm[1], lw=1, label='Point-Gamma')
     ax[1].plot(np.array(unimix_cdf.rx2('x')),
                np.array(unimix_cdf.rx2('y')).ravel(), c=cm[2], lw=1, label='Unimodal')
     F = np.cumsum(np.array(descend_res.slots['density.points'])[:,1])
     ax[1].plot(np.array(descend_res.slots['density.points'])[:,0],
                F / F.max(), c=cm[3], lw=1, label='ZIEF')
     ax[1].plot(np.array(npmle_cdf.rx2('x')),
                np.array(npmle_cdf.rx2('y')).ravel(), c=cm[4], lw=1, label='NPMLE')
     ax[1].set_xlabel('Latent gene expression')
     ax[1].set_ylabel('CDF')

     ax[1].legend(frameon=False)

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   [[file:figure/deconvolution.org/deconv-example.png]]
   :END:

   Print out the histogram for inspection.

   #+BEGIN_SRC ipython
     np.vstack((h[1][:-1], h[0])).T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[52]:
   #+BEGIN_EXAMPLE
     array([[  0.,   0.],
     [  1.,   1.],
     [  2.,   1.],
     [  3.,   0.],
     [  4.,   0.],
     [  5.,   0.],
     [  6.,   1.],
     [  7.,   0.],
     [  8.,   1.],
     [  9.,   5.],
     [ 10.,   8.],
     [ 11.,   4.],
     [ 12.,   9.],
     [ 13.,   9.],
     [ 14.,   8.],
     [ 15.,  20.],
     [ 16.,  17.],
     [ 17.,  24.],
     [ 18.,  31.],
     [ 19.,  44.],
     [ 20.,  39.],
     [ 21.,  41.],
     [ 22.,  46.],
     [ 23.,  72.],
     [ 24.,  68.],
     [ 25.,  74.],
     [ 26.,  74.],
     [ 27.,  86.],
     [ 28.,  94.],
     [ 29., 114.],
     [ 30.,  96.],
     [ 31., 102.],
     [ 32., 120.],
     [ 33., 132.],
     [ 34., 161.],
     [ 35., 138.],
     [ 36., 159.],
     [ 37., 197.],
     [ 38., 186.],
     [ 39., 210.],
     [ 40., 232.],
     [ 41., 244.],
     [ 42., 284.],
     [ 43., 309.],
     [ 44., 321.],
     [ 45., 332.],
     [ 46., 342.],
     [ 47., 371.],
     [ 48., 349.],
     [ 49., 356.],
     [ 50., 317.],
     [ 51., 343.],
     [ 52., 347.],
     [ 53., 342.],
     [ 54., 308.],
     [ 55., 294.],
     [ 56., 274.],
     [ 57., 272.],
     [ 58., 241.],
     [ 59., 219.],
     [ 60., 191.],
     [ 61., 164.],
     [ 62., 145.],
     [ 63., 144.],
     [ 64., 120.],
     [ 65., 121.],
     [ 66., 100.],
     [ 67.,  95.],
     [ 68.,  69.],
     [ 69.,  62.],
     [ 70.,  53.],
     [ 71.,  47.],
     [ 72.,  52.],
     [ 73.,  32.],
     [ 74.,  35.],
     [ 75.,  36.],
     [ 76.,  30.],
     [ 77.,  28.],
     [ 78.,  20.],
     [ 79.,  27.],
     [ 80.,  26.],
     [ 81.,  21.],
     [ 82.,  12.],
     [ 83.,  12.],
     [ 84.,   9.],
     [ 85.,   7.],
     [ 86.,  12.],
     [ 87.,   8.],
     [ 88.,   9.],
     [ 89.,   6.],
     [ 90.,   4.],
     [ 91.,   5.],
     [ 92.,   2.],
     [ 93.,   2.],
     [ 94.,   2.],
     [ 95.,   3.],
     [ 96.,   1.],
     [ 97.,   2.],
     [ 98.,   2.],
     [ 99.,   0.],
     [100.,   0.],
     [101.,   0.],
     [102.,   1.],
     [103.,   1.],
     [104.,   0.],
     [105.,   0.],
     [106.,   2.]])
   #+END_EXAMPLE
   :END:

   Look at what is going on with NPMLE.

   #+BEGIN_SRC ipython
     res0 = ashr.ash_workhorse(
       pd.Series(np.zeros(x.shape[0])),
       1,
       outputlevel=pd.Series(['fitted_g', 'loglik']),
       lik=ashr.lik_pois(y=xj, scale=size_factor, link='identity'),
       g=ashr.unimix(pd.Series(np.ones(100) / 100), pd.Series(grid[:-1]), pd.Series(grid[1:])))
     res1 = ashr.ash_workhorse(
       pd.Series(np.zeros(x.shape[0])),
       1,
       outputlevel=pd.Series(['fitted_g', 'loglik']),
       lik=ashr.lik_pois(y=xj, scale=size_factor, link='identity'),
       g=ashr.unimix(pd.Series(np.ones(200) / 200), pd.Series(grid[:-1]), pd.Series(grid[1:])))
   #+END_SRC

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/npmle-example.png
     plt.clf()
     plt.gcf().set_size_inches(4, 2)
     grid = np.linspace(lam.min(), lam.max(), 1000)
     plt.plot(grid, np.array(ashr.cdf_ash(res0, grid)[1]).ravel(), label='NPMLE (100 components)', lw=1, c='k')
     plt.plot(grid, np.array(ashr.cdf_ash(res1, grid)[1]).ravel(), label='NPMLE (200 components)', lw=2, ls=':', c='r')
     plt.legend(frameon=False)
     plt.xlabel('Latent gene expression')
     plt.ylabel('CDF')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   : Text(0, 0.5, 'CDF')
   [[file:figure/deconvolution.org/npmle-example.png]]
   :END:

   #+BEGIN_SRC ipython
     np.array(res0.rx2('loglik')) - np.array(res1.rx2('loglik'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   : array([0.])
   :END:

** Spike-in data
   :PROPERTIES:
   :CUSTOM_ID: spike-ins
   :END:

   [[https://www.biorxiv.org/content/10.1101/582064v1][Svensson 2019]] analyze
   negative control data in which only spike-in data is sequenced. 

   He claims that there should be no heterogeneity between samples in
   spike-ins. However, there is random sampling of molecules in the spike-in
   protocol, which will introduce noise. This was previously established by
   [[https://www.pnas.org/content/115/28/E6437/][Wang et al. 2018]].

   Further, [[http://dx.doi.org/10.1038/srep39921][Tung et al. 2016]] establish
   that in spike-in data added to real cells, there is considerable
   heterogeneity in efficiency not just between cells, but also donor
   individuals.

   #+NAME: ercc-data
   #+BEGIN_SRC ipython
     def read_chromium(sample):
       x = scanpy.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/svensson_chromium_control.h5ad')
       scanpy.pp.filter_genes(x, min_counts=1)
       return x[x.obs['sample'] == sample][:,x.var.filter(like='ERCC', axis='index').index].X.A

     def read_dropseq():
       x = scanpy.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/macosko_dropseq_control.h5ad')
       scanpy.pp.filter_genes(x, min_counts=1)
       return x[:,x.var.filter(like='ERCC', axis='index').index].X.A

     def read_indrops():
       x = scanpy.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/klein_indrops_control.h5ad')
       scanpy.pp.filter_genes(x, min_counts=1)
       return x[:,x.var.filter(like='ERCC', axis='index').index].X.A

     def read_gemcode():
       x = scanpy.read('/project2/mstephens/aksarkar/projects/singlecell-modes/data/negative-controls/zheng_gemcode_control.h5ad')
       scanpy.pp.filter_genes(x, min_counts=1)
       return x.X.A

     def read_c1():
       x = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/ercc-counts.txt.gz', sep='\t', index_col=0)
       keep_samples = pd.read_csv('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt', header=None, index_col=0, sep='\t')
       # Throw out samples with only one spike-in molecule detected
       return x.loc[:,np.logical_and((x.sum(axis=0) > 1).values, keep_samples.values.ravel())].values.T

     data = {
       'dropseq': read_dropseq,
       'indrops': read_indrops,
       'chromium1': lambda: read_chromium('20311'),
       'chromium2': lambda: read_chromium('20312'),
       'gemcode': read_gemcode,
       'c1': read_c1,
     }
   #+END_SRC

   #+RESULTS: ercc-data
   :RESULTS:
   # Out[22]:
   :END:


   #+NAME: run-ercc-benchmark-cpu
   #+BEGIN_SRC ipython :eval never
     <<imports>>
     import os
     <<ercc-data>>
     cpu_methods = ['unimodal', 'zief', 'npmle']
     tasks = [(d, c) for d in data for c in cpu_methods]
     dataset, method = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool() as pool:
       x = data[dataset]()
       res = scmodes.benchmark.evaluate_deconv_generalization(x, pool=pool, test_size=0.1, methods=[method])
       res.to_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{dataset}-{method}.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch -a 0-17 --partition=broadwl -n1 -c28 --exclusive --time=6:00:00 --mem=16G --job-name=deconv-generalization --out=benchmark-cpu.out
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<run-ercc-benchmark-cpu>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60316984

   #+NAME: run-ercc-benchmark-gpu
   #+BEGIN_SRC ipython :eval never
     <<imports>>
     <<ercc-data>>
     for dataset in ('c1',):
       x = data[dataset]()
       res = scmodes.benchmark.evaluate_deconv_generalization(x, pool=None, test_size=0.1, methods=['gamma', 'point_gamma'])
       res.to_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{dataset}-gpu.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 --gres=gpu:1 --mem=4G --time=60:00 --job-name=deconv-generalization --out=benchmark-gpu.out
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<run-ercc-benchmark-gpu>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60316986

   Read the results.

   #+BEGIN_SRC ipython
     benchmark = {}
     for data in ('dropseq', 'indrops', 'chromium1', 'chromium2', 'gemcode', 'c1'):
       benchmark[data] = (
         pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-gpu.txt.gz', index_col=0, sep='\t')
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-unimodal.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-zief.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-npmle.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   Plot the generalization performance of each method.

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/control-benchmark.png
     fig, ax = plt.subplots(1, 6, sharey=True)
     fig.set_size_inches(8, 3)
     for a, k in zip(ax.ravel(), sorted(benchmark.keys())):
       T = (benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:]
       T = np.ma.masked_invalid(T).filled(0)
       a.boxplot(T, widths=.5, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
       a.axhline(y=0, ls=':', lw=1, c='k')
       a.set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
       a.set_title(k)
     ax[2].set_xlabel('Assumed latent dist')
     ax[0].set_ylabel('Diff val set log lik from Gamma')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[142]:
   [[file:figure/deconvolution.org/control-benchmark.png]]
   :END:

   Zoom in on the relevant part of the plot.

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/control-benchmark-inset.png
     fig, ax = plt.subplots(1, 6, sharey=True)
     fig.set_size_inches(8, 3)
     ax[0].set_ylim(0, 1700)
     for a, k in zip(ax.ravel(), sorted(benchmark.keys())):
       T = (benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:]
       T = np.ma.masked_invalid(T).filled(0)
       a.boxplot(T, widths=.5, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
       a.axhline(y=0, ls=':', lw=1, c='k')
       a.set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
       a.set_title(k)
     ax[2].set_xlabel('Assumed latent dist')
     ax[0].set_ylabel('Diff val set log lik from Gamma')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[143]:
   [[file:figure/deconvolution.org/control-benchmark-inset.png]]
   :END:

   *Conclusions:*

   1. ZIG does not perform better than Gamma, supporting the conclusions of
      [[https://www.biorxiv.org/content/10.1101/582064v1][Svensson 2019]]
   2. There is heterogeneity which isn't adequately described by Gamma, but
      appears equally well described by unimodal/ZIEF/NPMLE

** Homogeneous cell populations
   :PROPERTIES:
   :CUSTOM_ID: homogeneous
   :END:

   Run the benchmark.

   #+NAME: run-homogeneous-benchmark-cpu
   #+BEGIN_SRC ipython :eval never
     import os
     data = {
       'cytotoxic_t': lambda: scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19/', return_df=True),
       'b_cells': lambda: scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/b_cells/filtered_matrices_mex/hg19/', return_df=True),
       'ipsc': lambda: scmodes.dataset.ipsc('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/', n=100, return_df=True),
     }
     cpu_methods = ['unimodal', 'zief', 'npmle']
     tasks = [(d, c) for d in data for c in cpu_methods]
     task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool(maxtasksperchild=20) as pool:
       # Important: this needs to be done after initializing the pool to avoid
       # memory duplication
       x = data[task[0]]()
       res = scmodes.benchmark.evaluate_deconv_generalization(x.values, pool=pool, test_size=0.1, random_state=0, methods=[task[1]])
       res.index = x.columns
       res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/{task[0]}-{task[1]}.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl --mem=32G -a 0-8 -n1 -c28 --exclusive --time=12:00:00 --job-name=benchmark --output=benchmark-cpu.out
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<imports>>
     <<run-homogeneous-benchmark-cpu>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60347150

   #+NAME: run-homogeneous-benchmark-gpu
   #+BEGIN_SRC ipython :eval never
     import os
     data = {
       'cytotoxic_t': lambda: scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19/', return_df=True),
       'b_cells': lambda: scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/b_cells/filtered_matrices_mex/hg19/', return_df=True),
       # Important: run the benchmark on all genes
       'ipsc': lambda: scmodes.dataset.ipsc('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/', return_df=True),
     }
     tasks = list(data.keys())
     task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     x = data[task]()
     res = scmodes.benchmark.evaluate_deconv_generalization(x.values, pool=None, test_size=0.1, random_state=0, methods=['gamma', 'point_gamma'])
     res.index = x.columns
     res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/{task}-gpu.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes
     sbatch --partition=gpu2 --gres=gpu:1 -a 1-2 --mem=16G --time=12:00:00 --job-name=benchmark --output=benchmark-gpu.out
     #!/bin/bash
     module load cuda/9.0
     source activate scmodes
     python <<EOF
     <<imports>>
     <<run-homogeneous-benchmark-gpu>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60328857

   Read the results.

   #+BEGIN_SRC ipython
     benchmark = {}
     for data in ('cytotoxic_t', 'b_cells', 'ipsc'):
       benchmark[data] = (
         pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-gpu.txt.gz', index_col=0, sep='\t')
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-unimodal.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-zief.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-npmle.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Plot the generalization performance of each method.

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/homogeneous-benchmark.png
     fig, ax = plt.subplots(1, 3)
     fig.set_size_inches(5, 3)
     for i, k in enumerate(sorted(benchmark.keys())):
       ax[i].boxplot((benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:],
                     widths=0.5, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
       ax[i].axhline(y=0, c='k', lw=1, ls=':')
       ax[i].set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
       ax[i].set_title(k)
     ax[0].set_ylabel('Diff val set log lik from Gamma')
     ax[1].set_xlabel('Assumed latent dist')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   [[file:figure/deconvolution.org/homogeneous-benchmark.png]]
   :END:

   *Conclusions:*

   - The choice of unimodal discretization matters both for generalization
     performance and computational speed. The default in ~ashr~ is flawed;
     [[https://github.com/aksarkar/scmodes/blob/4d84236888daba32a7fee60642f3addd5a34ff9c/scmodes/benchmark/deconvolution.py#L83][our
     choice]] makes the method considerably slower
   - In the iPSC data, modeling all samples without considering individual of
     origin is clearly flawed

** Synthetic cell mixtures
   :PROPERTIES:
   :CUSTOM_ID: synthetic
   :END:
*** T cell-B cell mixture

    Create a synthetic heterogeneous population of cells by combining sorted
    CD8+ T cells and CD19+ B cells from
    [[https://www.nature.com/articles/ncomms14049][Zheng et al. 2017]].

    #+NAME: cd8-cd19-mix
    #+BEGIN_SRC ipython
      t_cells = scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19/', return_df=True, min_detect=0)
      b_cells = scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/b_cells/filtered_matrices_mex/hg19/', return_df=True, min_detect=0)
      x, y = scmodes.dataset.synthetic_mix(t_cells, b_cells)
      # Important: filter genes after mixing cells
      keep_genes = (x > 0).mean(axis=0) >= 0.25
      x = x.loc[:,keep_genes]
    #+END_SRC

    #+NAME: run-cd8-cd19-mix-benchmark-gpu
    #+BEGIN_SRC ipython :eval never
      <<imports>>
      <<cd8-cd19-mix>>
      res = scmodes.benchmark.evaluate_deconv_generalization(x.values, stratify=y, pool=None, train_size=0.5, test_size=0.1, random_state=0, methods=['gamma', 'point_gamma'])
      res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/cd8-cd19-mix-gpu.txt.gz', compression='gzip', sep='\t')
    #+END_SRC

    #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
      sbatch --partition=gpu2 --gres=gpu:1 --mem=16G --time=12:00:00 --job-name=benchmark --output=benchmark-gpu.out
      #!/bin/bash
      module load cuda/9.0
      source activate scmodes
      python <<EOF
      <<run-cd8-cd19-mix-benchmark-gpu>>
      EOF
    #+END_SRC

    #+RESULTS:
    : Submitted batch job 60359981

    #+NAME: run-cd8-cd19-mix-benchmark-cpu
    #+BEGIN_SRC ipython :eval never
      <<imports>>
      import os
      tasks = ['unimodal', 'zief', 'npmle']
      task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
      with mp.Pool() as pool:
        <<cd8-cd19-mix>>
        res = scmodes.benchmark.evaluate_deconv_generalization(x.values, stratify=y, pool=pool, train_size=0.5, test_size=0.1, random_state=0, methods=[task])
        res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/cd8-cd19-mix-{task}.txt.gz', compression='gzip', sep='\t')
    #+END_SRC

    #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
      sbatch --partition=broadwl -a 0-2 -n1 -c28 --exclusive --mem=16G --time=12:00:00 --job-name=benchmark --output=benchmark-cpu.out
      #!/bin/bash
      module load cuda/9.0
      source activate scmodes
      python <<EOF
      <<run-cd8-cd19-mix-benchmark-cpu>>
      EOF
    #+END_SRC

    #+RESULTS:
    : Submitted batch job 60379001

*** Naive/activated T cell mixture

    Create a synthetic mixture of cells by combining sorted
    CD8+ cytotoxic T cells and CD8+/CD45RA+ naive cytotoxic T cells
    [[https://www.nature.com/articles/ncomms14049][Zheng et al. 2017]].

    #+NAME: cyto-naive-mix
    #+BEGIN_SRC ipython
      cyto = scmodes.dataset.read_10x(prefix='/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cytotoxic_t/filtered_matrices_mex/hg19', return_df=True, min_detect=0)
      naive = scmodes.dataset.read_10x(prefix='/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/naive_cytotoxic/filtered_matrices_mex/hg19', return_df=True, min_detect=0)
      x, y = scmodes.dataset.synthetic_mix(cyto, naive)
      keep_genes = (x > 0).mean(axis=0) >= 0.25
      x = x.loc[:,keep_genes]
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[3]:
    :END:

    #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
      sbatch --partition=gpu2 --gres=gpu:1 --mem=32G --time=1:00:00 --job-name=benchmark --output=benchmark-gpu.out
      #!/bin/bash
      source activate scmodes
      python <<EOF
      <<imports>>
      <<cyto-naive-mix>>
      res = scmodes.benchmark.evaluate_deconv_generalization(x.values, pool=None, stratify=y, train_size=0.5, test_size=0.1, random_state=0, methods=['gamma', 'point_gamma'])
      res.index = x.columns
      res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/cyto-naive-t-mix-gpu.txt.gz', compression='gzip', sep='\t')
      EOF
    #+END_SRC

    #+RESULTS:
    : Submitted batch job 60384663

    #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
      sbatch --partition=broadwl -a 0-2 -n1 -c28 --exclusive --mem=32G --time=24:00:00 --job-name=benchmark --output=benchmark-cpu.out
      #!/bin/bash
      source activate scmodes
      python <<EOF
      <<imports>>
      import os
      tasks = ['unimodal', 'zief', 'npmle']
      task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
      with mp.Pool(maxtasksperchild=10) as pool:
        <<cyto-naive-mix>>
        res = scmodes.benchmark.evaluate_deconv_generalization(x.values, pool=pool, stratify=y, train_size=0.5, test_size=0.1, random_state=0, methods=[task])
        res.index = x.columns
        res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/cyto-naive-t-mix-{task}.txt.gz', compression='gzip', sep='\t')
      EOF
    #+END_SRC

    #+RESULTS:
    : Submitted batch job 60384670

*** Plot the results

    Read the results.

    #+BEGIN_SRC ipython
      benchmark = {}
      for data in ('cd8-cd19-mix', 'cyto-naive-t-mix'):
        benchmark[data] = (
          pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-gpu.txt.gz', index_col=0, sep='\t')
          .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-unimodal.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
          .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-zief.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
          .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-npmle.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True))
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[4]:
    :END:

    Plot the results.

    #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/synthetic-mix-benchmark.png
      fig, ax = plt.subplots(1, 2, sharey=True)
      fig.set_size_inches(4, 3)
      for a, k, t in zip(ax, sorted(benchmark.keys()), ['T cell/B cell', 'Cytotoxic/Naive T cell']):
        T = (benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:]
        a.boxplot([x[~np.isnan(x)] for x in T.T],
                  widths=0.25, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
        a.axhline(y=0, ls=':', lw=1, c='k')
        a.set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
        a.set_xlabel('Assumed latent dist')
        a.set_title(t)
      ax[0].set_ylabel('Diff val set log lik from Gamma')
      fig.tight_layout()
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[5]:
    [[file:figure/deconvolution.org/synthetic-mix-benchmark.png]]
    :END:

    Zoom in on the relevant part of the plot.

    #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/synthetic-mix-benchmark-inset.png
      fig, ax = plt.subplots(1, 2)
      fig.set_size_inches(4, 3)
      for a, k, t in zip(ax, sorted(benchmark.keys()), ['T cell/B cell', 'Cytotoxic/Naive T cell']):
        T = (benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:]
        a.boxplot([x[~np.isnan(x)] for x in T.T],
                  widths=0.25, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
        a.boxplot(T, widths=0.25, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
        a.axhline(y=0, ls=':', lw=1, c='k')
        a.set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
        a.set_xlabel('Assumed latent dist')
        a.set_ylim(0, 1.05 * np.ma.masked_invalid(T).max())
        a.set_title(t)
      ax[0].set_ylabel('Diff val set log lik from Gamma')
      fig.tight_layout()
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[10]:
    [[file:figure/deconvolution.org/synthetic-mix-benchmark-inset.png]]
    :END:

** Heterogeneous cell populations
   :PROPERTIES:
   :CUSTOM_ID: heterogeneous
   :END:

   #+NAME: heterogeneous-data
   #+BEGIN_SRC ipython :eval never
     data = {
       'pbmcs_68k': lambda: scmodes.dataset.read_10x('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/fresh_68k_pbmc_donor_a/filtered_matrices_mex/hg19', return_df=True),
       'cortex': lambda: scmodes.dataset.cortex('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/zeisel-2015/GSE60361_C1-3005-Expression.txt.gz', return_df=True)
     }
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[3]:
   :END:

   #+NAME: heterogeneous-benchmark-gpu
   #+BEGIN_SRC ipython :eval never
     <<imports>>
     import os
     <<heterogeneous-data>>
     tasks = ['pbmcs_68k', 'cortex']
     task = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     x = data[task]()
     res = scmodes.benchmark.evaluate_deconv_generalization(x.values, pool=None, test_size=0.1, random_state=0, methods=['gamma', 'point_gamma'])
     res.index = x.columns
     res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/{task}-gpu.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=gpu2 -a 0-1 --gres=gpu:1 --mem=16G --time=12:00:00 --job-name=benchmark --output=benchmark-gpu.out
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<heterogeneous-benchmark-gpu>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60391681

   #+NAME: heterogeneous-benchmark-cpu
   #+BEGIN_SRC ipython :eval never
     <<imports>>
     import os
     <<heterogeneous-data>>
     cpu_methods = ['unimodal', 'zief', 'npmle']
     tasks = [(d, c) for d in data for c in cpu_methods]
     dataset, method = tasks[int(os.environ['SLURM_ARRAY_TASK_ID'])]
     with mp.Pool() as pool:
       x = data[dataset]()
       res = scmodes.benchmark.evaluate_deconv_generalization(x.values, pool=pool, train_size=0.5, test_size=0.1, random_state=0, methods=[method])
       res.index = x.columns
       res.to_csv(f'/scratch/midway2/aksarkar/modes/deconv-generalization/{dataset}-{method}.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC sh :noweb eval :dir /scratch/midway2/aksarkar/modes/
     sbatch --partition=broadwl -a 1 -n1 -c28 --exclusive --mem=32G --time=24:00:00 --job-name=benchmark --output=benchmark-cpu.out
     #!/bin/bash
     source activate scmodes
     python <<EOF
     <<heterogeneous-benchmark-cpu>>
     EOF
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 60396725

   Read the results.

   #+BEGIN_SRC ipython
     benchmark = {}
     for data in ('cortex', 'pbmcs_68k'):
       benchmark[data] = (
         pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-gpu.txt.gz', index_col=0, sep='\t')
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-unimodal.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-zief.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True)
         .merge(pd.read_csv(f'/project2/mstephens/aksarkar/projects/singlecell-modes/data/deconv-generalization/{data}-npmle.txt.gz', index_col=0, sep='\t'), left_index=True, right_index=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   Plot the results.

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/heterogeneous-benchmark.png
     fig, ax = plt.subplots(1, 2, sharey=True)
     fig.set_size_inches(4, 3)
     for a, k, t in zip(ax, sorted(benchmark.keys()), ['Mouse cortex', 'Human PBMCs']):
       T = (benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:]
       a.boxplot([x[~np.isnan(x)] for x in T.T],
                 widths=0.25, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
       a.axhline(y=0, ls=':', lw=1, c='k')
       a.set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
       a.set_xlabel('Assumed latent dist')
       a.set_title(t)
     ax[0].set_ylabel('Diff val set log lik from Gamma')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   [[file:figure/deconvolution.org/heterogeneous-benchmark.png]]
   :END:

   Zoom in on the relevant part of the plot.

   #+BEGIN_SRC ipython :ipyfile figure/deconvolution.org/heterogeneous-benchmark-inset.png
     fig, ax = plt.subplots(1, 2)
     fig.set_size_inches(4, 3)
     for a, k, t in zip(ax, sorted(benchmark.keys()), ['Mouse cortex', 'Human PBMCs']):
       T = np.ma.masked_invalid((benchmark[f'{k}'].values - benchmark[f'{k}']['gamma'].values.reshape(-1, 1))[:,1:]).filled(-1e6)
       a.boxplot(T, widths=0.25, medianprops={'color': 'k'}, flierprops={'marker': '.', 'markersize': 4})
       a.axhline(y=0, ls=':', lw=1, c='k')
       a.set_xticklabels(['ZIG', 'Unimodal', 'ZIEF', 'NPMLE'], rotation=90)
       a.set_xlabel('Assumed latent dist')
       a.set_ylim(0, 1.05 * T.max())
       a.set_title(t)
     ax[0].set_ylabel('Diff val set log lik from Gamma')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   [[file:figure/deconvolution.org/heterogeneous-benchmark-inset.png]]
   :END:

