#+TITLE: Comparison of expression deconvolution approaches
#+SETUPFILE: setup.org

* Introduction

  Suppose we have observations \(x_i \sim f(\theta_i), i = 1, \ldots, n\), and
  \(\theta_i \sim g(\cdot)\). /Distribution deconvolution/ is the problem of
  estimating \(g \in \mathcal{G}\) from \(x_1, \ldots, x_n\), assuming \(f\) is known
  ([[https://academic.oup.com/biomet/article/103/1/1/2390141][Efron
  2016]]).

  Recent work suggests that scRNA-seq data follows this generative model
  ([[http://dx.doi.org/10.1073/pnas.1721085115][Wang et al. 2018]]). Here, we
  investigate the trade-off between model complexity/flexibility and
  generalization for different choices of \(\mathcal{G}\) in real data.

* Setup

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(mem="32G",partition="gpu2",venv="scmodes",opts="--gres=gpu:1") :dir /scratch/midway2/aksarkar/modes :exports none

  #+RESULTS:
  :RESULTS:
  Submitted batch job 58781149
  :END:

  #+BEGIN_SRC ipython
    import colorcet
    import gzip
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import scipy.io
    import scipy.stats as st
    import scipy.special as sp

    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import rpy2.robjects.numpy2ri

    rpy2.robjects.pandas2ri.activate()
    rpy2.robjects.numpy2ri.activate()

    descend = rpy2.robjects.packages.importr('descend')
    ashr = rpy2.robjects.packages.importr('ashr')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[17]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
    plt.rcParams['figure.facecolor'] = 'w'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[53]:
  :END:

* Methods
** Distribution deconvolution

   The general form of distribution deconvolution for scRNA-seq is:

   \[ x_{ij} \sim \mathrm{Poisson}(\exp(\mathbf{z}_i' \mathbf{b}_j) \lambda_{ij}) \]

   \[ \lambda_{ij} \sim g_j(\cdot) \]

   where:

   - \(x_{ij}\) is the count of molecules of gene \(j\) in cell \(i\)
   - \(\mathbf{z}_i\) is a \(q\)-vector of covariates for cell \(i\)
   - \(\mathbf{b}_j\) is a \(q\)-vector of confounding effects on gene \(j\)
   - \(\lambda_{ij}\) is proportional to the relative abundance of gene \(j\)
     in cell \(i\)

   The primary inference goal is to recover \(g_j\). A secondary goal could be
   to recover \(\lambda_{ij}\). We can trade off flexibility and complexity of
   \(g_j\) for ease of implementation and speed.

   1. *Poisson:* \(g_j = \delta_\mu\)
   2. *NB:* \(g_j = \mathrm{Gamma}(\cdot)\)
   3. *ZINB:* \(g_j = \pi_j \delta_0(\cdot) + (1 - \pi_j)
      \mathrm{Gamma}(\cdot)\)
   4. *Unimodal:* \(g_j = \sum_k \pi_k \mathrm{Uniform}(\lambda_0, a_{jk})\),
      where \(\lambda_0\) is the mode (jointly estimated from the
      data). Implemented in ~ashR~.
   5. *Spline:* \(g_j = \exp(\mathbf{Q}'\alpha - \phi(\alpha))\), where
      \(\mathbf{Q}\) is a \(5 \times K\) discretized degree 5 cubic
      spline. Implemented in ~DESCEND~.
   6. *Nonparametric:* \(g_j = \sum_k \pi_k \mathrm{Uniform}(a_k, a_{k+1})\),
      where \(a_1, \ldots, a_K\) define a uniform grid. Implemented in ~ashR~.

   In order to evaluate methods on their ability to estimate \(g_j\), we hold
   out samples in a cross-validation setting, and score methods on the log
   likelihood of the held out data.

   #+BEGIN_SRC ipython
     def nb_nll(x, mean, inv_disp):
       return (x * np.log(mean / inv_disp) -
               x * np.log(1 + mean / inv_disp) -
               inv_disp * np.log(1 + mean / inv_disp) +
               sp.gammaln(x + inv_disp) -
               sp.gammaln(inv_disp) -
               sp.gammaln(x + 1))

     def score_nb(x_train, x_test):
       import scqtl
       onehot = np.ones((x_train.shape[0], 1))
       size_factor = x_train.sum(axis=0).reshape(-1, 1)
       design = np.zeros((num_samples, 1))
       log_mu, log_phi, *_ = scqtl.tf.fit(
         umi=x_train.astype(np.float32),
         onehot=onehot.astype(np.float32),
         design=design.astype(np.float32),
         size_factor=size_factor.astype(np.float32),
         learning_rate=1e-3,
         max_epochs=20000,
         verbose=True)
       return nb_nll(x_test, np.exp(log_mu), np.exp(-log_phi)).sum()

     def softplus(x):
       if x > 30:
         return x
       else:
         return np.log(1 + np.exp(x))

     def zinb_nll(x, mean, inv_disp, logodds):
       case_zero = -softplus(-logodds) + softplus(nb_llik(x, mean, inv_disp) - logodds)
       case_non_zero = -softplus(logodds) + nb_llik(x, mean, inv_disp)
       return np.where(x < 1, case_zero, case_non_zero)

     def score_zinb(x_train, x_test):
       import scqtl
       onehot = np.ones((x_train.shape[0], 1))
       size_factor = x_train.sum(axis=0).reshape(-1, 1)
       design = np.zeros((num_samples, 1))
       init = scqtl.tf.fit(
         umi=x_train.astype(np.float32),
         onehot=onehot.astype(np.float32),
         design=design.astype(np.float32),
         size_factor=size_factor.astype(np.float32),
         learning_rate=1e-3,
         max_epochs=20000,
         verbose=True)
       log_mu, log_phi, logodds, nb_llik, zinb_llik = scqtl.tf.fit(
         umi=umi.astype(np.float32),
         onehot=onehot.astype(np.float32),
         design=design.astype(np.float32),
         size_factor=size_factor.astype(np.float32),
         learning_rate=1e-3,
         max_epochs=20000,
         warm_start=init[:3],
         verbose=True)
       return zinb_nll(x_test, np.exp(logodds), np.exp(-log_phi), logodds).sum()

     def score_ash(x_train, x_test):
       pass
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[3]:
   :END:

* Results
** Homogeneous cell populations

   Use sorted cells from Zheng et al. 2016 as a baseline.

   #+BEGIN_SRC ipython
     def cd8_cytotoxic_t_cells(min_detect=0.25):
       counts = scipy.io.mmread('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cd8+_cytotoxic_t_cells/filtered_matrices_mex/hg19/matrix.mtx.gz').tocsr()
       counts = counts[((counts > 0).mean(axis=1) >= min_detect).A.ravel()].T.A.astype(np.int)
       return counts

     def cd19_b_cells(min_detect=0.25):
       counts = scipy.io.mmread('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cd19+_b_cells/filtered_matrices_mex/hg19/matrix.mtx.gz').tocsr()
       counts = counts[((counts > 0).mean(axis=1) >= min_detect).A.ravel()].T.A.astype(np.int)
       return counts
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Look at some examples.

   #+BEGIN_SRC ipython
     x = cd8_cytotoxic_t_cells()
     xj = pd.Series(x[:,x.mean(axis=0).argmax()])
     size_factor = pd.Series(x.sum(axis=1))
     lam = xj / size_factor
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[94]:
   :END:

   #+BEGIN_SRC ipython
     res = ashr.ash_workhorse(
       pd.Series(np.zeros(x.shape[0])),
       pd.Series(np.ones(x.shape[0])),
       lik=ashr.lik_pois(y=xj, scale=size_factor, link='identity'),
       mode=lam.mean())
     Fj = ashr.cdf_ash(res, np.linspace(lam.min(), lam.max(), 1000))
     fig, ax = plt.subplots(2, 1)
     ax[0].hist(xj, bins=100, color='k')
     ax[0].set_xlabel('Molecule count')
     ax[0].set_ylabel('Number of cells')

     ax[1].plot(np.array(Fj.rx2('x'))[:-1], np.diff(np.array(Fj.rx2('y')).ravel()), c='k', lw=1)
     ax[1].set_xlabel('$\lambda$')
     ax[1].set_ylabel('Density')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[99]:
   [[file:figure/deconvolution.org/ash-example.png]]
   :END:

** Synthetic cell mixtures

** Real cell mixtures

   #+BEGIN_SRC ipython
     def pbmcs_68k(min_detect=0.25):
       counts = scipy.io.mmread('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/68k_pbmcs/filtered_matrices_mex/hg19/matrix.mtx.gz').tocsr()
       counts = counts[((counts > 0).mean(axis=1) >= min_detect).A.ravel()].T.A.astype(np.int)
       return counts

     def cortex():
       counts = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/zeisel-2015/GSE60361_C1-3005-Expression.txt.gz', index_col=0)
       # Follow scVI here
       return counts.loc[counts.var(axis=1).sort_values(ascending=False).head(n=500).index].values.T
   #+END_SRC
